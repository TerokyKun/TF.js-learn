/**
    * @license
    * Copyright 2023 Google LLC. All Rights Reserved.
    * Licensed under the Apache License, Version 2.0 (the "License");
    * you may not use this file except in compliance with the License.
    * You may obtain a copy of the License at
    *
    * http://www.apache.org/licenses/LICENSE-2.0
    *
    * Unless required by applicable law or agreed to in writing, software
    * distributed under the License is distributed on an "AS IS" BASIS,
    * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    * See the License for the specific language governing permissions and
    * limitations under the License.
    * =============================================================================
    */
(function (global, factory) {
    typeof exports === 'object' && typeof module !== 'undefined' ? factory(exports, require('@mediapipe/pose'), require('@tensorflow/tfjs-core'), require('@tensorflow/tfjs-converter')) :
    typeof define === 'function' && define.amd ? define(['exports', '@mediapipe/pose', '@tensorflow/tfjs-core', '@tensorflow/tfjs-converter'], factory) :
    (global = global || self, factory(global.poseDetection = {}, global.globalThis, global.tf, global.tf));
}(this, (function (exports, pose, tf, tfconv) { 'use strict';

    /******************************************************************************
    Copyright (c) Microsoft Corporation.

    Permission to use, copy, modify, and/or distribute this software for any
    purpose with or without fee is hereby granted.

    THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH
    REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY
    AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT,
    INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM
    LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR
    OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR
    PERFORMANCE OF THIS SOFTWARE.
    ***************************************************************************** */
    /* global Reflect, Promise */

    var extendStatics = function(d, b) {
        extendStatics = Object.setPrototypeOf ||
            ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||
            function (d, b) { for (var p in b) if (Object.prototype.hasOwnProperty.call(b, p)) d[p] = b[p]; };
        return extendStatics(d, b);
    };

    function __extends(d, b) {
        if (typeof b !== "function" && b !== null)
            throw new TypeError("Class extends value " + String(b) + " is not a constructor or null");
        extendStatics(d, b);
        function __() { this.constructor = d; }
        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());
    }

    var __assign = function() {
        __assign = Object.assign || function __assign(t) {
            for (var s, i = 1, n = arguments.length; i < n; i++) {
                s = arguments[i];
                for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p)) t[p] = s[p];
            }
            return t;
        };
        return __assign.apply(this, arguments);
    };

    function __awaiter(thisArg, _arguments, P, generator) {
        function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
        return new (P || (P = Promise))(function (resolve, reject) {
            function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
            function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
            function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
            step((generator = generator.apply(thisArg, _arguments || [])).next());
        });
    }

    function __generator(thisArg, body) {
        var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;
        return g = { next: verb(0), "throw": verb(1), "return": verb(2) }, typeof Symbol === "function" && (g[Symbol.iterator] = function() { return this; }), g;
        function verb(n) { return function (v) { return step([n, v]); }; }
        function step(op) {
            if (f) throw new TypeError("Generator is already executing.");
            while (_) try {
                if (f = 1, y && (t = op[0] & 2 ? y["return"] : op[0] ? y["throw"] || ((t = y["return"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;
                if (y = 0, t) op = [op[0] & 2, t.value];
                switch (op[0]) {
                    case 0: case 1: t = op; break;
                    case 4: _.label++; return { value: op[1], done: false };
                    case 5: _.label++; y = op[1]; op = [0]; continue;
                    case 7: op = _.ops.pop(); _.trys.pop(); continue;
                    default:
                        if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }
                        if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }
                        if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }
                        if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }
                        if (t[2]) _.ops.pop();
                        _.trys.pop(); continue;
                }
                op = body.call(thisArg, _);
            } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }
            if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };
        }
    }

    function __spreadArray(to, from, pack) {
        if (pack || arguments.length === 2) for (var i = 0, l = from.length, ar; i < l; i++) {
            if (ar || !(i in from)) {
                if (!ar) ar = Array.prototype.slice.call(from, 0, i);
                ar[i] = from[i];
            }
        }
        return to.concat(ar || Array.prototype.slice.call(from));
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * https://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    // Don't change the order. The order needs to be consistent with the model
    // keypoint result list.
    var COCO_KEYPOINTS = [
        'nose', 'left_eye', 'right_eye', 'left_ear', 'right_ear', 'left_shoulder',
        'right_shoulder', 'left_elbow', 'right_elbow', 'left_wrist', 'right_wrist',
        'left_hip', 'right_hip', 'left_knee', 'right_knee', 'left_ankle',
        'right_ankle'
    ];
    // Don't change the order. The order needs to be consistent with the model
    // keypoint result list.
    var BLAZEPOSE_KEYPOINTS = [
        'nose',
        'left_eye_inner',
        'left_eye',
        'left_eye_outer',
        'right_eye_inner',
        'right_eye',
        'right_eye_outer',
        'left_ear',
        'right_ear',
        'mouth_left',
        'mouth_right',
        'left_shoulder',
        'right_shoulder',
        'left_elbow',
        'right_elbow',
        'left_wrist',
        'right_wrist',
        'left_pinky',
        'right_pinky',
        'left_index',
        'right_index',
        'left_thumb',
        'right_thumb',
        'left_hip',
        'right_hip',
        'left_knee',
        'right_knee',
        'left_ankle',
        'right_ankle',
        'left_heel',
        'right_heel',
        'left_foot_index',
        'right_foot_index'
    ];
    var BLAZEPOSE_KEYPOINTS_BY_SIDE = {
        left: [1, 2, 3, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31],
        right: [4, 5, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32],
        middle: [0]
    };
    var COCO_KEYPOINTS_BY_SIDE = {
        left: [1, 3, 5, 7, 9, 11, 13, 15],
        right: [2, 4, 6, 8, 10, 12, 14, 16],
        middle: [0]
    };
    var COCO_CONNECTED_KEYPOINTS_PAIRS = [
        [0, 1], [0, 2], [1, 3], [2, 4], [5, 6], [5, 7], [5, 11], [6, 8], [6, 12],
        [7, 9], [8, 10], [11, 12], [11, 13], [12, 14], [13, 15], [14, 16]
    ];
    var BLAZEPOSE_CONNECTED_KEYPOINTS_PAIRS = [
        [0, 1], [0, 4], [1, 2], [2, 3], [3, 7], [4, 5],
        [5, 6], [6, 8], [9, 10], [11, 12], [11, 13], [11, 23],
        [12, 14], [14, 16], [12, 24], [13, 15], [15, 17], [16, 18],
        [16, 20], [15, 17], [15, 19], [15, 21], [16, 22], [17, 19],
        [18, 20], [23, 25], [23, 24], [24, 26], [25, 27], [26, 28],
        [27, 29], [28, 30], [27, 31], [28, 32], [29, 31], [30, 32]
    ];

    function toNumber(value) {
        return value instanceof SVGAnimatedLength ? value.baseVal.value : value;
    }
    /**
     * Converts input image to an HTMLCanvasElement. Note that converting
     * back from the output of this function to imageData or a Tensor will be lossy
     * due to premultiplied alpha color values. For more details please reference:
     * https://developer.mozilla.org/en-US/docs/Web/API/CanvasRenderingContext2D/putImageData#data_loss_due_to_browser_optimization
     * @param image Input image.
     *
     * @returns Converted HTMLCanvasElement.
     */
    function toHTMLCanvasElementLossy(image) {
        return __awaiter(this, void 0, void 0, function () {
            var canvas, ctx;
            return __generator(this, function (_a) {
                switch (_a.label) {
                    case 0:
                        canvas = document.createElement('canvas');
                        if (!(image instanceof tf.Tensor)) return [3 /*break*/, 2];
                        return [4 /*yield*/, tf.browser.toPixels(image, canvas)];
                    case 1:
                        _a.sent();
                        return [3 /*break*/, 3];
                    case 2:
                        canvas.width = toNumber(image.width);
                        canvas.height = toNumber(image.height);
                        ctx = canvas.getContext('2d');
                        if (image instanceof ImageData) {
                            ctx.putImageData(image, 0, 0);
                        }
                        else {
                            ctx.drawImage(image, 0, 0);
                        }
                        _a.label = 3;
                    case 3: return [2 /*return*/, canvas];
                }
            });
        });
    }
    /**
     * Converts input image to ImageData. Note that converting
     * from a CanvasImageSource will be lossy due to premultiplied alpha color
     * values. For more details please reference:
     * https://developer.mozilla.org/en-US/docs/Web/API/CanvasRenderingContext2D/putImageData#data_loss_due_to_browser_optimization
     * @param image Input image.
     *
     * @returns Converted ImageData.
     */
    function toImageDataLossy(image) {
        return __awaiter(this, void 0, void 0, function () {
            var _a, height, width, _b, canvas, ctx;
            return __generator(this, function (_c) {
                switch (_c.label) {
                    case 0:
                        if (!(image instanceof tf.Tensor)) return [3 /*break*/, 2];
                        _a = image.shape.slice(0, 2), height = _a[0], width = _a[1];
                        _b = ImageData.bind;
                        return [4 /*yield*/, tf.browser.toPixels(image)];
                    case 1: return [2 /*return*/, new (_b.apply(ImageData, [void 0, _c.sent(), width, height]))()];
                    case 2:
                        canvas = document.createElement('canvas');
                        ctx = canvas.getContext('2d');
                        canvas.width = toNumber(image.width);
                        canvas.height = toNumber(image.height);
                        ctx.drawImage(image, 0, 0);
                        return [2 /*return*/, ctx.getImageData(0, 0, canvas.width, canvas.height)];
                }
            });
        });
    }
    /**
     * Converts input image to Tensor. Note that converting
     * from a CanvasImageSource will be lossy due to premultiplied alpha color
     * values. For more details please reference:
     * https://developer.mozilla.org/en-US/docs/Web/API/CanvasRenderingContext2D/putImageData#data_loss_due_to_browser_optimization
     * @param image Input image.
     *
     * @returns Converted Tensor.
     */
    function toTensorLossy(image) {
        return __awaiter(this, void 0, void 0, function () {
            var pixelsInput, _a;
            return __generator(this, function (_b) {
                switch (_b.label) {
                    case 0:
                        if (!(image instanceof SVGImageElement || image instanceof OffscreenCanvas)) return [3 /*break*/, 2];
                        return [4 /*yield*/, toHTMLCanvasElementLossy(image)];
                    case 1:
                        _a = _b.sent();
                        return [3 /*break*/, 3];
                    case 2:
                        _a = image;
                        _b.label = 3;
                    case 3:
                        pixelsInput = _a;
                        return [2 /*return*/, tf.browser.fromPixels(pixelsInput, 4)];
                }
            });
        });
    }
    function assertMaskValue(maskValue) {
        if (maskValue < 0 || maskValue >= 256) {
            throw new Error("Mask value must be in range [0, 255] but got ".concat(maskValue));
        }
        if (!Number.isInteger(maskValue)) {
            throw new Error("Mask value must be an integer but got ".concat(maskValue));
        }
    }

    var DEFAULT_BLAZEPOSE_MODEL_CONFIG = {
        runtime: 'mediapipe',
        enableSmoothing: true,
        enableSegmentation: false,
        smoothSegmentation: true,
        modelType: 'full'
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * https://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function validateModelConfig(modelConfig) {
        if (modelConfig == null) {
            return __assign({}, DEFAULT_BLAZEPOSE_MODEL_CONFIG);
        }
        var config = __assign({}, modelConfig);
        config.runtime = 'mediapipe';
        if (config.enableSegmentation == null) {
            config.enableSegmentation =
                DEFAULT_BLAZEPOSE_MODEL_CONFIG.enableSegmentation;
        }
        if (config.enableSmoothing == null) {
            config.enableSmoothing = DEFAULT_BLAZEPOSE_MODEL_CONFIG.enableSmoothing;
        }
        if (config.smoothSegmentation == null) {
            config.smoothSegmentation =
                DEFAULT_BLAZEPOSE_MODEL_CONFIG.smoothSegmentation;
        }
        if (config.modelType == null) {
            config.modelType = DEFAULT_BLAZEPOSE_MODEL_CONFIG.modelType;
        }
        return config;
    }

    var BlazePoseMediaPipeMask = /** @class */ (function () {
        function BlazePoseMediaPipeMask(mask) {
            this.mask = mask;
        }
        BlazePoseMediaPipeMask.prototype.toCanvasImageSource = function () {
            return __awaiter(this, void 0, void 0, function () {
                return __generator(this, function (_a) {
                    return [2 /*return*/, this.mask];
                });
            });
        };
        BlazePoseMediaPipeMask.prototype.toImageData = function () {
            return __awaiter(this, void 0, void 0, function () {
                return __generator(this, function (_a) {
                    return [2 /*return*/, toImageDataLossy(this.mask)];
                });
            });
        };
        BlazePoseMediaPipeMask.prototype.toTensor = function () {
            return __awaiter(this, void 0, void 0, function () {
                return __generator(this, function (_a) {
                    return [2 /*return*/, toTensorLossy(this.mask)];
                });
            });
        };
        BlazePoseMediaPipeMask.prototype.getUnderlyingType = function () {
            return 'canvasimagesource';
        };
        return BlazePoseMediaPipeMask;
    }());
    function maskValueToLabel(maskValue) {
        assertMaskValue(maskValue);
        return 'person';
    }
    /**
     * MediaPipe detector class.
     */
    var BlazePoseMediaPipeDetector = /** @class */ (function () {
        // Should not be called outside.
        function BlazePoseMediaPipeDetector(config) {
            var _this = this;
            // This will be filled out by asynchronous calls to onResults. They will be
            // stable after `await send` is called on the pose solution.
            this.width = 0;
            this.height = 0;
            this.selfieMode = false;
            this.poseSolution = new pose.Pose({
                locateFile: function (path, base) {
                    if (config.solutionPath) {
                        var solutionPath = config.solutionPath.replace(/\/+$/, '');
                        return "".concat(solutionPath, "/").concat(path);
                    }
                    return "".concat(base, "/").concat(path);
                }
            });
            var modelComplexity;
            switch (config.modelType) {
                case 'lite':
                    modelComplexity = 0;
                    break;
                case 'heavy':
                    modelComplexity = 2;
                    break;
                case 'full':
                default:
                    modelComplexity = 1;
                    break;
            }
            this.poseSolution.setOptions({
                modelComplexity: modelComplexity,
                smoothLandmarks: config.enableSmoothing,
                enableSegmentation: config.enableSegmentation,
                smoothSegmentation: config.smoothSegmentation,
                selfieMode: this.selfieMode,
            });
            this.poseSolution.onResults(function (results) {
                _this.height = results.image.height;
                _this.width = results.image.width;
                if (results.poseLandmarks == null) {
                    _this.poses = [];
                }
                else {
                    var pose_1 = _this.translateOutput(results.poseLandmarks, results.poseWorldLandmarks);
                    if (results.segmentationMask) {
                        pose_1.segmentation = {
                            maskValueToLabel: maskValueToLabel,
                            mask: new BlazePoseMediaPipeMask(results.segmentationMask)
                        };
                    }
                    _this.poses = [pose_1];
                }
            });
        }
        BlazePoseMediaPipeDetector.prototype.translateOutput = function (pose, pose3D) {
            var _this = this;
            var output = {
                keypoints: pose.map(function (landmark, i) { return ({
                    x: landmark.x * _this.width,
                    y: landmark.y * _this.height,
                    z: landmark.z,
                    score: landmark.visibility,
                    name: BLAZEPOSE_KEYPOINTS[i]
                }); })
            };
            if (pose3D != null) {
                output.keypoints3D = pose3D.map(function (landmark, i) { return ({
                    x: landmark.x,
                    y: landmark.y,
                    z: landmark.z,
                    score: landmark.visibility,
                    name: BLAZEPOSE_KEYPOINTS[i]
                }); });
            }
            return output;
        };
        /**
         * Estimates poses for an image or video frame.
         *
         * It returns a single pose or multiple poses based on the maxPose parameter
         * from the `config`.
         *
         * @param image
         * ImageData|HTMLImageElement|HTMLCanvasElement|HTMLVideoElement The input
         * image to feed through the network.
         *
         * @param config Optional.
         *       maxPoses: Optional. Max number of poses to estimate.
         *       When maxPoses = 1, a single pose is detected, it is usually much
         *       more efficient than maxPoses > 1. When maxPoses > 1, multiple poses
         *       are detected.
         *
         *       flipHorizontal: Optional. Default to false. When image data comes
         *       from camera, the result has to flip horizontally.
         *
         *       enableSmoothing: Optional. Default to true. Smooth pose landmarks
         *       coordinates and visibility scores to reduce jitter.
         *
         * @param timestamp Optional. In milliseconds. This is useful when image is
         *     a tensor, which doesn't have timestamp info. Or to override timestamp
         *     in a video.
         *
         * @return An array of `Pose`s.
         */
        BlazePoseMediaPipeDetector.prototype.estimatePoses = function (image, estimationConfig, timestamp) {
            return __awaiter(this, void 0, void 0, function () {
                var _a, _b;
                return __generator(this, function (_c) {
                    switch (_c.label) {
                        case 0:
                            if (estimationConfig && estimationConfig.flipHorizontal &&
                                (estimationConfig.flipHorizontal !== this.selfieMode)) {
                                this.selfieMode = estimationConfig.flipHorizontal;
                                this.poseSolution.setOptions({
                                    selfieMode: this.selfieMode,
                                });
                            }
                            if (!(image instanceof tf.Tensor)) return [3 /*break*/, 2];
                            _b = ImageData.bind;
                            return [4 /*yield*/, tf.browser.toPixels(image)];
                        case 1:
                            _a = new (_b.apply(ImageData, [void 0, _c.sent(), image.shape[1], image.shape[0]]))();
                            return [3 /*break*/, 3];
                        case 2:
                            _a = image;
                            _c.label = 3;
                        case 3:
                            // Cast to GL TexImageSource types.
                            image = _a;
                            return [4 /*yield*/, this.poseSolution.send({ image: image }, timestamp)];
                        case 4:
                            _c.sent();
                            return [2 /*return*/, this.poses];
                    }
                });
            });
        };
        BlazePoseMediaPipeDetector.prototype.dispose = function () {
            this.poseSolution.close();
        };
        BlazePoseMediaPipeDetector.prototype.reset = function () {
            this.poseSolution.reset();
        };
        BlazePoseMediaPipeDetector.prototype.initialize = function () {
            return this.poseSolution.initialize();
        };
        return BlazePoseMediaPipeDetector;
    }());
    /**
     * Loads the MediaPipe solution.
     *
     * @param modelConfig ModelConfig object that contains parameters for
     * the BlazePose loading process. Please find more details of each parameters
     * in the documentation of the `BlazePoseMediaPipeModelConfig` interface.
     */
    function load(modelConfig) {
        return __awaiter(this, void 0, void 0, function () {
            var config, result;
            return __generator(this, function (_a) {
                switch (_a.label) {
                    case 0:
                        config = validateModelConfig(modelConfig);
                        result = new BlazePoseMediaPipeDetector(config);
                        return [4 /*yield*/, result.initialize()];
                    case 1:
                        _a.sent();
                        return [2 /*return*/, result];
                }
            });
        });
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * https://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function getImageSize(input) {
        if (input instanceof tf.Tensor) {
            return { height: input.shape[0], width: input.shape[1] };
        }
        else {
            return { height: input.height, width: input.width };
        }
    }
    /**
     * Normalizes the provided angle to the range -pi to pi.
     * @param angle The angle in radians to be normalized.
     */
    function normalizeRadians(angle) {
        return angle - 2 * Math.PI * Math.floor((angle + Math.PI) / (2 * Math.PI));
    }
    /**
     * Transform value ranges.
     * @param fromMin Min of original value range.
     * @param fromMax Max of original value range.
     * @param toMin New min of transformed value range.
     * @param toMax New max of transformed value range.
     */
    function transformValueRange(fromMin, fromMax, toMin, toMax) {
        var fromRange = fromMax - fromMin;
        var toRange = toMax - toMin;
        if (fromRange === 0) {
            throw new Error("Original min and max are both ".concat(fromMin, ", range cannot be 0."));
        }
        var scale = toRange / fromRange;
        var offset = toMin - fromMin * scale;
        return { scale: scale, offset: offset };
    }
    /**
     * Convert an image to an image tensor representation.
     *
     * The image tensor has a shape [1, height, width, colorChannel].
     *
     * @param input An image, video frame, or image tensor.
     */
    function toImageTensor(input) {
        return input instanceof tf.Tensor ? input : tf.browser.fromPixels(input);
    }
    /**
     * Padding ratio of left, top, right, bottom, based on the output dimensions.
     *
     * The padding values are non-zero only when the "keep_aspect_ratio" is true.
     *
     * For instance, when the input image is 10x10 (width x height) and the
     * output dimensions is 20x40 and "keep_aspect_ratio" is true, we should scale
     * the input image to 20x20 and places it in the middle of the output image with
     * an equal padding of 10 pixels at the top and the bottom. The result is
     * therefore {left: 0, top: 0.25, right: 0, bottom: 0.25} (10/40 = 0.25f).
     * @param roi The original rectangle to pad.
     * @param targetSize The target width and height of the result rectangle.
     * @param keepAspectRatio Whether keep aspect ratio. Default to false.
     */
    function padRoi(roi, targetSize, keepAspectRatio) {
        if (keepAspectRatio === void 0) { keepAspectRatio = false; }
        if (!keepAspectRatio) {
            return { top: 0, left: 0, right: 0, bottom: 0 };
        }
        var targetH = targetSize.height;
        var targetW = targetSize.width;
        validateSize(targetSize, 'targetSize');
        validateSize(roi, 'roi');
        var tensorAspectRatio = targetH / targetW;
        var roiAspectRatio = roi.height / roi.width;
        var newWidth;
        var newHeight;
        var horizontalPadding = 0;
        var verticalPadding = 0;
        if (tensorAspectRatio > roiAspectRatio) {
            // pad height;
            newWidth = roi.width;
            newHeight = roi.width * tensorAspectRatio;
            verticalPadding = (1 - roiAspectRatio / tensorAspectRatio) / 2;
        }
        else {
            // pad width.
            newWidth = roi.height / tensorAspectRatio;
            newHeight = roi.height;
            horizontalPadding = (1 - tensorAspectRatio / roiAspectRatio) / 2;
        }
        roi.width = newWidth;
        roi.height = newHeight;
        return {
            top: verticalPadding,
            left: horizontalPadding,
            right: horizontalPadding,
            bottom: verticalPadding
        };
    }
    /**
     * Get the rectangle information of an image, including xCenter, yCenter, width,
     * height and rotation.
     *
     * @param imageSize imageSize is used to calculate the rectangle.
     * @param normRect Optional. If normRect is not null, it will be used to get
     *     a subarea rectangle information in the image. `imageSize` is used to
     *     calculate the actual non-normalized coordinates.
     */
    function getRoi(imageSize, normRect) {
        if (normRect) {
            return {
                xCenter: normRect.xCenter * imageSize.width,
                yCenter: normRect.yCenter * imageSize.height,
                width: normRect.width * imageSize.width,
                height: normRect.height * imageSize.height,
                rotation: normRect.rotation
            };
        }
        else {
            return {
                xCenter: 0.5 * imageSize.width,
                yCenter: 0.5 * imageSize.height,
                width: imageSize.width,
                height: imageSize.height,
                rotation: 0
            };
        }
    }
    /**
     * Generate the projective transformation matrix to be used for `tf.transform`.
     *
     * See more documentation in `tf.transform`.
     *
     * @param matrix The transformation matrix mapping subRect to rect, can be
     *     computed using `getRotatedSubRectToRectTransformMatrix` calculator.
     * @param imageSize The original image height and width.
     * @param inputResolution The target height and width.
     */
    function getProjectiveTransformMatrix(matrix, imageSize, inputResolution) {
        validateSize(inputResolution, 'inputResolution');
        // To use M with regular x, y coordinates, we need to normalize them first.
        // Because x' = a0 * x + a1 * y + a2, y' = b0 * x + b1 * y + b2,
        // we need to use factor (1/inputResolution.width) to normalize x for a0 and
        // b0, similarly we need to use factor (1/inputResolution.height) to normalize
        // y for a1 and b1.
        // Also at the end, we need to de-normalize x' and y' to regular coordinates.
        // So we need to use factor imageSize.width for a0, a1 and a2, similarly
        // we need to use factor imageSize.height for b0, b1 and b2.
        var a0 = (1 / inputResolution.width) * matrix[0][0] * imageSize.width;
        var a1 = (1 / inputResolution.height) * matrix[0][1] * imageSize.width;
        var a2 = matrix[0][3] * imageSize.width;
        var b0 = (1 / inputResolution.width) * matrix[1][0] * imageSize.height;
        var b1 = (1 / inputResolution.height) * matrix[1][1] * imageSize.height;
        var b2 = matrix[1][3] * imageSize.height;
        return [a0, a1, a2, b0, b1, b2, 0, 0];
    }
    function validateSize(size, name) {
        tf.util.assert(size.width !== 0, function () { return "".concat(name, " width cannot be 0."); });
        tf.util.assert(size.height !== 0, function () { return "".concat(name, " height cannot be 0."); });
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * https://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    // ref:
    // https://github.com/google/mediapipe/blob/master/mediapipe/calculators/util/detections_to_rects_calculator.cc
    function computeRotation(detection, imageSize, config) {
        var locationData = detection.locationData;
        var startKeypoint = config.rotationVectorStartKeypointIndex;
        var endKeypoint = config.rotationVectorEndKeypointIndex;
        var targetAngle;
        if (config.rotationVectorTargetAngle) {
            targetAngle = config.rotationVectorTargetAngle;
        }
        else {
            targetAngle = Math.PI * config.rotationVectorTargetAngleDegree / 180;
        }
        var x0 = locationData.relativeKeypoints[startKeypoint].x * imageSize.width;
        var y0 = locationData.relativeKeypoints[startKeypoint].y * imageSize.height;
        var x1 = locationData.relativeKeypoints[endKeypoint].x * imageSize.width;
        var y1 = locationData.relativeKeypoints[endKeypoint].y * imageSize.height;
        var rotation = normalizeRadians(targetAngle - Math.atan2(-(y1 - y0), x1 - x0));
        return rotation;
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * https://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    // ref:
    // https://github.com/google/mediapipe/blob/master/mediapipe/calculators/util/alignment_points_to_rects_calculator.cc
    function calculateAlignmentPointsRects(detection, imageSize, config) {
        var startKeypoint = config.rotationVectorStartKeypointIndex;
        var endKeypoint = config.rotationVectorEndKeypointIndex;
        var locationData = detection.locationData;
        var xCenter = locationData.relativeKeypoints[startKeypoint].x * imageSize.width;
        var yCenter = locationData.relativeKeypoints[startKeypoint].y * imageSize.height;
        var xScale = locationData.relativeKeypoints[endKeypoint].x * imageSize.width;
        var yScale = locationData.relativeKeypoints[endKeypoint].y * imageSize.height;
        // Bounding box size as double distance from center to scale point.
        var boxSize = Math.sqrt((xScale - xCenter) * (xScale - xCenter) +
            (yScale - yCenter) * (yScale - yCenter)) *
            2;
        var rotation = computeRotation(detection, imageSize, config);
        // Set resulting bounding box.
        return {
            xCenter: xCenter / imageSize.width,
            yCenter: yCenter / imageSize.height,
            width: boxSize / imageSize.width,
            height: boxSize / imageSize.height,
            rotation: rotation
        };
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * https://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function arrayToMatrix4x4(array) {
        if (array.length !== 16) {
            throw new Error("Array length must be 16 but got ".concat(array.length));
        }
        return [
            [array[0], array[1], array[2], array[3]],
            [array[4], array[5], array[6], array[7]],
            [array[8], array[9], array[10], array[11]],
            [array[12], array[13], array[14], array[15]],
        ];
    }
    function generalDet3Helper(matrix, i1, i2, i3, j1, j2, j3) {
        return matrix[i1][j1] *
            (matrix[i2][j2] * matrix[i3][j3] - matrix[i2][j3] * matrix[i3][j2]);
    }
    function cofactor4x4(matrix, i, j) {
        var i1 = (i + 1) % 4, i2 = (i + 2) % 4, i3 = (i + 3) % 4, j1 = (j + 1) % 4, j2 = (j + 2) % 4, j3 = (j + 3) % 4;
        return generalDet3Helper(matrix, i1, i2, i3, j1, j2, j3) +
            generalDet3Helper(matrix, i2, i3, i1, j1, j2, j3) +
            generalDet3Helper(matrix, i3, i1, i2, j1, j2, j3);
    }
    /**
     * Calculates inverse of an invertible 4x4 matrix.
     * @param matrix 4x4 matrix to invert.
     */
    // ref:
    // https://github.com/google/mediapipe/blob/master/mediapipe/calculators/util/inverse_matrix_calculator.cc
    // https://gitlab.com/libeigen/eigen/-/blob/master/Eigen/src/LU/InverseImpl.h
    function calculateInverseMatrix(matrix) {
        var inverse = arrayToMatrix4x4(new Array(16).fill(0));
        inverse[0][0] = cofactor4x4(matrix, 0, 0);
        inverse[1][0] = -cofactor4x4(matrix, 0, 1);
        inverse[2][0] = cofactor4x4(matrix, 0, 2);
        inverse[3][0] = -cofactor4x4(matrix, 0, 3);
        inverse[0][2] = cofactor4x4(matrix, 2, 0);
        inverse[1][2] = -cofactor4x4(matrix, 2, 1);
        inverse[2][2] = cofactor4x4(matrix, 2, 2);
        inverse[3][2] = -cofactor4x4(matrix, 2, 3);
        inverse[0][1] = -cofactor4x4(matrix, 1, 0);
        inverse[1][1] = cofactor4x4(matrix, 1, 1);
        inverse[2][1] = -cofactor4x4(matrix, 1, 2);
        inverse[3][1] = cofactor4x4(matrix, 1, 3);
        inverse[0][3] = -cofactor4x4(matrix, 3, 0);
        inverse[1][3] = cofactor4x4(matrix, 3, 1);
        inverse[2][3] = -cofactor4x4(matrix, 3, 2);
        inverse[3][3] = cofactor4x4(matrix, 3, 3);
        var scale = matrix[0][0] * inverse[0][0] + matrix[1][0] * inverse[0][1] +
            matrix[2][0] * inverse[0][2] + matrix[3][0] * inverse[0][3];
        for (var i = 0; i < inverse.length; i++) {
            for (var j = 0; j < inverse.length; j++) {
                inverse[i][j] /= scale;
            }
        }
        return inverse;
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * https://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    /**
     * Projects normalized landmarks in a rectangle to its original coordinates. The
     * rectangle must also be in normalized coordinates.
     * @param landmarks A normalized Landmark list representing landmarks in a
     *     normalized rectangle.
     * @param inputRect A normalized rectangle.
     * @param config Config object has one field ignoreRotation, default to false.
     */
    // ref:
    // https://github.com/google/mediapipe/blob/master/mediapipe/calculators/util/landmark_projection_calculator.cc
    function calculateLandmarkProjection(landmarks, inputRect, config) {
        if (config === void 0) { config = {
            ignoreRotation: false
        }; }
        var outputLandmarks = [];
        for (var _i = 0, landmarks_1 = landmarks; _i < landmarks_1.length; _i++) {
            var landmark = landmarks_1[_i];
            var x = landmark.x - 0.5;
            var y = landmark.y - 0.5;
            var angle = config.ignoreRotation ? 0 : inputRect.rotation;
            var newX = Math.cos(angle) * x - Math.sin(angle) * y;
            var newY = Math.sin(angle) * x + Math.cos(angle) * y;
            newX = newX * inputRect.width + inputRect.xCenter;
            newY = newY * inputRect.height + inputRect.yCenter;
            var newZ = landmark.z * inputRect.width; // Scale Z coordinate as x.
            var newLandmark = __assign({}, landmark);
            newLandmark.x = newX;
            newLandmark.y = newY;
            newLandmark.z = newZ;
            outputLandmarks.push(newLandmark);
        }
        return outputLandmarks;
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * https://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    /**
     * A calculator to copy score between landmarks.
     *
     * Landmarks to copy from and to copy to can be of different type (normalized or
     * non-normalized), but landmarks to copy to and output landmarks should be of
     * the same type.
     * @param landmarksFrom  A list of landmarks.
     *     to copy from.
     * @param landmarksTo  A list of landmarks.
     *     to copy to.
     * @param copyScore Copy the score from the `landmarksFrom` parameter.
     */
    // ref:
    // https://github.com/google/mediapipe/blob/master/mediapipe/calculators/util/visibility_copy_calculator.cc
    function calculateScoreCopy(landmarksFrom, landmarksTo, copyScore) {
        if (copyScore === void 0) { copyScore = true; }
        var outputLandmarks = [];
        for (var i = 0; i < landmarksFrom.length; i++) {
            // Create output landmark and copy all fields from the `to` landmarks
            var newLandmark = __assign({}, landmarksTo[i]);
            // Copy score from the `from` landmark.
            if (copyScore) {
                newLandmark.score = landmarksFrom[i].score;
            }
            outputLandmarks.push(newLandmark);
        }
        return outputLandmarks;
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * https://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    /**
     * Projects world landmarks from the rectangle to original coordinates.
     *
     * World landmarks are predicted in meters rather than in pixels of the image
     * and have origin in the middle of the hips rather than in the corner of the
     * pose image (cropped with given rectangle). Thus only rotation (but not scale
     * and translation) is applied to the landmarks to transform them back to
     * original coordinates.
     * @param worldLandmarks A Landmark list representing world landmarks in the
     *     rectangle.
     * @param inputRect A normalized rectangle.
     */
    // ref:
    // https://github.com/google/mediapipe/blob/master/mediapipe/calculators/util/landmark_projection_calculator.cc
    function calculateWorldLandmarkProjection(worldLandmarks, inputRect) {
        var outputLandmarks = [];
        for (var _i = 0, worldLandmarks_1 = worldLandmarks; _i < worldLandmarks_1.length; _i++) {
            var worldLandmark = worldLandmarks_1[_i];
            var x = worldLandmark.x;
            var y = worldLandmark.y;
            var angle = inputRect.rotation;
            var newX = Math.cos(angle) * x - Math.sin(angle) * y;
            var newY = Math.sin(angle) * x + Math.cos(angle) * y;
            var newLandmark = __assign({}, worldLandmark);
            newLandmark.x = newX;
            newLandmark.y = newY;
            outputLandmarks.push(newLandmark);
        }
        return outputLandmarks;
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * https://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    var MICRO_SECONDS_TO_SECOND = 1e-6;
    var SECOND_TO_MICRO_SECONDS = 1e6;
    var MILLISECOND_TO_MICRO_SECONDS = 1000;

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * https://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    /**
     * Generates a 4x4 projective transform matrix M, so that for any point in the
     * subRect image p(x, y), we can use the matrix to calculate the projected point
     * in the original image p' (x', y'): p' = p * M;
     *
     * @param subRect Rotated sub rect in absolute coordinates.
     * @param rectWidth
     * @param rectHeight
     * @param flipHorizontaly Whether to flip the image horizontally.
     */
    // Ref:
    // https://github.com/google/mediapipe/blob/master/mediapipe/calculators/tensor/image_to_tensor_utils.h
    function getRotatedSubRectToRectTransformMatrix(subRect, rectWidth, rectHeight, flipHorizontally) {
        // The resulting matrix is multiplication of below commented out matrices:
        //   postScaleMatrix
        //     * translateMatrix
        //     * rotateMatrix
        //     * flipMatrix
        //     * scaleMatrix
        //     * initialTranslateMatrix
        // For any point in the transformed image p, we can use the above matrix to
        // calculate the projected point in the original image p'. So that:
        // p' = p * M;
        // Note: The transform matrix below assumes image coordinates is normalized
        // to [0, 1] range.
        // Matrix to convert X,Y to [-0.5, 0.5] range "initialTranslateMatrix"
        // [ 1.0,  0.0, 0.0, -0.5]
        // [ 0.0,  1.0, 0.0, -0.5]
        // [ 0.0,  0.0, 1.0,  0.0]
        // [ 0.0,  0.0, 0.0,  1.0]
        var a = subRect.width;
        var b = subRect.height;
        // Matrix to scale X,Y,Z to sub rect "scaleMatrix"
        // Z has the same scale as X.
        // [   a, 0.0, 0.0, 0.0]
        // [0.0,    b, 0.0, 0.0]
        // [0.0, 0.0,    a, 0.0]
        // [0.0, 0.0, 0.0, 1.0]
        var flip = flipHorizontally ? -1 : 1;
        // Matrix for optional horizontal flip around middle of output image.
        // [ fl  , 0.0, 0.0, 0.0]
        // [ 0.0, 1.0, 0.0, 0.0]
        // [ 0.0, 0.0, 1.0, 0.0]
        // [ 0.0, 0.0, 0.0, 1.0]
        var c = Math.cos(subRect.rotation);
        var d = Math.sin(subRect.rotation);
        // Matrix to do rotation around Z axis "rotateMatrix"
        // [    c,   -d, 0.0, 0.0]
        // [    d,    c, 0.0, 0.0]
        // [ 0.0, 0.0, 1.0, 0.0]
        // [ 0.0, 0.0, 0.0, 1.0]
        var e = subRect.xCenter;
        var f = subRect.yCenter;
        // Matrix to do X,Y translation of sub rect within parent rect
        // "translateMatrix"
        // [1.0, 0.0, 0.0, e   ]
        // [0.0, 1.0, 0.0, f   ]
        // [0.0, 0.0, 1.0, 0.0]
        // [0.0, 0.0, 0.0, 1.0]
        var g = 1.0 / rectWidth;
        var h = 1.0 / rectHeight;
        // Matrix to scale X,Y,Z to [0.0, 1.0] range "postScaleMatrix"
        // [g,    0.0, 0.0, 0.0]
        // [0.0, h,    0.0, 0.0]
        // [0.0, 0.0,    g, 0.0]
        // [0.0, 0.0, 0.0, 1.0]
        var matrix = new Array(16);
        // row 1
        matrix[0] = a * c * flip * g;
        matrix[1] = -b * d * g;
        matrix[2] = 0.0;
        matrix[3] = (-0.5 * a * c * flip + 0.5 * b * d + e) * g;
        // row 2
        matrix[4] = a * d * flip * h;
        matrix[5] = b * c * h;
        matrix[6] = 0.0;
        matrix[7] = (-0.5 * b * c - 0.5 * a * d * flip + f) * h;
        // row 3
        matrix[8] = 0.0;
        matrix[9] = 0.0;
        matrix[10] = a * g;
        matrix[11] = 0.0;
        // row 4
        matrix[12] = 0.0;
        matrix[13] = 0.0;
        matrix[14] = 0.0;
        matrix[15] = 1.0;
        return arrayToMatrix4x4(matrix);
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * https://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function shiftImageValue(image, outputFloatRange) {
        // Calculate the scale and offset to shift from [0, 255] to [-1, 1].
        var valueRange = transformValueRange(0, 255, outputFloatRange[0] /* min */, outputFloatRange[1] /* max */);
        // Shift value range.
        return tf.tidy(function () { return tf.add(tf.mul(image, valueRange.scale), valueRange.offset); });
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * https://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    /**
     * Convert an image or part of it to an image tensor.
     *
     * @param image An image, video frame or image tensor.
     * @param config
     *      inputResolution: The target height and width.
     *      keepAspectRatio?: Whether target tensor should keep aspect ratio.
     * @param normRect A normalized rectangle, representing the subarea to crop from
     *      the image. If normRect is provided, the returned image tensor represents
     *      the subarea.
     * @returns A map with the following properties:
     *     - imageTensor
     *     - padding: Padding ratio of left, top, right, bottom, based on the output
     * dimensions.
     *     - transformationMatrix: Projective transform matrix used to transform
     * input image to transformed image.
     */
    function convertImageToTensor(image, config, normRect) {
        var outputTensorSize = config.outputTensorSize, keepAspectRatio = config.keepAspectRatio, borderMode = config.borderMode, outputTensorFloatRange = config.outputTensorFloatRange;
        // Ref:
        // https://github.com/google/mediapipe/blob/master/mediapipe/calculators/tensor/image_to_tensor_calculator.cc
        var imageSize = getImageSize(image);
        var roi = getRoi(imageSize, normRect);
        var padding = padRoi(roi, outputTensorSize, keepAspectRatio);
        var transformationMatrix = getRotatedSubRectToRectTransformMatrix(roi, imageSize.width, imageSize.height, false);
        var imageTensor = tf.tidy(function () {
            var $image = toImageTensor(image);
            var transformMatrix = tf.tensor2d(getProjectiveTransformMatrix(transformationMatrix, imageSize, outputTensorSize), [1, 8]);
            var fillMode = borderMode === 'zero' ? 'constant' : 'nearest';
            var imageTransformed = tf.image.transform(
            // tslint:disable-next-line: no-unnecessary-type-assertion
            tf.expandDims(tf.cast($image, 'float32')), transformMatrix, 'bilinear', fillMode, 0, [outputTensorSize.height, outputTensorSize.width]);
            var imageShifted = outputTensorFloatRange != null ?
                shiftImageValue(imageTransformed, outputTensorFloatRange) :
                imageTransformed;
            return imageShifted;
        });
        return { imageTensor: imageTensor, padding: padding, transformationMatrix: transformationMatrix };
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * https://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    // ref:
    // https://github.com/google/mediapipe/blob/350fbb2100ad531bc110b93aaea23d96af5a5064/mediapipe/calculators/tflite/ssd_anchors_calculator.cc
    function createSsdAnchors(config) {
        // Set defaults.
        if (config.reduceBoxesInLowestLayer == null) {
            config.reduceBoxesInLowestLayer = false;
        }
        if (config.interpolatedScaleAspectRatio == null) {
            config.interpolatedScaleAspectRatio = 1.0;
        }
        if (config.fixedAnchorSize == null) {
            config.fixedAnchorSize = false;
        }
        var anchors = [];
        var layerId = 0;
        while (layerId < config.numLayers) {
            var anchorHeight = [];
            var anchorWidth = [];
            var aspectRatios = [];
            var scales = [];
            // For same strides, we merge the anchors in the same order.
            var lastSameStrideLayer = layerId;
            while (lastSameStrideLayer < config.strides.length &&
                config.strides[lastSameStrideLayer] === config.strides[layerId]) {
                var scale = calculateScale(config.minScale, config.maxScale, lastSameStrideLayer, config.strides.length);
                if (lastSameStrideLayer === 0 && config.reduceBoxesInLowestLayer) {
                    // For first layer, it can be specified to use predefined anchors.
                    aspectRatios.push(1);
                    aspectRatios.push(2);
                    aspectRatios.push(0.5);
                    scales.push(0.1);
                    scales.push(scale);
                    scales.push(scale);
                }
                else {
                    for (var aspectRatioId = 0; aspectRatioId < config.aspectRatios.length; ++aspectRatioId) {
                        aspectRatios.push(config.aspectRatios[aspectRatioId]);
                        scales.push(scale);
                    }
                    if (config.interpolatedScaleAspectRatio > 0.0) {
                        var scaleNext = lastSameStrideLayer === config.strides.length - 1 ?
                            1.0 :
                            calculateScale(config.minScale, config.maxScale, lastSameStrideLayer + 1, config.strides.length);
                        scales.push(Math.sqrt(scale * scaleNext));
                        aspectRatios.push(config.interpolatedScaleAspectRatio);
                    }
                }
                lastSameStrideLayer++;
            }
            for (var i = 0; i < aspectRatios.length; ++i) {
                var ratioSqrts = Math.sqrt(aspectRatios[i]);
                anchorHeight.push(scales[i] / ratioSqrts);
                anchorWidth.push(scales[i] * ratioSqrts);
            }
            var featureMapHeight = 0;
            var featureMapWidth = 0;
            if (config.featureMapHeight.length > 0) {
                featureMapHeight = config.featureMapHeight[layerId];
                featureMapWidth = config.featureMapWidth[layerId];
            }
            else {
                var stride = config.strides[layerId];
                featureMapHeight = Math.ceil(config.inputSizeHeight / stride);
                featureMapWidth = Math.ceil(config.inputSizeWidth / stride);
            }
            for (var y = 0; y < featureMapHeight; ++y) {
                for (var x = 0; x < featureMapWidth; ++x) {
                    for (var anchorId = 0; anchorId < anchorHeight.length; ++anchorId) {
                        var xCenter = (x + config.anchorOffsetX) / featureMapWidth;
                        var yCenter = (y + config.anchorOffsetY) / featureMapHeight;
                        var newAnchor = { xCenter: xCenter, yCenter: yCenter, width: 0, height: 0 };
                        if (config.fixedAnchorSize) {
                            newAnchor.width = 1.0;
                            newAnchor.height = 1.0;
                        }
                        else {
                            newAnchor.width = anchorWidth[anchorId];
                            newAnchor.height = anchorHeight[anchorId];
                        }
                        anchors.push(newAnchor);
                    }
                }
            }
            layerId = lastSameStrideLayer;
        }
        return anchors;
    }
    function calculateScale(minScale, maxScale, strideIndex, numStrides) {
        if (numStrides === 1) {
            return (minScale + maxScale) * 0.5;
        }
        else {
            return minScale + (maxScale - minScale) * strideIndex / (numStrides - 1);
        }
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * https://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function splitDetectionResult(detectionResult) {
        return tf.tidy(function () {
            // logit is stored in the first element in each anchor data.
            var logits = tf.slice(detectionResult, [0, 0, 0], [1, -1, 1]);
            // Bounding box coords are stored in the next four elements for each anchor
            // point.
            var rawBoxes = tf.slice(detectionResult, [0, 0, 1], [1, -1, -1]);
            return [logits, rawBoxes];
        });
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * https://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function detectorResult(detectionResult) {
        return tf.tidy(function () {
            var _a = splitDetectionResult(detectionResult), logits = _a[0], rawBoxes = _a[1];
            // Shape [896, 12]
            var rawBoxes2d = tf.squeeze(rawBoxes);
            // Shape [896]
            var logits1d = tf.squeeze(logits);
            return { boxes: rawBoxes2d, logits: logits1d };
        });
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * https://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function isVideo(image) {
        return (image != null) && image.currentTime != null;
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * https://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    /**
     * Converts normalized Landmark to `Detection`. A relative bounding box will
     * be created containing all landmarks exactly.
     * @param landmarks List of normalized landmarks.
     *
     * @returns A `Detection`.
     */
    // ref:
    // https://github.com/google/mediapipe/blob/master/mediapipe/calculators/util/landmarks_to_detection_calculator.cc
    function landmarksToDetection(landmarks) {
        var detection = { locationData: { relativeKeypoints: [] } };
        var xMin = Number.MAX_SAFE_INTEGER;
        var xMax = Number.MIN_SAFE_INTEGER;
        var yMin = Number.MAX_SAFE_INTEGER;
        var yMax = Number.MIN_SAFE_INTEGER;
        for (var i = 0; i < landmarks.length; ++i) {
            var landmark = landmarks[i];
            xMin = Math.min(xMin, landmark.x);
            xMax = Math.max(xMax, landmark.x);
            yMin = Math.min(yMin, landmark.y);
            yMax = Math.max(yMax, landmark.y);
            detection.locationData.relativeKeypoints.push({ x: landmark.x, y: landmark.y });
        }
        detection.locationData.relativeBoundingBox =
            { xMin: xMin, yMin: yMin, xMax: xMax, yMax: yMax, width: (xMax - xMin), height: (yMax - yMin) };
        return detection;
    }

    function nonMaxSuppression(detections, maxDetections, iouThreshold, 
    // Currently only IOU overap is supported.
    overlapType) {
        return __awaiter(this, void 0, void 0, function () {
            var detectionsTensor, scoresTensor, selectedIdsTensor, selectedIds, selectedDetections;
            return __generator(this, function (_a) {
                switch (_a.label) {
                    case 0:
                        // Sort to match NonMaxSuppresion calculator's decreasing detection score
                        // traversal.
                        // NonMaxSuppresionCalculator: RetainMaxScoringLabelOnly
                        detections.sort(function (detectionA, detectionB) {
                            return Math.max.apply(Math, detectionB.score) - Math.max.apply(Math, detectionA.score);
                        });
                        detectionsTensor = tf.tensor2d(detections.map(function (d) {
                            return [d.locationData.relativeBoundingBox.yMin,
                                d.locationData.relativeBoundingBox.xMin,
                                d.locationData.relativeBoundingBox.yMax,
                                d.locationData.relativeBoundingBox.xMax];
                        }));
                        scoresTensor = tf.tensor1d(detections.map(function (d) { return d.score[0]; }));
                        return [4 /*yield*/, tf.image.nonMaxSuppressionAsync(detectionsTensor, scoresTensor, maxDetections, iouThreshold)];
                    case 1:
                        selectedIdsTensor = _a.sent();
                        return [4 /*yield*/, selectedIdsTensor.array()];
                    case 2:
                        selectedIds = _a.sent();
                        selectedDetections = detections.filter(function (_, i) { return (selectedIds.indexOf(i) > -1); });
                        tf.dispose([detectionsTensor, scoresTensor, selectedIdsTensor]);
                        return [2 /*return*/, selectedDetections];
                }
            });
        });
    }

    function normalizedKeypointsToKeypoints(normalizedKeypoints, imageSize) {
        return normalizedKeypoints.map(function (normalizedKeypoint) {
            var keypoint = __assign(__assign({}, normalizedKeypoint), { x: normalizedKeypoint.x * imageSize.width, y: normalizedKeypoint.y * imageSize.height });
            if (normalizedKeypoint.z != null) {
                // Scale z the same way as x (using image width).
                keypoint.z = normalizedKeypoint.z * imageSize.width;
            }
            return keypoint;
        });
    }

    /**
     * A calculator that refines landmarks using corresponding heatmap area.
     *
     * High level algorithm
     * For each landmark, we replace original value with a value calculated from the
     * area in heatmap close to original landmark position (the area is defined by
     * config.kernelSize). To calculate new coordinate from heatmap we calculate an
     * weighted average inside the kernel. We update the landmark if heatmap is
     * confident in it's prediction i.e. max(heatmap) in kernel is at least bigger
     * than config.minConfidenceToRefine.
     * @param landmarks List of lardmarks to refine.
     * @param heatmapTensor The heatmap for the landmarks with shape
     *     [height, width, channel]. The channel dimension has to be the same as
     *     the number of landmarks.
     * @param config The config for refineLandmarksFromHeap,
     *     see `RefineLandmarksFromHeatmapConfig` for detail.
     *
     * @returns Normalized landmarks.
     */
    function refineLandmarksFromHeatmap(landmarks, heatmapTensor, config) {
        return __awaiter(this, void 0, void 0, function () {
            var $heatmapTensor, _a, hmHeight, hmWidth, hmChannels, outLandmarks, heatmapBuf, i, landmark, outLandmark, centerCol, centerRow, offset, beginCol, endCol, beginRow, endRow, sum, weightedCol, weightedRow, maxValue, row, col, confidence;
            return __generator(this, function (_b) {
                switch (_b.label) {
                    case 0:
                        $heatmapTensor = tf.squeeze(heatmapTensor, [0]);
                        _a = $heatmapTensor.shape, hmHeight = _a[0], hmWidth = _a[1], hmChannels = _a[2];
                        if (landmarks.length !== hmChannels) {
                            throw new Error('Expected heatmap to have same number of channels ' +
                                'as the number of landmarks. But got landmarks length: ' +
                                "".concat(landmarks.length, ", heatmap length: ").concat(hmChannels));
                        }
                        outLandmarks = [];
                        return [4 /*yield*/, $heatmapTensor.buffer()];
                    case 1:
                        heatmapBuf = _b.sent();
                        for (i = 0; i < landmarks.length; i++) {
                            landmark = landmarks[i];
                            outLandmark = __assign({}, landmark);
                            outLandmarks.push(outLandmark);
                            centerCol = Math.trunc(outLandmark.x * hmWidth);
                            centerRow = Math.trunc(outLandmark.y * hmHeight);
                            // Point is outside of the image let's keep it intact.
                            if (centerCol < 0 || centerCol >= hmWidth || centerRow < 0 ||
                                centerCol >= hmHeight) {
                                continue;
                            }
                            offset = Math.trunc((config.kernelSize - 1) / 2);
                            beginCol = Math.max(0, centerCol - offset);
                            endCol = Math.min(hmWidth, centerCol + offset + 1);
                            beginRow = Math.max(0, centerRow - offset);
                            endRow = Math.min(hmHeight, centerRow + offset + 1);
                            sum = 0;
                            weightedCol = 0;
                            weightedRow = 0;
                            maxValue = 0;
                            // Main loop. Go over kernel and calculate weighted sum of coordinates,
                            // sum of weights and max weights.
                            for (row = beginRow; row < endRow; ++row) {
                                for (col = beginCol; col < endCol; ++col) {
                                    confidence = heatmapBuf.get(row, col, i);
                                    sum += confidence;
                                    maxValue = Math.max(maxValue, confidence);
                                    weightedCol += col * confidence;
                                    weightedRow += row * confidence;
                                }
                            }
                            if (maxValue >= config.minConfidenceToRefine && sum > 0) {
                                outLandmark.x = weightedCol / hmWidth / sum;
                                outLandmark.y = weightedRow / hmHeight / sum;
                            }
                        }
                        $heatmapTensor.dispose();
                        return [2 /*return*/, outLandmarks];
                }
            });
        });
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * https://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    /**
     * Adjusts detection locations on the letterboxed image to the corresponding
     * locations on the same image with the letterbox removed (the input image to
     * the graph before image transformation).
     *
     * @param detections A list of detection boxes on an letterboxed image.
     * @param letterboxPadding A `padding` object representing the letterbox padding
     *     from the 4 sides: left, top, right, bottom, of the letterboxed image,
     *     normalized by the letterboxed image dimensions.
     * @returns detections: A list of detection boxes representing detections with
     *     their locations adjusted to the letterbox-removed (non-padded) image.
     */
    // ref:
    // https://github.com/google/mediapipe/blob/master/mediapipe/calculators/util/detection_letterbox_removal_calculator.cc
    function removeDetectionLetterbox(detections, letterboxPadding) {
        if (detections === void 0) { detections = []; }
        var left = letterboxPadding.left;
        var top = letterboxPadding.top;
        var leftAndRight = letterboxPadding.left + letterboxPadding.right;
        var topAndBottom = letterboxPadding.top + letterboxPadding.bottom;
        for (var i = 0; i < detections.length; i++) {
            var detection = detections[i];
            var relativeBoundingBox = detection.locationData.relativeBoundingBox;
            var xMin = (relativeBoundingBox.xMin - left) / (1 - leftAndRight);
            var yMin = (relativeBoundingBox.yMin - top) / (1 - topAndBottom);
            var width = relativeBoundingBox.width / (1 - leftAndRight);
            var height = relativeBoundingBox.height / (1 - topAndBottom);
            relativeBoundingBox.xMin = xMin;
            relativeBoundingBox.yMin = yMin;
            relativeBoundingBox.width = width;
            relativeBoundingBox.height = height;
            relativeBoundingBox.xMax = xMin + width;
            relativeBoundingBox.yMax = yMin + height;
            var relativeKeypoints = detection.locationData.relativeKeypoints;
            if (relativeKeypoints) {
                relativeKeypoints.forEach(function (keypoint) {
                    var newX = (keypoint.x - left) / (1 - leftAndRight);
                    var newY = (keypoint.y - top) / (1 - topAndBottom);
                    keypoint.x = newX;
                    keypoint.y = newY;
                });
            }
        }
        return detections;
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * https://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    /**
     * Adjusts landmark locations on a letterboxed image to the corresponding
     * locations on the same image with the letterbox removed.
     * @param rawLandmark A NormalizedLandmarkList representing landmarks on an
     * letterboxed image.
     * @param padding A `padding` representing the letterbox padding from the 4
     *     sides, left, top, right, bottom, of the letterboxed image, normalized by
     *     the letterboxed image dimensions.
     * @returns Normalized landmarks.
     */
    // ref:
    // https://github.com/google/mediapipe/blob/master/mediapipe/calculators/util/landmark_letterbox_removal_calculator.cc
    function removeLandmarkLetterbox(rawLandmark, padding) {
        var left = padding.left;
        var top = padding.top;
        var leftAndRight = padding.left + padding.right;
        var topAndBottom = padding.top + padding.bottom;
        var outLandmarks = rawLandmark.map(function (landmark) {
            return __assign(__assign({}, landmark), { x: (landmark.x - left) / (1 - leftAndRight), y: (landmark.y - top) / (1 - topAndBottom), z: landmark.z / (1 - leftAndRight) // Scale Z coordinate as X.
             });
        });
        return outLandmarks;
    }

    /**
     * A calculator for mixing two segmentation masks together, based on an
     * uncertantity probability estimate.
     * @param prevMaks Segmentation mask from previous image.
     * @param newMask Segmentation mask of current image.
     * @param config Contains ratio of amount of previous mask to blend with
     *     current.
     *
     * @returns Image mask.
     */
    // ref:
    // https://github.com/google/mediapipe/blob/master/mediapipe/calculators/image/segmentation_smoothing_calculator.cc
    function smoothSegmentation(prevMask, newMask, config) {
        if (tf.getBackend() === 'webgl') {
            // Same as implementation in the else case but reduces number of shader
            // calls to 1 instead of 17.
            return smoothSegmentationWebGL(prevMask, newMask, config);
        }
        return tf.tidy(function () {
            /*
             * Assume p := newMaskValue
             * H(p) := 1 + (p * log(p) + (1-p) * log(1-p)) / log(2)
             * uncertainty alpha(p) =
             *   Clamp(1 - (1 - H(p)) * (1 - H(p)), 0, 1) [squaring the
             * uncertainty]
             *
             * The following polynomial approximates uncertainty alpha as a
             * function of (p + 0.5):
             */
            var c1 = 5.68842;
            var c2 = -0.748699;
            var c3 = -57.8051;
            var c4 = 291.309;
            var c5 = -624.717;
            var t = tf.sub(newMask, 0.5);
            var x = tf.square(t);
            // Per element calculation is: 1.0 - Math.min(1.0, x * (c1 + x * (c2 + x
            // * (c3 + x * (c4 + x * c5))))).
            var uncertainty = tf.sub(1, tf.minimum(1, tf.mul(x, tf.add(c1, tf.mul(x, tf.add(c2, tf.mul(x, tf.add(c3, tf.mul(x, tf.add(c4, tf.mul(x, c5)))))))))));
            // Per element calculation is: newMaskValue + (prevMaskValue -
            // newMaskValue) * (uncertainty * combineWithPreviousRatio).
            return tf.add(newMask, tf.mul(tf.sub(prevMask, newMask), tf.mul(uncertainty, config.combineWithPreviousRatio)));
        });
    }
    function smoothSegmentationWebGL(prevMask, newMask, config) {
        var ratio = config.combineWithPreviousRatio.toFixed(2);
        var program = {
            variableNames: ['prevMask', 'newMask'],
            outputShape: prevMask.shape,
            userCode: "\n  void main() {\n      ivec2 coords = getOutputCoords();\n      int height = coords[0];\n      int width = coords[1];\n\n      float prevMaskValue = getPrevMask(height, width);\n      float newMaskValue = getNewMask(height, width);\n\n      /*\n      * Assume p := newMaskValue\n      * H(p) := 1 + (p * log(p) + (1-p) * log(1-p)) / log(2)\n      * uncertainty alpha(p) =\n      *   Clamp(1 - (1 - H(p)) * (1 - H(p)), 0, 1) [squaring the\n      * uncertainty]\n      *\n      * The following polynomial approximates uncertainty alpha as a\n      * function of (p + 0.5):\n      */\n      const float c1 = 5.68842;\n      const float c2 = -0.748699;\n      const float c3 = -57.8051;\n      const float c4 = 291.309;\n      const float c5 = -624.717;\n      float t = newMaskValue - 0.5;\n      float x = t * t;\n\n      float uncertainty =\n        1.0 - min(1.0, x * (c1 + x * (c2 + x * (c3 + x * (c4 + x * c5)))));\n\n      float outputValue = newMaskValue + (prevMaskValue - newMaskValue) *\n                             (uncertainty * ".concat(ratio, ");\n\n      setOutput(outputValue);\n    }\n")
        };
        var webglBackend = tf.backend();
        return tf.tidy(function () {
            var outputTensorInfo = webglBackend.compileAndRun(program, [prevMask, newMask]);
            return tf.engine().makeTensorFromDataId(outputTensorInfo.dataId, outputTensorInfo.shape, outputTensorInfo.dtype);
        });
    }

    /**
     * Convert result Tensors from object detection models into Detection boxes.
     *
     * @param detectionTensors List of Tensors of type Float32. The list of tensors
     *     can have 2 or 3 tensors. First tensor is the predicted raw
     *     boxes/keypoints. The size of the values must be
     *     (num_boxes * num_predicted_values). Second tensor is the score tensor.
     *     The size of the valuse must be (num_boxes * num_classes). It's optional
     *     to pass in a third tensor for anchors (e.g. for SSD models) depend on the
     *     outputs of the detection model. The size of anchor tensor must be
     *     (num_boxes * 4).
     * @param anchor A tensor for anchors. The size of anchor tensor must be
     *     (num_boxes * 4).
     * @param config
     */
    function tensorsToDetections(detectionTensors, anchor, config) {
        return __awaiter(this, void 0, void 0, function () {
            var rawScoreTensor, rawBoxTensor, boxes, normalizedScore, outputDetections;
            return __generator(this, function (_a) {
                switch (_a.label) {
                    case 0:
                        rawScoreTensor = detectionTensors[0];
                        rawBoxTensor = detectionTensors[1];
                        boxes = decodeBoxes(rawBoxTensor, anchor, config);
                        normalizedScore = tf.tidy(function () {
                            var normalizedScore = rawScoreTensor;
                            if (config.sigmoidScore) {
                                if (config.scoreClippingThresh != null) {
                                    normalizedScore = tf.clipByValue(rawScoreTensor, -config.scoreClippingThresh, config.scoreClippingThresh);
                                }
                                normalizedScore = tf.sigmoid(normalizedScore);
                                return normalizedScore;
                            }
                            return normalizedScore;
                        });
                        return [4 /*yield*/, convertToDetections(boxes, normalizedScore, config)];
                    case 1:
                        outputDetections = _a.sent();
                        tf.dispose([boxes, normalizedScore]);
                        return [2 /*return*/, outputDetections];
                }
            });
        });
    }
    function convertToDetections(detectionBoxes, detectionScore, config) {
        return __awaiter(this, void 0, void 0, function () {
            var outputDetections, detectionBoxesData, detectionScoresData, i, boxOffset, detection, bbox, locationData, totalIdx, kpId, keypointIndex, keypoint;
            return __generator(this, function (_a) {
                switch (_a.label) {
                    case 0:
                        outputDetections = [];
                        return [4 /*yield*/, detectionBoxes.data()];
                    case 1:
                        detectionBoxesData = _a.sent();
                        return [4 /*yield*/, detectionScore.data()];
                    case 2:
                        detectionScoresData = _a.sent();
                        for (i = 0; i < config.numBoxes; ++i) {
                            if (config.minScoreThresh != null &&
                                detectionScoresData[i] < config.minScoreThresh) {
                                continue;
                            }
                            boxOffset = i * config.numCoords;
                            detection = convertToDetection(detectionBoxesData[boxOffset + 0] /* boxYMin */, detectionBoxesData[boxOffset + 1] /* boxXMin */, detectionBoxesData[boxOffset + 2] /* boxYMax */, detectionBoxesData[boxOffset + 3] /* boxXMax */, detectionScoresData[i], config.flipVertically, i);
                            bbox = detection.locationData.relativeBoundingBox;
                            if (bbox.width < 0 || bbox.height < 0) {
                                // Decoded detection boxes could have negative values for width/height
                                // due to model prediction. Filter out those boxes since some
                                // downstream calculators may assume non-negative values.
                                continue;
                            }
                            // Add keypoints.
                            if (config.numKeypoints > 0) {
                                locationData = detection.locationData;
                                locationData.relativeKeypoints = [];
                                totalIdx = config.numKeypoints * config.numValuesPerKeypoint;
                                for (kpId = 0; kpId < totalIdx; kpId += config.numValuesPerKeypoint) {
                                    keypointIndex = boxOffset + config.keypointCoordOffset + kpId;
                                    keypoint = {
                                        x: detectionBoxesData[keypointIndex + 0],
                                        y: config.flipVertically ? 1 - detectionBoxesData[keypointIndex + 1] :
                                            detectionBoxesData[keypointIndex + 1]
                                    };
                                    locationData.relativeKeypoints.push(keypoint);
                                }
                            }
                            outputDetections.push(detection);
                        }
                        return [2 /*return*/, outputDetections];
                }
            });
        });
    }
    function convertToDetection(boxYMin, boxXMin, boxYMax, boxXMax, score, flipVertically, i) {
        return {
            score: [score],
            ind: i,
            locationData: {
                relativeBoundingBox: {
                    xMin: boxXMin,
                    yMin: flipVertically ? 1 - boxYMax : boxYMin,
                    xMax: boxXMax,
                    yMax: flipVertically ? 1 - boxYMin : boxYMax,
                    width: boxXMax - boxXMin,
                    height: boxYMax - boxYMin
                }
            }
        };
    }
    //[xCenter, yCenter, w, h, kp1, kp2, kp3, kp4]
    //[yMin, xMin, yMax, xMax, kpX, kpY, kpX, kpY]
    function decodeBoxes(rawBoxes, anchor, config) {
        return tf.tidy(function () {
            var yCenter;
            var xCenter;
            var h;
            var w;
            if (config.reverseOutputOrder) {
                // Shape [numOfBoxes, 1].
                xCenter = tf.squeeze(tf.slice(rawBoxes, [0, config.boxCoordOffset + 0], [-1, 1]));
                yCenter = tf.squeeze(tf.slice(rawBoxes, [0, config.boxCoordOffset + 1], [-1, 1]));
                w = tf.squeeze(tf.slice(rawBoxes, [0, config.boxCoordOffset + 2], [-1, 1]));
                h = tf.squeeze(tf.slice(rawBoxes, [0, config.boxCoordOffset + 3], [-1, 1]));
            }
            else {
                yCenter = tf.squeeze(tf.slice(rawBoxes, [0, config.boxCoordOffset + 0], [-1, 1]));
                xCenter = tf.squeeze(tf.slice(rawBoxes, [0, config.boxCoordOffset + 1], [-1, 1]));
                h = tf.squeeze(tf.slice(rawBoxes, [0, config.boxCoordOffset + 2], [-1, 1]));
                w = tf.squeeze(tf.slice(rawBoxes, [0, config.boxCoordOffset + 3], [-1, 1]));
            }
            xCenter =
                tf.add(tf.mul(tf.div(xCenter, config.xScale), anchor.w), anchor.x);
            yCenter =
                tf.add(tf.mul(tf.div(yCenter, config.yScale), anchor.h), anchor.y);
            if (config.applyExponentialOnBoxSize) {
                h = tf.mul(tf.exp(tf.div(h, config.hScale)), anchor.h);
                w = tf.mul(tf.exp(tf.div(w, config.wScale)), anchor.w);
            }
            else {
                h = tf.mul(tf.div(h, config.hScale), anchor.h);
                w = tf.mul(tf.div(w, config.wScale), anchor.h);
            }
            var yMin = tf.sub(yCenter, tf.div(h, 2));
            var xMin = tf.sub(xCenter, tf.div(w, 2));
            var yMax = tf.add(yCenter, tf.div(h, 2));
            var xMax = tf.add(xCenter, tf.div(w, 2));
            // Shape [numOfBoxes, 4].
            var boxes = tf.concat([
                tf.reshape(yMin, [config.numBoxes, 1]),
                tf.reshape(xMin, [config.numBoxes, 1]),
                tf.reshape(yMax, [config.numBoxes, 1]),
                tf.reshape(xMax, [config.numBoxes, 1])
            ], 1);
            if (config.numKeypoints) {
                for (var k = 0; k < config.numKeypoints; ++k) {
                    var keypointOffset = config.keypointCoordOffset + k * config.numValuesPerKeypoint;
                    var keypointX = void 0;
                    var keypointY = void 0;
                    if (config.reverseOutputOrder) {
                        keypointX =
                            tf.squeeze(tf.slice(rawBoxes, [0, keypointOffset], [-1, 1]));
                        keypointY =
                            tf.squeeze(tf.slice(rawBoxes, [0, keypointOffset + 1], [-1, 1]));
                    }
                    else {
                        keypointY =
                            tf.squeeze(tf.slice(rawBoxes, [0, keypointOffset], [-1, 1]));
                        keypointX =
                            tf.squeeze(tf.slice(rawBoxes, [0, keypointOffset + 1], [-1, 1]));
                    }
                    var keypointXNormalized = tf.add(tf.mul(tf.div(keypointX, config.xScale), anchor.w), anchor.x);
                    var keypointYNormalized = tf.add(tf.mul(tf.div(keypointY, config.yScale), anchor.h), anchor.y);
                    boxes = tf.concat([
                        boxes, tf.reshape(keypointXNormalized, [config.numBoxes, 1]),
                        tf.reshape(keypointYNormalized, [config.numBoxes, 1])
                    ], 1);
                }
            }
            // Shape [numOfBoxes, 4] || [numOfBoxes, 12].
            return boxes;
        });
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * https://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function sigmoid(value) {
        return 1 / (1 + Math.exp(-value));
    }

    function applyActivation(activation, value) {
        return activation === 'none' ? value : sigmoid(value);
    }
    /**
     * A calculator for converting Tensors from regression models into landmarks.
     * Note that if the landmarks in the tensor has more than 5 dimensions, only the
     * first 5 dimensions will be converted to [x,y,z, visibility, presence]. The
     * latter two fields may also stay unset if such attributes are not supported in
     * the model.
     * @param landmarkTensor List of Tensors of type float32. Only the first tensor
     * will be used. The size of the values must be (num_dimension x num_landmarks).
     * @param flipHorizontally Optional. Whether to flip landmarks horizontally or
     * not. Overrides corresponding field in config.
     * @param flipVertically Optional. Whether to flip landmarks vertically or not.
     * Overrides corresponding field in config.
     *
     * @param config
     *
     * @returns Normalized landmarks.
     */
    function tensorsToLandmarks(landmarkTensor, config, flipHorizontally, flipVertically) {
        return __awaiter(this, void 0, void 0, function () {
            var numValues, numDimensions, rawLandmarks, outputLandmarks, ld, offset, landmark, i, landmark;
            return __generator(this, function (_a) {
                switch (_a.label) {
                    case 0:
                        flipHorizontally = flipHorizontally || config.flipHorizontally || false;
                        flipVertically = flipVertically || config.flipVertically || false;
                        numValues = landmarkTensor.size;
                        numDimensions = numValues / config.numLandmarks;
                        return [4 /*yield*/, landmarkTensor.data()];
                    case 1:
                        rawLandmarks = _a.sent();
                        outputLandmarks = [];
                        for (ld = 0; ld < config.numLandmarks; ++ld) {
                            offset = ld * numDimensions;
                            landmark = { x: 0, y: 0 };
                            if (flipHorizontally) {
                                landmark.x = config.inputImageWidth - rawLandmarks[offset];
                            }
                            else {
                                landmark.x = rawLandmarks[offset];
                            }
                            if (numDimensions > 1) {
                                if (flipVertically) {
                                    landmark.y = config.inputImageHeight - rawLandmarks[offset + 1];
                                }
                                else {
                                    landmark.y = rawLandmarks[offset + 1];
                                }
                            }
                            if (numDimensions > 2) {
                                landmark.z = rawLandmarks[offset + 2];
                            }
                            if (numDimensions > 3) {
                                landmark.score = applyActivation(config.visibilityActivation, rawLandmarks[offset + 3]);
                            }
                            // presence is in rawLandmarks[offset + 4], we don't expose it.
                            outputLandmarks.push(landmark);
                        }
                        for (i = 0; i < outputLandmarks.length; ++i) {
                            landmark = outputLandmarks[i];
                            landmark.x = landmark.x / config.inputImageWidth;
                            landmark.y = landmark.y / config.inputImageHeight;
                            // Scale Z coordinate as X + allow additional uniform normalization.
                            landmark.z = landmark.z / config.inputImageWidth / (config.normalizeZ || 1);
                        }
                        return [2 /*return*/, outputLandmarks];
                }
            });
        });
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * https://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    /**
     * Converts a tensor from a segmentation model to an image mask.
     * @param segmentationTensor Output from segmentation model of shape (1, height,
     *     width, channels).
     * @param config Contains activation to apply.
     * @param outputSize Desired dimensions of output image mask.
     *
     * @returns Image mask.
     */
    function tensorsToSegmentation(segmentationTensor, config, outputSize) {
        return tf.tidy(function () {
            // Remove batch dimension.
            var $segmentationTensor = 
            // tslint:disable-next-line: no-unnecessary-type-assertion
            tf.squeeze(segmentationTensor, [0]);
            var tensorChannels = $segmentationTensor.shape[2];
            // Process mask tensor and apply activation function.
            if (tensorChannels === 1) {
                // Create initial working mask.
                var smallMaskMat = $segmentationTensor;
                switch (config.activation) {
                    case 'none':
                        break;
                    case 'sigmoid':
                        smallMaskMat = tf.sigmoid(smallMaskMat);
                        break;
                    case 'softmax':
                        throw new Error('Softmax activation requires two channels.');
                    default:
                        throw new Error("Activation not supported (".concat(config.activation, ")"));
                }
                var outputMat = outputSize ?
                    tf.image.resizeBilinear(smallMaskMat, [outputSize.height, outputSize.width]) :
                    smallMaskMat;
                // Remove channel dimension.
                return tf.squeeze(outputMat, [2]);
            }
            else {
                throw new Error("Unsupported number of tensor channels ".concat(tensorChannels));
            }
        });
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * https://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    /**
     * Performs geometric transformation to the input normalized rectangle,
     * correpsonding to input normalized rectangle respectively.
     * @param rect The normalized rectangle.
     * @param imageSize The original imageSize.
     * @param config See documentation in `RectTransformationConfig`.
     */
    // ref:
    // https://github.com/google/mediapipe/blob/master/mediapipe/calculators/util/rect_transformation_calculator.cc
    function transformNormalizedRect(rect, imageSize, config) {
        var width = rect.width;
        var height = rect.height;
        var rotation = rect.rotation;
        if (config.rotation != null || config.rotationDegree != null) {
            rotation = computeNewRotation(rotation, config);
        }
        if (rotation === 0) {
            rect.xCenter = rect.xCenter + width * config.shiftX;
            rect.yCenter = rect.yCenter + height * config.shiftY;
        }
        else {
            var xShift = (imageSize.width * width * config.shiftX * Math.cos(rotation) -
                imageSize.height * height * config.shiftY * Math.sin(rotation)) /
                imageSize.width;
            var yShift = (imageSize.width * width * config.shiftX * Math.sin(rotation) +
                imageSize.height * height * config.shiftY * Math.cos(rotation)) /
                imageSize.height;
            rect.xCenter = rect.xCenter + xShift;
            rect.yCenter = rect.yCenter + yShift;
        }
        if (config.squareLong) {
            var longSide = Math.max(width * imageSize.width, height * imageSize.height);
            width = longSide / imageSize.width;
            height = longSide / imageSize.height;
        }
        else if (config.squareShort) {
            var shortSide = Math.min(width * imageSize.width, height * imageSize.height);
            width = shortSide / imageSize.width;
            height = shortSide / imageSize.height;
        }
        rect.width = width * config.scaleX;
        rect.height = height * config.scaleY;
        return rect;
    }
    function computeNewRotation(rotation, config) {
        if (config.rotation != null) {
            rotation += config.rotation;
        }
        else if (config.rotationDegree != null) {
            rotation += Math.PI * config.rotationDegree / 180;
        }
        return normalizeRadians(rotation);
    }

    /**
     * Estimate object scale to allow filter work similarly on nearer or futher
     * objects.
     * @param roi Normalized rectangle.
     * @param imageSize An object that contains width and height.
     * @returns A number representing the object scale.
     */
    function getObjectScale(roi, imageSize) {
        var objectWidth = roi.width * imageSize.width;
        var objectHeight = roi.height * imageSize.height;
        return (objectWidth + objectHeight) / 2;
    }

    function keypointsToNormalizedKeypoints(keypoints, imageSize) {
        return keypoints.map(function (keypoint) {
            var normalizedKeypoint = __assign(__assign({}, keypoint), { x: keypoint.x / imageSize.width, y: keypoint.y / imageSize.height });
            if (keypoint.z != null) {
                // Scale z the same way as x (using image width).
                keypoint.z = keypoint.z / imageSize.width;
            }
            return normalizedKeypoint;
        });
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * https://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    /**
     * A stateful filter that smoothes values overtime.
     *
     * More specifically, it stores the previous value, and when there's a new
     * value, a coefficient 'alpha' is applied to the new value, and `1 - alpha` is
     * applied to the previous value. The smaller the alpha is, the smoother result
     * and the bigger lag.
     */
    // ref:
    // https://github.com/google/mediapipe/blob/master/mediapipe/util/filtering/low_pass_filter.cc
    var LowPassFilter = /** @class */ (function () {
        function LowPassFilter(alpha) {
            this.alpha = alpha;
            this.initialized = false;
        }
        LowPassFilter.prototype.apply = function (value, threshold) {
            var result;
            if (this.initialized) {
                if (threshold == null) {
                    // Regular lowpass filter.
                    // result = this.alpha * value + (1 - this.alpha) * this.storedValue;
                    result = this.storedValue + this.alpha * (value - this.storedValue);
                }
                else {
                    // We need to reformat the formula to be able to conveniently apply
                    // another optional non-linear function to the
                    // (value - this.storedValue) part.
                    // Add additional non-linearity to cap extreme value.
                    // More specifically, assume x = (value - this.storedValue), when x is
                    // close zero, the derived x is close to x, when x is several magnitudes
                    // larger, the drived x grows much slower then x. It behaves like
                    // sign(x)log(abs(x)).
                    result = this.storedValue +
                        this.alpha * threshold *
                            Math.asinh((value - this.storedValue) / threshold);
                }
            }
            else {
                result = value;
                this.initialized = true;
            }
            this.rawValue = value;
            this.storedValue = result;
            return result;
        };
        LowPassFilter.prototype.applyWithAlpha = function (value, alpha, threshold) {
            this.alpha = alpha;
            return this.apply(value, threshold);
        };
        LowPassFilter.prototype.hasLastRawValue = function () {
            return this.initialized;
        };
        LowPassFilter.prototype.lastRawValue = function () {
            return this.rawValue;
        };
        LowPassFilter.prototype.reset = function () {
            this.initialized = false;
        };
        return LowPassFilter;
    }());

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * https://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    /**
     * OneEuroFilter.
     */
    // ref:
    // https://github.com/google/mediapipe/blob/master/mediapipe/util/filtering/one_euro_filter.cc
    // Also ref original paper:
    // https://cristal.univ-lille.fr/~casiez/1euro/
    var OneEuroFilter = /** @class */ (function () {
        /**
         * Constructor of `OneEuroFilter` class.
         * @param config See documentation of `OneEuroFilterConfig`.
         */
        function OneEuroFilter(config) {
            this.frequency = config.frequency;
            this.minCutOff = config.minCutOff;
            this.beta = config.beta;
            this.thresholdCutOff = config.thresholdCutOff;
            this.thresholdBeta = config.thresholdBeta;
            this.derivateCutOff = config.derivateCutOff;
            this.x = new LowPassFilter(this.getAlpha(this.minCutOff));
            this.dx = new LowPassFilter(this.getAlpha(this.derivateCutOff));
            this.lastTimestamp = 0;
        }
        /**
         * Applies filter to the value.
         * @param value valueToFilter.
         * @param microSeconds timestamp associated with the value (for instance,
         *     timestamp of the frame where you got value from).
         */
        OneEuroFilter.prototype.apply = function (value, microSeconds, valueScale) {
            if (value == null) {
                return value;
            }
            var $microSeconds = Math.trunc(microSeconds);
            if (this.lastTimestamp >= $microSeconds) {
                // Results are unpreditable in this case, so nothing to do but return
                // same value.
                return value;
            }
            // Update the sampling frequency based on timestamps.
            if (this.lastTimestamp !== 0 && $microSeconds !== 0) {
                this.frequency =
                    1 / (($microSeconds - this.lastTimestamp) * MICRO_SECONDS_TO_SECOND);
            }
            this.lastTimestamp = $microSeconds;
            // Estimate the current variation per second.
            var dValue = this.x.hasLastRawValue() ?
                (value - this.x.lastRawValue()) * valueScale * this.frequency :
                0;
            var edValue = this.dx.applyWithAlpha(dValue, this.getAlpha(this.derivateCutOff));
            var cutOff = this.minCutOff + this.beta * Math.abs(edValue);
            var threshold = this.thresholdCutOff != null ?
                this.thresholdCutOff + this.thresholdBeta * Math.abs(edValue) :
                null;
            // filter the given value.
            return this.x.applyWithAlpha(value, this.getAlpha(cutOff), threshold);
        };
        OneEuroFilter.prototype.getAlpha = function (cutoff) {
            // te = 1.0 / this.frequency
            // tau = 1.0 / (2 * Math.PI * cutoff)
            // result = 1 / (1.0 + (tau / te))
            return 1.0 / (1.0 + (this.frequency / (2 * Math.PI * cutoff)));
        };
        return OneEuroFilter;
    }());

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * https://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    /**
     * A stateful filter that smoothes keypoints values overtime.
     *
     * More specifically, it uses `OneEuroFilter` to smooth every x, y, z
     * coordinates over time, which as result gives us velocity of how these values
     * change over time. With higher velocity it weights new values higher.
     */
    // ref:
    // https://github.com/google/mediapipe/blob/master/mediapipe/calculators/util/landmarks_smoothing_calculator.cc
    var KeypointsOneEuroFilter = /** @class */ (function () {
        function KeypointsOneEuroFilter(config) {
            this.config = config;
        }
        KeypointsOneEuroFilter.prototype.apply = function (keypoints, microSeconds, objectScale) {
            var _this = this;
            if (keypoints == null) {
                this.reset();
                return null;
            }
            // Initialize filters once.
            this.initializeFiltersIfEmpty(keypoints);
            // Get value scale as inverse value of the object scale.
            // If value is too small smoothing will be disabled and keypoints will be
            // returned as is.
            var valueScale = 1;
            if (!this.config.disableValueScaling) {
                if (objectScale < this.config.minAllowedObjectScale) {
                    return __spreadArray([], keypoints, true);
                }
                valueScale = 1.0 / objectScale;
            }
            // Filter keypoints. Every axis of every keypoint is filtered separately.
            return keypoints.map(function (keypoint, i) {
                var outKeypoint = __assign(__assign({}, keypoint), { x: _this.xFilters[i].apply(keypoint.x, microSeconds, valueScale), y: _this.yFilters[i].apply(keypoint.y, microSeconds, valueScale) });
                if (keypoint.z != null) {
                    outKeypoint.z =
                        _this.zFilters[i].apply(keypoint.z, microSeconds, valueScale);
                }
                return outKeypoint;
            });
        };
        KeypointsOneEuroFilter.prototype.reset = function () {
            this.xFilters = null;
            this.yFilters = null;
            this.zFilters = null;
        };
        // Initializes filters for the first time or after reset. If initialized the
        // check the size.
        KeypointsOneEuroFilter.prototype.initializeFiltersIfEmpty = function (keypoints) {
            var _this = this;
            if (this.xFilters == null || this.xFilters.length !== keypoints.length) {
                this.xFilters = keypoints.map(function (_) { return new OneEuroFilter(_this.config); });
                this.yFilters = keypoints.map(function (_) { return new OneEuroFilter(_this.config); });
                this.zFilters = keypoints.map(function (_) { return new OneEuroFilter(_this.config); });
            }
        };
        return KeypointsOneEuroFilter;
    }());

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * https://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    /**
     * This filter keeps track (on a window of specified size) of value changes
     * over time, which as result gives us velocity of how value changes over time.
     * With higher velocity it weights new values higher.
     *
     * Use `windowSize` and `velocityScale` to tweak this filter for your use case.
     */
    // ref:
    // https://github.com/google/mediapipe/blob/master/mediapipe/util/filtering/relative_velocity_filter.cc
    var RelativeVelocityFilter = /** @class */ (function () {
        /**
         * Constructor of `RelativeVelocityFilter` class.
         * @param config
         *        `windowSize`:  Higher windowSize adds to lag and to stability.
         *        `velocityScale`: Lower velocityScale adds to lag and to stability.
         */
        function RelativeVelocityFilter(config) {
            this.config = config;
            this.window = [];
            this.lowPassFilter = new LowPassFilter(1.0);
            this.lastValue = 0;
            this.lastValueScale = 1;
            this.lastTimestamp = -1;
        }
        /**
         * Applies filter to the value.
         * @param value valueToFilter.
         * @param microSeconds timestamp associated with the value (for instance,
         *     timestamp of the frame where you got value from).
         * @param valueScale value scale (for instance, if your value is a distance
         *     detected on a frame, it can look same on different devices but have
         *     quite different absolute values due to different resolution, you
         *     should come up with an appropriate parameter for your particular use
         *     case).
         */
        RelativeVelocityFilter.prototype.apply = function (value, microSeconds, valueScale) {
            if (value == null) {
                return value;
            }
            var $microSeconds = Math.trunc(microSeconds);
            if (this.lastTimestamp >= $microSeconds) {
                // Results are unpreditable in this case, so nothing to do but return
                // same value.
                return value;
            }
            var alpha;
            if (this.lastTimestamp === -1) {
                alpha = 1;
            }
            else {
                // Implement the DistanceEstimationMode.kLegacyTransition.
                // TODO(lina128): Change to kForceCurrentScale or at least add an option
                // that can be tweaked with parameter.
                var distance = value * valueScale - this.lastValue * this.lastValueScale;
                var duration = $microSeconds - this.lastTimestamp;
                var cumulativeDistance = distance;
                var cumulativeDuration = duration;
                // Define max cumulative duration assuming 30 frames per second is a good
                // frame rate, so assuming 30 values per second or 1 / 30 of a second is
                // a good duration per window element.
                var assumedMaxDuration = SECOND_TO_MICRO_SECONDS / 30;
                var maxCumulativeDuration = (1 + this.window.length) * assumedMaxDuration;
                for (var _i = 0, _a = this.window; _i < _a.length; _i++) {
                    var el = _a[_i];
                    if (cumulativeDuration + el.duration > maxCumulativeDuration) {
                        // This helps in cases when durations are large and outdated
                        // window elements have bad impact on filtering results.
                        break;
                    }
                    cumulativeDistance += el.distance;
                    cumulativeDuration += el.duration;
                }
                var velocity = cumulativeDistance / (cumulativeDuration * MICRO_SECONDS_TO_SECOND);
                alpha = 1 - 1 / (1 + this.config.velocityScale * Math.abs(velocity));
                this.window.unshift({ distance: distance, duration: duration });
                if (this.window.length > this.config.windowSize) {
                    this.window.pop();
                }
            }
            this.lastValue = value;
            this.lastValueScale = valueScale;
            this.lastTimestamp = $microSeconds;
            return this.lowPassFilter.applyWithAlpha(value, alpha);
        };
        return RelativeVelocityFilter;
    }());

    /**
     * A stateful filter that smoothes landmark values overtime.
     *
     * More specifically, it uses `RelativeVelocityFilter` to smooth every x, y, z
     * coordinates over time, which as result gives us velocity of how these values
     * change over time. With higher velocity it weights new values higher.
     */
    // ref:
    // https://github.com/google/mediapipe/blob/master/mediapipe/calculators/util/landmarks_smoothing_calculator.cc
    var KeypointsVelocityFilter = /** @class */ (function () {
        function KeypointsVelocityFilter(config) {
            this.config = config;
        }
        KeypointsVelocityFilter.prototype.apply = function (keypoints, microSeconds, objectScale) {
            var _this = this;
            if (keypoints == null) {
                this.reset();
                return null;
            }
            // Get value scale as inverse value of the object scale.
            // If value is too small smoothing will be disabled and keypoints will be
            // returned as is.
            var valueScale = 1;
            if (!this.config.disableValueScaling) {
                if (objectScale < this.config.minAllowedObjectScale) {
                    return __spreadArray([], keypoints, true);
                }
                valueScale = 1 / objectScale;
            }
            // Initialize filters once.
            this.initializeFiltersIfEmpty(keypoints);
            // Filter keypoints. Every axis of every keypoint is filtered separately.
            return keypoints.map(function (keypoint, i) {
                var outKeypoint = __assign(__assign({}, keypoint), { x: _this.xFilters[i].apply(keypoint.x, microSeconds, valueScale), y: _this.yFilters[i].apply(keypoint.y, microSeconds, valueScale) });
                if (keypoint.z != null) {
                    outKeypoint.z =
                        _this.zFilters[i].apply(keypoint.z, microSeconds, valueScale);
                }
                return outKeypoint;
            });
        };
        KeypointsVelocityFilter.prototype.reset = function () {
            this.xFilters = null;
            this.yFilters = null;
            this.zFilters = null;
        };
        // Initializes filters for the first time or after reset. If initialized the
        // check the size.
        KeypointsVelocityFilter.prototype.initializeFiltersIfEmpty = function (keypoints) {
            var _this = this;
            if (this.xFilters == null || this.xFilters.length !== keypoints.length) {
                this.xFilters =
                    keypoints.map(function (_) { return new RelativeVelocityFilter(_this.config); });
                this.yFilters =
                    keypoints.map(function (_) { return new RelativeVelocityFilter(_this.config); });
                this.zFilters =
                    keypoints.map(function (_) { return new RelativeVelocityFilter(_this.config); });
            }
        };
        return KeypointsVelocityFilter;
    }());

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * https://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    /**
     * A Calculator to smooth keypoints over time.
     */
    var KeypointsSmoothingFilter = /** @class */ (function () {
        function KeypointsSmoothingFilter(config) {
            if (config.velocityFilter != null) {
                this.keypointsFilter = new KeypointsVelocityFilter(config.velocityFilter);
            }
            else if (config.oneEuroFilter != null) {
                this.keypointsFilter = new KeypointsOneEuroFilter(config.oneEuroFilter);
            }
            else {
                throw new Error('Either configure velocityFilter or oneEuroFilter, but got ' +
                    "".concat(config, "."));
            }
        }
        /**
         * Apply one of the stateful `KeypointsFilter` to keypoints.
         *
         * Currently supports `OneEuroFilter` and `VelocityFilter`.
         * @param keypoints A list of 2D or 3D keypoints, can be normalized or
         *     non-normalized.
         * @param timestamp The timestamp of the video frame.
         * @param imageSize Optional. The imageSize is useful when keypoints are
         *     normalized.
         * @param normalized Optional. Whether the keypoints are normalized. Default
         *     to false.
         * @param objectScaleROI Optional. The auxiliary ROI to calculate object
         *     scale. If not set, objectScale defaults to 1.
         */
        KeypointsSmoothingFilter.prototype.apply = function (keypoints, timestamp, imageSize, normalized, objectScaleROI) {
            if (normalized === void 0) { normalized = false; }
            if (keypoints == null) {
                this.keypointsFilter.reset();
                return null;
            }
            var objectScale = objectScaleROI != null ? getObjectScale(objectScaleROI, imageSize) : 1;
            var scaledKeypoints = normalized ?
                normalizedKeypointsToKeypoints(keypoints, imageSize) :
                keypoints;
            var scaledKeypointsFiltered = this.keypointsFilter.apply(scaledKeypoints, timestamp, objectScale);
            return normalized ?
                keypointsToNormalizedKeypoints(scaledKeypointsFiltered, imageSize) :
                scaledKeypointsFiltered;
        };
        return KeypointsSmoothingFilter;
    }());

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * https://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    /**
     * Smoothing visibility using a `LowPassFilter` for each landmark.
     */
    var LowPassVisibilityFilter = /** @class */ (function () {
        function LowPassVisibilityFilter(config) {
            this.alpha = config.alpha;
        }
        LowPassVisibilityFilter.prototype.apply = function (landmarks) {
            var _this = this;
            if (landmarks == null) {
                // Reset filters.
                this.visibilityFilters = null;
                return null;
            }
            if (this.visibilityFilters == null ||
                (this.visibilityFilters.length !== landmarks.length)) {
                // Initialize new filters.
                this.visibilityFilters =
                    landmarks.map(function (_) { return new LowPassFilter(_this.alpha); });
            }
            var outLandmarks = [];
            // Filter visibilities.
            for (var i = 0; i < landmarks.length; ++i) {
                var landmark = landmarks[i];
                var outLandmark = __assign({}, landmark);
                outLandmark.score = this.visibilityFilters[i].apply(landmark.score);
                outLandmarks.push(outLandmark);
            }
            return outLandmarks;
        };
        return LowPassVisibilityFilter;
    }());

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * https://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    var DEFAULT_BLAZEPOSE_DETECTOR_MODEL_URL = 'https://tfhub.dev/mediapipe/tfjs-model/blazepose_3d/detector/1';
    var DEFAULT_BLAZEPOSE_LANDMARK_MODEL_URL_FULL = 'https://tfhub.dev/mediapipe/tfjs-model/blazepose_3d/landmark/full/2';
    var DEFAULT_BLAZEPOSE_LANDMARK_MODEL_URL_LITE = 'https://tfhub.dev/mediapipe/tfjs-model/blazepose_3d/landmark/lite/2';
    var DEFAULT_BLAZEPOSE_LANDMARK_MODEL_URL_HEAVY = 'https://tfhub.dev/mediapipe/tfjs-model/blazepose_3d/landmark/heavy/2';
    var BLAZEPOSE_DETECTOR_ANCHOR_CONFIGURATION = {
        reduceBoxesInLowestlayer: false,
        interpolatedScaleAspectRatio: 1.0,
        featureMapHeight: [],
        featureMapWidth: [],
        numLayers: 5,
        minScale: 0.1484375,
        maxScale: 0.75,
        inputSizeHeight: 224,
        inputSizeWidth: 224,
        anchorOffsetX: 0.5,
        anchorOffsetY: 0.5,
        strides: [8, 16, 32, 32, 32],
        aspectRatios: [1.0],
        fixedAnchorSize: true
    };
    var DEFAULT_BLAZEPOSE_MODEL_CONFIG$1 = {
        runtime: 'tfjs',
        modelType: 'full',
        enableSmoothing: true,
        enableSegmentation: false,
        smoothSegmentation: true,
        detectorModelUrl: DEFAULT_BLAZEPOSE_DETECTOR_MODEL_URL,
        landmarkModelUrl: DEFAULT_BLAZEPOSE_LANDMARK_MODEL_URL_FULL
    };
    var DEFAULT_BLAZEPOSE_ESTIMATION_CONFIG = {
        maxPoses: 1,
        flipHorizontal: false
    };
    var BLAZEPOSE_TENSORS_TO_DETECTION_CONFIGURATION = {
        applyExponentialOnBoxSize: false,
        flipVertically: false,
        ignoreClasses: [],
        numClasses: 1,
        numBoxes: 2254,
        numCoords: 12,
        boxCoordOffset: 0,
        keypointCoordOffset: 4,
        numKeypoints: 4,
        numValuesPerKeypoint: 2,
        sigmoidScore: true,
        scoreClippingThresh: 100.0,
        reverseOutputOrder: true,
        xScale: 224.0,
        yScale: 224.0,
        hScale: 224.0,
        wScale: 224.0,
        minScoreThresh: 0.5
    };
    var BLAZEPOSE_DETECTOR_NON_MAX_SUPPRESSION_CONFIGURATION = {
        minSuppressionThreshold: 0.3,
        overlapType: 'intersection-over-union'
    };
    var BLAZEPOSE_DETECTOR_RECT_TRANSFORMATION_CONFIG = {
        shiftX: 0,
        shiftY: 0,
        scaleX: 1.25,
        scaleY: 1.25,
        squareLong: true
    };
    var BLAZEPOSE_DETECTOR_IMAGE_TO_TENSOR_CONFIG = {
        outputTensorSize: { width: 224, height: 224 },
        keepAspectRatio: true,
        outputTensorFloatRange: [-1, 1],
        borderMode: 'zero'
    };
    var BLAZEPOSE_LANDMARK_IMAGE_TO_TENSOR_CONFIG = {
        outputTensorSize: { width: 256, height: 256 },
        keepAspectRatio: true,
        outputTensorFloatRange: [0, 1],
        borderMode: 'zero'
    };
    var BLAZEPOSE_POSE_PRESENCE_SCORE = 0.5;
    var BLAZEPOSE_TENSORS_TO_LANDMARKS_CONFIG = {
        numLandmarks: 39,
        inputImageWidth: 256,
        inputImageHeight: 256,
        visibilityActivation: 'sigmoid',
        flipHorizontally: false,
        flipVertically: false
    };
    var BLAZEPOSE_TENSORS_TO_WORLD_LANDMARKS_CONFIG = {
        numLandmarks: 39,
        inputImageWidth: 1,
        inputImageHeight: 1,
        visibilityActivation: 'sigmoid',
        flipHorizontally: false,
        flipVertically: false
    };
    var BLAZEPOSE_REFINE_LANDMARKS_FROM_HEATMAP_CONFIG = {
        kernelSize: 7,
        minConfidenceToRefine: 0.5
    };
    var BLAZEPOSE_NUM_KEYPOINTS = 33;
    var BLAZEPOSE_NUM_AUXILIARY_KEYPOINTS = 35;
    var BLAZEPOSE_VISIBILITY_SMOOTHING_CONFIG = {
        alpha: 0.1
    };
    var BLAZEPOSE_LANDMARKS_SMOOTHING_CONFIG_ACTUAL = {
        oneEuroFilter: {
            frequency: 30,
            minCutOff: 0.05,
            // filter when landmark is static.
            beta: 80,
            // alpha in landmark EMA filter when landmark is moving fast.
            derivateCutOff: 1.0,
            // landmark velocity EMA filter.,
            minAllowedObjectScale: 1e-6
        }
    };
    // Auxiliary landmarks are smoothed heavier than main landmarks to make ROI
    // crop for pose landmarks prediction very stable when object is not moving but
    // responsive enough in case of sudden movements.
    var BLAZEPOSE_LANDMARKS_SMOOTHING_CONFIG_AUXILIARY = {
        oneEuroFilter: {
            frequency: 30,
            minCutOff: 0.01,
            // EMA filter when landmark is static.
            beta: 10.0,
            // ~0.68 alpha in landmark EMA filter when landmark is moving
            // fast.
            derivateCutOff: 1.0,
            // landmark velocity EMA filter.
            minAllowedObjectScale: 1e-6
        }
    };
    var BLAZEPOSE_WORLD_LANDMARKS_SMOOTHING_CONFIG_ACTUAL = {
        oneEuroFilter: {
            frequency: 30,
            minCutOff: 0.1,
            // filter when landmark is static.
            beta: 40,
            // alpha in landmark EMA filter when landmark is moving fast.
            derivateCutOff: 1.0,
            // landmark velocity EMA filter.
            minAllowedObjectScale: 1e-6,
            disableValueScaling: true // As world landmarks are predicted in real world 3D coordintates
            // in meters (rather than in pixels of input image) prediction
            // scale does not depend on the pose size in the image.
        }
    };
    var BLAZEPOSE_TENSORS_TO_SEGMENTATION_CONFIG = {
        activation: 'none', // Sigmoid is not needed since it is already part of the model.
    };
    var BLAZEPOSE_SEGMENTATION_SMOOTHING_CONFIG = {
        combineWithPreviousRatio: 0.7
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * https://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function validateModelConfig$1(modelConfig) {
        var config = modelConfig == null ?
            __assign({}, DEFAULT_BLAZEPOSE_MODEL_CONFIG$1) : __assign({}, modelConfig);
        if (config.enableSmoothing == null) {
            config.enableSmoothing = DEFAULT_BLAZEPOSE_MODEL_CONFIG$1.enableSmoothing;
        }
        if (config.enableSegmentation == null) {
            config.enableSegmentation =
                DEFAULT_BLAZEPOSE_MODEL_CONFIG$1.enableSegmentation;
        }
        if (config.smoothSegmentation == null) {
            config.smoothSegmentation =
                DEFAULT_BLAZEPOSE_MODEL_CONFIG$1.smoothSegmentation;
        }
        if (config.modelType == null) {
            config.modelType = DEFAULT_BLAZEPOSE_MODEL_CONFIG$1.modelType;
        }
        if (config.detectorModelUrl == null) {
            config.detectorModelUrl = DEFAULT_BLAZEPOSE_MODEL_CONFIG$1.detectorModelUrl;
        }
        if (config.landmarkModelUrl == null) {
            switch (config.modelType) {
                case 'lite':
                    config.landmarkModelUrl = DEFAULT_BLAZEPOSE_LANDMARK_MODEL_URL_LITE;
                    break;
                case 'heavy':
                    config.landmarkModelUrl = DEFAULT_BLAZEPOSE_LANDMARK_MODEL_URL_HEAVY;
                    break;
                case 'full':
                default:
                    config.landmarkModelUrl = DEFAULT_BLAZEPOSE_LANDMARK_MODEL_URL_FULL;
                    break;
            }
        }
        return config;
    }
    function validateEstimationConfig(estimationConfig) {
        var config;
        if (estimationConfig == null) {
            config = DEFAULT_BLAZEPOSE_ESTIMATION_CONFIG;
        }
        else {
            config = __assign({}, estimationConfig);
        }
        if (config.maxPoses == null) {
            config.maxPoses = 1;
        }
        if (config.maxPoses <= 0) {
            throw new Error("Invalid maxPoses ".concat(config.maxPoses, ". Should be > 0."));
        }
        if (config.maxPoses > 1) {
            throw new Error('Multi-pose detection is not implemented yet. Please set maxPoses ' +
                'to 1.');
        }
        return config;
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * https://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    var BlazePoseTfjsMask = /** @class */ (function () {
        function BlazePoseTfjsMask(mask) {
            this.mask = mask;
        }
        BlazePoseTfjsMask.prototype.toCanvasImageSource = function () {
            return __awaiter(this, void 0, void 0, function () {
                return __generator(this, function (_a) {
                    return [2 /*return*/, toHTMLCanvasElementLossy(this.mask)];
                });
            });
        };
        BlazePoseTfjsMask.prototype.toImageData = function () {
            return __awaiter(this, void 0, void 0, function () {
                return __generator(this, function (_a) {
                    return [2 /*return*/, toImageDataLossy(this.mask)];
                });
            });
        };
        BlazePoseTfjsMask.prototype.toTensor = function () {
            return __awaiter(this, void 0, void 0, function () {
                return __generator(this, function (_a) {
                    return [2 /*return*/, this.mask];
                });
            });
        };
        BlazePoseTfjsMask.prototype.getUnderlyingType = function () {
            return 'tensor';
        };
        return BlazePoseTfjsMask;
    }());
    function maskValueToLabel$1(maskValue) {
        assertMaskValue(maskValue);
        return 'person';
    }
    /**
     * BlazePose detector class.
     */
    var BlazePoseTfjsDetector = /** @class */ (function () {
        function BlazePoseTfjsDetector(detectorModel, landmarkModel, enableSmoothing, enableSegmentation, smoothSegmentation, modelType) {
            this.detectorModel = detectorModel;
            this.landmarkModel = landmarkModel;
            this.enableSmoothing = enableSmoothing;
            this.enableSegmentation = enableSegmentation;
            this.smoothSegmentation = smoothSegmentation;
            this.modelType = modelType;
            // Store global states.
            this.regionOfInterest = null;
            this.prevFilteredSegmentationMask = null;
            this.anchors =
                createSsdAnchors(BLAZEPOSE_DETECTOR_ANCHOR_CONFIGURATION);
            var anchorW = tf.tensor1d(this.anchors.map(function (a) { return a.width; }));
            var anchorH = tf.tensor1d(this.anchors.map(function (a) { return a.height; }));
            var anchorX = tf.tensor1d(this.anchors.map(function (a) { return a.xCenter; }));
            var anchorY = tf.tensor1d(this.anchors.map(function (a) { return a.yCenter; }));
            this.anchorTensor = { x: anchorX, y: anchorY, w: anchorW, h: anchorH };
            this.prevFilteredSegmentationMask =
                this.enableSegmentation ? tf.tensor2d([], [0, 0]) : null;
        }
        /**
         * Estimates poses for an image or video frame.
         *
         * It returns a single pose or multiple poses based on the maxPose parameter
         * from the `config`.
         *
         * @param image
         * ImageData|HTMLImageElement|HTMLCanvasElement|HTMLVideoElement The input
         * image to feed through the network.
         *
         * @param estimationConfig Optional. See `BlazePoseTfjsEstimationConfig`
         *       documentation for detail.
         *
         * @param timestamp Optional. In milliseconds. This is useful when image is
         *     a tensor, which doesn't have timestamp info. Or to override timestamp
         *     in a video.
         *
         * @return An array of `Pose`s.
         */
        // TF.js implementation of the mediapipe pose detection pipeline.
        // ref graph:
        // https://github.com/google/mediapipe/blob/master/mediapipe/modules/pose_landmark/pose_landmark_cpu.pbtxt
        BlazePoseTfjsDetector.prototype.estimatePoses = function (image, estimationConfig, timestamp) {
            return __awaiter(this, void 0, void 0, function () {
                var config, imageSize, image3d, poseRect, detections, firstDetection, poseLandmarksByRoiResult, unfilteredPoseLandmarks, unfilteredAuxiliaryLandmarks, poseScore, unfilteredWorldLandmarks, unfilteredSegmentationMask, _a, poseLandmarks, auxiliaryLandmarks, poseWorldLandmarks, poseRectFromLandmarks, filteredSegmentationMask, keypoints, keypoints3D, pose, rgbaMask, segmentation;
                return __generator(this, function (_b) {
                    switch (_b.label) {
                        case 0:
                            config = validateEstimationConfig(estimationConfig);
                            if (image == null) {
                                this.reset();
                                return [2 /*return*/, []];
                            }
                            this.maxPoses = config.maxPoses;
                            // User provided timestamp will override video's timestamp.
                            if (timestamp != null) {
                                this.timestamp = timestamp * MILLISECOND_TO_MICRO_SECONDS;
                            }
                            else {
                                // For static images, timestamp should be null.
                                this.timestamp =
                                    isVideo(image) ? image.currentTime * SECOND_TO_MICRO_SECONDS : null;
                            }
                            imageSize = getImageSize(image);
                            image3d = tf.tidy(function () { return tf.cast(toImageTensor(image), 'float32'); });
                            poseRect = this.regionOfInterest;
                            if (!(poseRect == null)) return [3 /*break*/, 2];
                            return [4 /*yield*/, this.detectPose(image3d)];
                        case 1:
                            detections = _b.sent();
                            if (detections.length === 0) {
                                this.reset();
                                image3d.dispose();
                                return [2 /*return*/, []];
                            }
                            firstDetection = detections[0];
                            // Calculates region of interest based on pose detection, so that can be
                            // used to detect landmarks.
                            poseRect = this.poseDetectionToRoi(firstDetection, imageSize);
                            _b.label = 2;
                        case 2: return [4 /*yield*/, this.poseLandmarksByRoi(poseRect, image3d)];
                        case 3:
                            poseLandmarksByRoiResult = _b.sent();
                            image3d.dispose();
                            if (poseLandmarksByRoiResult == null) {
                                this.reset();
                                return [2 /*return*/, []];
                            }
                            unfilteredPoseLandmarks = poseLandmarksByRoiResult.landmarks, unfilteredAuxiliaryLandmarks = poseLandmarksByRoiResult.auxiliaryLandmarks, poseScore = poseLandmarksByRoiResult.poseScore, unfilteredWorldLandmarks = poseLandmarksByRoiResult.worldLandmarks, unfilteredSegmentationMask = poseLandmarksByRoiResult.segmentationMask;
                            _a = this.poseLandmarkFiltering(unfilteredPoseLandmarks, unfilteredAuxiliaryLandmarks, unfilteredWorldLandmarks, imageSize), poseLandmarks = _a.actualLandmarksFiltered, auxiliaryLandmarks = _a.auxiliaryLandmarksFiltered, poseWorldLandmarks = _a.actualWorldLandmarksFiltered;
                            poseRectFromLandmarks = this.poseLandmarksToRoi(auxiliaryLandmarks, imageSize);
                            // Cache roi for next image.
                            this.regionOfInterest = poseRectFromLandmarks;
                            filteredSegmentationMask = this.smoothSegmentation && unfilteredSegmentationMask != null ?
                                this.poseSegmentationFiltering(unfilteredSegmentationMask) :
                                unfilteredSegmentationMask;
                            keypoints = poseLandmarks != null ?
                                normalizedKeypointsToKeypoints(poseLandmarks, imageSize) :
                                null;
                            // Add keypoint name.
                            if (keypoints != null) {
                                keypoints.forEach(function (keypoint, i) {
                                    keypoint.name = BLAZEPOSE_KEYPOINTS[i];
                                });
                            }
                            keypoints3D = poseWorldLandmarks;
                            // Add keypoint name.
                            if (keypoints3D != null) {
                                keypoints3D.forEach(function (keypoint3D, i) {
                                    keypoint3D.name = BLAZEPOSE_KEYPOINTS[i];
                                });
                            }
                            pose = { score: poseScore, keypoints: keypoints, keypoints3D: keypoints3D };
                            if (filteredSegmentationMask !== null) {
                                rgbaMask = tf.tidy(function () {
                                    var mask3D = 
                                    // tslint:disable-next-line: no-unnecessary-type-assertion
                                    tf.expandDims(filteredSegmentationMask, 2);
                                    // Pads a pixel [r] to [r, 0].
                                    var rgMask = tf.pad(mask3D, [[0, 0], [0, 0], [0, 1]]);
                                    // Pads a pixel [r, 0] to [r, 0, 0, r].
                                    return tf.mirrorPad(rgMask, [[0, 0], [0, 0], [0, 2]], 'symmetric');
                                });
                                if (!this.smoothSegmentation) {
                                    tf.dispose(filteredSegmentationMask);
                                }
                                segmentation = {
                                    maskValueToLabel: maskValueToLabel$1,
                                    mask: new BlazePoseTfjsMask(rgbaMask)
                                };
                                pose.segmentation = segmentation;
                            }
                            return [2 /*return*/, [pose]];
                    }
                });
            });
        };
        BlazePoseTfjsDetector.prototype.poseSegmentationFiltering = function (segmentationMask) {
            var prevMask = this.prevFilteredSegmentationMask;
            if (prevMask.size === 0) {
                this.prevFilteredSegmentationMask = segmentationMask;
            }
            else {
                this.prevFilteredSegmentationMask = smoothSegmentation(prevMask, segmentationMask, BLAZEPOSE_SEGMENTATION_SMOOTHING_CONFIG);
                tf.dispose(segmentationMask);
            }
            tf.dispose(prevMask);
            return this.prevFilteredSegmentationMask;
        };
        BlazePoseTfjsDetector.prototype.dispose = function () {
            this.detectorModel.dispose();
            this.landmarkModel.dispose();
            tf.dispose([
                this.anchorTensor.x, this.anchorTensor.y, this.anchorTensor.w,
                this.anchorTensor.h, this.prevFilteredSegmentationMask
            ]);
        };
        BlazePoseTfjsDetector.prototype.reset = function () {
            this.regionOfInterest = null;
            if (this.enableSegmentation) {
                tf.dispose(this.prevFilteredSegmentationMask);
                this.prevFilteredSegmentationMask = tf.tensor2d([], [0, 0]);
            }
            this.visibilitySmoothingFilterActual = null;
            this.visibilitySmoothingFilterAuxiliary = null;
            this.landmarksSmoothingFilterActual = null;
            this.landmarksSmoothingFilterAuxiliary = null;
        };
        // Detects poses.
        // Subgraph: PoseDetectionCpu.
        // ref:
        // https://github.com/google/mediapipe/blob/master/mediapipe/modules/pose_detection/pose_detection_cpu.pbtxt
        BlazePoseTfjsDetector.prototype.detectPose = function (image) {
            return __awaiter(this, void 0, void 0, function () {
                var _a, imageValueShifted, padding, detectionResult, _b, boxes, logits, detections, selectedDetections, newDetections;
                return __generator(this, function (_c) {
                    switch (_c.label) {
                        case 0:
                            _a = convertImageToTensor(image, BLAZEPOSE_DETECTOR_IMAGE_TO_TENSOR_CONFIG), imageValueShifted = _a.imageTensor, padding = _a.padding;
                            detectionResult = this.detectorModel.predict(imageValueShifted);
                            _b = detectorResult(detectionResult), boxes = _b.boxes, logits = _b.logits;
                            return [4 /*yield*/, tensorsToDetections([logits, boxes], this.anchorTensor, BLAZEPOSE_TENSORS_TO_DETECTION_CONFIGURATION)];
                        case 1:
                            detections = _c.sent();
                            if (detections.length === 0) {
                                tf.dispose([imageValueShifted, detectionResult, logits, boxes]);
                                return [2 /*return*/, detections];
                            }
                            return [4 /*yield*/, nonMaxSuppression(detections, this.maxPoses, BLAZEPOSE_DETECTOR_NON_MAX_SUPPRESSION_CONFIGURATION
                                    .minSuppressionThreshold)];
                        case 2:
                            selectedDetections = _c.sent();
                            newDetections = removeDetectionLetterbox(selectedDetections, padding);
                            tf.dispose([imageValueShifted, detectionResult, logits, boxes]);
                            return [2 /*return*/, newDetections];
                    }
                });
            });
        };
        // Calculates region of interest from a detection.
        // Subgraph: PoseDetectionToRoi.
        // ref:
        // https://github.com/google/mediapipe/blob/master/mediapipe/modules/pose_landmark/pose_detection_to_roi.pbtxt
        // If detection is not null, imageSize should not be null either.
        BlazePoseTfjsDetector.prototype.poseDetectionToRoi = function (detection, imageSize) {
            var startKeypointIndex;
            var endKeypointIndex;
            // Converts pose detection into a rectangle based on center and scale
            // alignment points.
            startKeypointIndex = 0;
            endKeypointIndex = 1;
            // PoseDetectionToRoi: AlignmentPointsRectsCalculator.
            var rawRoi = calculateAlignmentPointsRects(detection, imageSize, {
                rotationVectorEndKeypointIndex: endKeypointIndex,
                rotationVectorStartKeypointIndex: startKeypointIndex,
                rotationVectorTargetAngleDegree: 90
            });
            // Expands pose rect with marging used during training.
            // PoseDetectionToRoi: RectTransformationCalculation.
            var roi = transformNormalizedRect(rawRoi, imageSize, BLAZEPOSE_DETECTOR_RECT_TRANSFORMATION_CONFIG);
            return roi;
        };
        // Predict pose landmarks  and optionally segmentation within an ROI
        // subgraph: PoseLandmarksByRoiCpu
        // ref:
        // https://github.com/google/mediapipe/blob/master/mediapipe/modules/pose_landmark/pose_landmark_by_roi_cpu.pbtxt
        // When poseRect is not null, image should not be null either.
        BlazePoseTfjsDetector.prototype.poseLandmarksByRoi = function (roi, image) {
            return __awaiter(this, void 0, void 0, function () {
                var imageSize, _a, imageValueShifted, letterboxPadding, transformationMatrix, outputs, outputTensor, tensorsToPoseLandmarksAndSegmentationResult, roiLandmarks, roiAuxiliaryLandmarks, poseScore, roiWorldLandmarks, roiSegmentationMask, poseLandmarksAndSegmentationInverseProjectionResults;
                return __generator(this, function (_b) {
                    switch (_b.label) {
                        case 0:
                            imageSize = getImageSize(image);
                            _a = convertImageToTensor(image, BLAZEPOSE_LANDMARK_IMAGE_TO_TENSOR_CONFIG, roi), imageValueShifted = _a.imageTensor, letterboxPadding = _a.padding, transformationMatrix = _a.transformationMatrix;
                            if (this.modelType !== 'lite' && this.modelType !== 'full' &&
                                this.modelType !== 'heavy') {
                                throw new Error('Model type must be one of lite, full or heavy,' +
                                    "but got ".concat(this.modelType));
                            }
                            outputs = ['ld_3d', 'output_poseflag', 'activation_heatmap', 'world_3d'];
                            if (this.enableSegmentation) {
                                outputs.push('activation_segmentation');
                            }
                            outputTensor = this.landmarkModel.execute(imageValueShifted, outputs);
                            return [4 /*yield*/, this.tensorsToPoseLandmarksAndSegmentation(outputTensor)];
                        case 1:
                            tensorsToPoseLandmarksAndSegmentationResult = _b.sent();
                            if (tensorsToPoseLandmarksAndSegmentationResult == null) {
                                tf.dispose(outputTensor);
                                tf.dispose(imageValueShifted);
                                return [2 /*return*/, null];
                            }
                            roiLandmarks = tensorsToPoseLandmarksAndSegmentationResult.landmarks, roiAuxiliaryLandmarks = tensorsToPoseLandmarksAndSegmentationResult.auxiliaryLandmarks, poseScore = tensorsToPoseLandmarksAndSegmentationResult.poseScore, roiWorldLandmarks = tensorsToPoseLandmarksAndSegmentationResult.worldLandmarks, roiSegmentationMask = tensorsToPoseLandmarksAndSegmentationResult.segmentationMask;
                            return [4 /*yield*/, this.poseLandmarksAndSegmentationInverseProjection(imageSize, roi, letterboxPadding, transformationMatrix, roiLandmarks, roiAuxiliaryLandmarks, roiWorldLandmarks, roiSegmentationMask)];
                        case 2:
                            poseLandmarksAndSegmentationInverseProjectionResults = _b.sent();
                            tf.dispose(outputTensor);
                            tf.dispose(imageValueShifted);
                            return [2 /*return*/, __assign({ poseScore: poseScore }, poseLandmarksAndSegmentationInverseProjectionResults)];
                    }
                });
            });
        };
        BlazePoseTfjsDetector.prototype.poseLandmarksAndSegmentationInverseProjection = function (imageSize, roi, letterboxPadding, transformationMatrix, roiLandmarks, roiAuxiliaryLandmarks, roiWorldLandmarks, roiSegmentationMask) {
            return __awaiter(this, void 0, void 0, function () {
                var adjustedLandmarks, adjustedAuxiliaryLandmarks, landmarks, auxiliaryLandmarks, worldLandmarks, segmentationMask;
                return __generator(this, function (_a) {
                    adjustedLandmarks = removeLandmarkLetterbox(roiLandmarks, letterboxPadding);
                    adjustedAuxiliaryLandmarks = removeLandmarkLetterbox(roiAuxiliaryLandmarks, letterboxPadding);
                    landmarks = calculateLandmarkProjection(adjustedLandmarks, roi);
                    auxiliaryLandmarks = calculateLandmarkProjection(adjustedAuxiliaryLandmarks, roi);
                    worldLandmarks = calculateWorldLandmarkProjection(roiWorldLandmarks, roi);
                    segmentationMask = null;
                    if (this.enableSegmentation) {
                        segmentationMask = tf.tidy(function () {
                            var _a = roiSegmentationMask.shape, inputHeight = _a[0], inputWidth = _a[1];
                            // Calculates the inverse transformation matrix.
                            // PoseLandmarksAndSegmentationInverseProjection:
                            // InverseMatrixCalculator.
                            var inverseTransformationMatrix = calculateInverseMatrix(transformationMatrix);
                            var projectiveTransform = tf.tensor2d(getProjectiveTransformMatrix(inverseTransformationMatrix, { width: inputWidth, height: inputHeight }, imageSize), [1, 8]);
                            // Projects the segmentation mask from the letterboxed ROI back to the
                            // full image.
                            // PoseLandmarksAndSegmentationInverseProjection: WarpAffineCalculator.
                            var shape4D = [1, inputHeight, inputWidth, 1];
                            return tf.squeeze(tf.image.transform(tf.reshape(roiSegmentationMask, shape4D), projectiveTransform, 'bilinear', 'constant', 0, [imageSize.height, imageSize.width]), [0, 3]);
                        });
                        tf.dispose(roiSegmentationMask);
                    }
                    return [2 /*return*/, { landmarks: landmarks, auxiliaryLandmarks: auxiliaryLandmarks, worldLandmarks: worldLandmarks, segmentationMask: segmentationMask }];
                });
            });
        };
        BlazePoseTfjsDetector.prototype.tensorsToPoseLandmarksAndSegmentation = function (tensors) {
            return __awaiter(this, void 0, void 0, function () {
                var landmarkTensor, poseFlagTensor, heatmapTensor, worldLandmarkTensor, segmentationTensor, poseScore, rawLandmarks, allLandmarks, landmarks, auxiliaryLandmarks, allWorldLandmarks, worldLandmarksWithoutVisibility, worldLandmarks, segmentationMask;
                return __generator(this, function (_a) {
                    switch (_a.label) {
                        case 0:
                            landmarkTensor = tensors[0], poseFlagTensor = tensors[1], heatmapTensor = tensors[2], worldLandmarkTensor = tensors[3], segmentationTensor = (this.enableSegmentation ? tensors[4] : null);
                            return [4 /*yield*/, poseFlagTensor.data()];
                        case 1:
                            poseScore = (_a.sent())[0];
                            // Applies a threshold to the confidence score to determine whether a pose
                            // is present.
                            if (poseScore < BLAZEPOSE_POSE_PRESENCE_SCORE) {
                                return [2 /*return*/, null];
                            }
                            return [4 /*yield*/, tensorsToLandmarks(landmarkTensor, BLAZEPOSE_TENSORS_TO_LANDMARKS_CONFIG)];
                        case 2:
                            rawLandmarks = _a.sent();
                            return [4 /*yield*/, refineLandmarksFromHeatmap(rawLandmarks, heatmapTensor, BLAZEPOSE_REFINE_LANDMARKS_FROM_HEATMAP_CONFIG)];
                        case 3:
                            allLandmarks = _a.sent();
                            landmarks = allLandmarks.slice(0, BLAZEPOSE_NUM_KEYPOINTS);
                            auxiliaryLandmarks = allLandmarks.slice(BLAZEPOSE_NUM_KEYPOINTS, BLAZEPOSE_NUM_AUXILIARY_KEYPOINTS);
                            return [4 /*yield*/, tensorsToLandmarks(worldLandmarkTensor, BLAZEPOSE_TENSORS_TO_WORLD_LANDMARKS_CONFIG)];
                        case 4:
                            allWorldLandmarks = _a.sent();
                            worldLandmarksWithoutVisibility = allWorldLandmarks.slice(0, BLAZEPOSE_NUM_KEYPOINTS);
                            worldLandmarks = calculateScoreCopy(landmarks, worldLandmarksWithoutVisibility, true);
                            segmentationMask = this.enableSegmentation ?
                                tensorsToSegmentation(segmentationTensor, BLAZEPOSE_TENSORS_TO_SEGMENTATION_CONFIG) :
                                null;
                            return [2 /*return*/, {
                                    landmarks: landmarks,
                                    auxiliaryLandmarks: auxiliaryLandmarks,
                                    poseScore: poseScore,
                                    worldLandmarks: worldLandmarks,
                                    segmentationMask: segmentationMask
                                }];
                    }
                });
            });
        };
        // Calculate region of interest (ROI) from landmarks.
        // Subgraph: PoseLandmarksToRoiCpu
        // ref:
        // https://github.com/google/mediapipe/blob/master/mediapipe/modules/pose_landmark/pose_landmarks_to_roi.pbtxt
        // When landmarks is not null, imageSize should not be null either.
        BlazePoseTfjsDetector.prototype.poseLandmarksToRoi = function (landmarks, imageSize) {
            // PoseLandmarksToRoi: LandmarksToDetectionCalculator.
            var detection = landmarksToDetection(landmarks);
            // Converts detection into a rectangle based on center and scale alignment
            // points.
            // PoseLandmarksToRoi: AlignmentPointsRectsCalculator.
            var rawRoi = calculateAlignmentPointsRects(detection, imageSize, {
                rotationVectorStartKeypointIndex: 0,
                rotationVectorEndKeypointIndex: 1,
                rotationVectorTargetAngleDegree: 90
            });
            // Expands pose rect with marging used during training.
            // PoseLandmarksToRoi: RectTransformationCalculator.
            var roi = transformNormalizedRect(rawRoi, imageSize, BLAZEPOSE_DETECTOR_RECT_TRANSFORMATION_CONFIG);
            return roi;
        };
        // Filter landmarks temporally to reduce jitter.
        // Subgraph: PoseLandmarkFiltering
        // ref:
        // https://github.com/google/mediapipe/blob/master/mediapipe/modules/pose_landmark/pose_landmark_filtering.pbtxt
        BlazePoseTfjsDetector.prototype.poseLandmarkFiltering = function (actualLandmarks, auxiliaryLandmarks, actualWorldLandmarks, imageSize) {
            var actualLandmarksFiltered;
            var auxiliaryLandmarksFiltered;
            var actualWorldLandmarksFiltered;
            if (this.timestamp == null || !this.enableSmoothing) {
                actualLandmarksFiltered = actualLandmarks;
                auxiliaryLandmarksFiltered = auxiliaryLandmarks;
                actualWorldLandmarksFiltered = actualWorldLandmarks;
            }
            else {
                var auxDetection = landmarksToDetection(auxiliaryLandmarks);
                var objectScaleROI = calculateAlignmentPointsRects(auxDetection, imageSize, {
                    rotationVectorEndKeypointIndex: 0,
                    rotationVectorStartKeypointIndex: 1,
                    rotationVectorTargetAngleDegree: 90
                });
                // Smoothes pose landmark visibilities to reduce jitter.
                if (this.visibilitySmoothingFilterActual == null) {
                    this.visibilitySmoothingFilterActual = new LowPassVisibilityFilter(BLAZEPOSE_VISIBILITY_SMOOTHING_CONFIG);
                }
                actualLandmarksFiltered =
                    this.visibilitySmoothingFilterActual.apply(actualLandmarks);
                if (this.visibilitySmoothingFilterAuxiliary == null) {
                    this.visibilitySmoothingFilterAuxiliary = new LowPassVisibilityFilter(BLAZEPOSE_VISIBILITY_SMOOTHING_CONFIG);
                }
                auxiliaryLandmarksFiltered =
                    this.visibilitySmoothingFilterAuxiliary.apply(auxiliaryLandmarks);
                actualWorldLandmarksFiltered =
                    this.visibilitySmoothingFilterActual.apply(actualWorldLandmarks);
                // Smoothes pose landmark coordinates to reduce jitter.
                if (this.landmarksSmoothingFilterActual == null) {
                    this.landmarksSmoothingFilterActual = new KeypointsSmoothingFilter(BLAZEPOSE_LANDMARKS_SMOOTHING_CONFIG_ACTUAL);
                }
                actualLandmarksFiltered = this.landmarksSmoothingFilterActual.apply(actualLandmarksFiltered, this.timestamp, imageSize, true /* normalized */, objectScaleROI);
                if (this.landmarksSmoothingFilterAuxiliary == null) {
                    this.landmarksSmoothingFilterAuxiliary = new KeypointsSmoothingFilter(BLAZEPOSE_LANDMARKS_SMOOTHING_CONFIG_AUXILIARY);
                }
                auxiliaryLandmarksFiltered = this.landmarksSmoothingFilterAuxiliary.apply(auxiliaryLandmarksFiltered, this.timestamp, imageSize, true /* normalized */, objectScaleROI);
                // Smoothes pose world landmark coordinates to reduce jitter.
                if (this.worldLandmarksSmoothingFilterActual == null) {
                    this.worldLandmarksSmoothingFilterActual = new KeypointsSmoothingFilter(BLAZEPOSE_WORLD_LANDMARKS_SMOOTHING_CONFIG_ACTUAL);
                }
                actualWorldLandmarksFiltered =
                    this.worldLandmarksSmoothingFilterActual.apply(actualWorldLandmarks, this.timestamp);
            }
            return {
                actualLandmarksFiltered: actualLandmarksFiltered,
                auxiliaryLandmarksFiltered: auxiliaryLandmarksFiltered,
                actualWorldLandmarksFiltered: actualWorldLandmarksFiltered
            };
        };
        return BlazePoseTfjsDetector;
    }());
    /**
     * Loads the BlazePose model.
     *
     * @param modelConfig ModelConfig object that contains parameters for
     * the BlazePose loading process. Please find more details of each parameters
     * in the documentation of the `BlazePoseTfjsModelConfig` interface.
     */
    function load$1(modelConfig) {
        return __awaiter(this, void 0, void 0, function () {
            var config, detectorFromTFHub, landmarkFromTFHub, _a, detectorModel, landmarkModel;
            return __generator(this, function (_b) {
                switch (_b.label) {
                    case 0:
                        config = validateModelConfig$1(modelConfig);
                        detectorFromTFHub = typeof config.detectorModelUrl === 'string' &&
                            (config.detectorModelUrl.indexOf('https://tfhub.dev') > -1);
                        landmarkFromTFHub = typeof config.landmarkModelUrl === 'string' &&
                            (config.landmarkModelUrl.indexOf('https://tfhub.dev') > -1);
                        return [4 /*yield*/, Promise.all([
                                tfconv.loadGraphModel(config.detectorModelUrl, { fromTFHub: detectorFromTFHub }),
                                tfconv.loadGraphModel(config.landmarkModelUrl, { fromTFHub: landmarkFromTFHub })
                            ])];
                    case 1:
                        _a = _b.sent(), detectorModel = _a[0], landmarkModel = _a[1];
                        return [2 /*return*/, new BlazePoseTfjsDetector(detectorModel, landmarkModel, config.enableSmoothing, config.enableSegmentation, config.smoothSegmentation, config.modelType)];
                }
            });
        });
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * https://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function validateTrackerConfig(config) {
        if (config.maxTracks < 1) {
            throw new Error("Must specify 'maxTracks' to be at least 1, but " +
                "encountered ".concat(config.maxTracks));
        }
        if (config.maxAge <= 0) {
            throw new Error("Must specify 'maxAge' to be positive, but " +
                "encountered ".concat(config.maxAge));
        }
        if (config.keypointTrackerParams !== undefined) {
            if (config.keypointTrackerParams.keypointConfidenceThreshold < 0 ||
                config.keypointTrackerParams.keypointConfidenceThreshold > 1) {
                throw new Error("Must specify 'keypointConfidenceThreshold' to be in the range " +
                    "[0, 1], but encountered " +
                    "".concat(config.keypointTrackerParams.keypointConfidenceThreshold));
            }
            if (config.keypointTrackerParams.minNumberOfKeypoints < 1) {
                throw new Error("Must specify 'minNumberOfKeypoints' to be at least 1, but " +
                    "encountered ".concat(config.keypointTrackerParams.minNumberOfKeypoints));
            }
            for (var _i = 0, _a = config.keypointTrackerParams.keypointFalloff; _i < _a.length; _i++) {
                var falloff = _a[_i];
                if (falloff <= 0.0) {
                    throw new Error("Must specify each keypoint falloff parameterto be positive " +
                        "but encountered ".concat(falloff));
                }
            }
        }
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * https://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    /**
     * A stateful tracker for associating detections between frames. This is an
     * abstract base class that performs generic mechanics. Implementations must
     * inherit from this class.
     */
    var Tracker = /** @class */ (function () {
        function Tracker(config) {
            validateTrackerConfig(config);
            this.tracks = [];
            this.maxTracks = config.maxTracks;
            this.maxAge = config.maxAge * 1000; // Convert msec to usec.
            this.minSimilarity = config.minSimilarity;
            this.nextID = 1;
        }
        /**
         * Tracks person instances across frames based on detections.
         * @param poses An array of detected `Pose`s.
         * @param timestamp The timestamp associated with the incoming poses, in
         * microseconds.
         * @returns An updated array of `Pose`s with tracking id properties.
         */
        Tracker.prototype.apply = function (poses, timestamp) {
            this.filterOldTracks(timestamp);
            var simMatrix = this.computeSimilarity(poses);
            this.assignTracks(poses, simMatrix, timestamp);
            this.updateTracks(timestamp);
            return poses;
        };
        /**
         * Returns a copy of the stored tracks.
         */
        Tracker.prototype.getTracks = function () {
            return this.tracks.slice();
        };
        /**
         * Returns a Set of active track IDs.
         */
        Tracker.prototype.getTrackIDs = function () {
            return new Set(this.tracks.map(function (track) { return track.id; }));
        };
        /**
         * Filters tracks based on their age.
         * @param timestamp The current timestamp in microseconds.
         */
        Tracker.prototype.filterOldTracks = function (timestamp) {
            var _this = this;
            this.tracks = this.tracks.filter(function (track) {
                return timestamp - track.lastTimestamp <= _this.maxAge;
            });
        };
        /**
         * Performs a greedy optimization to link detections with tracks. The `poses`
         * array is updated in place by providing an `id` property. If incoming
         * detections are not linked with existing tracks, new tracks will be created.
         * @param poses An array of detected `Pose`s. It's assumed that poses are
         * sorted from most confident to least confident.
         * @param simMatrix A 2D array of shape [num_det, num_tracks] with pairwise
         * similarity scores between detections and tracks.
         * @param timestamp The current timestamp in microseconds.
         */
        Tracker.prototype.assignTracks = function (poses, simMatrix, timestamp) {
            var unmatchedTrackIndices = Array.from(Array(simMatrix[0].length).keys());
            var detectionIndices = Array.from(Array(poses.length).keys());
            var unmatchedDetectionIndices = [];
            for (var _i = 0, detectionIndices_1 = detectionIndices; _i < detectionIndices_1.length; _i++) {
                var detectionIndex = detectionIndices_1[_i];
                if (unmatchedTrackIndices.length === 0) {
                    unmatchedDetectionIndices.push(detectionIndex);
                    continue;
                }
                // Assign the detection to the track which produces the highest pairwise
                // similarity score, assuming the score exceeds the minimum similarity
                // threshold.
                var maxTrackIndex = -1;
                var maxSimilarity = -1;
                for (var _a = 0, unmatchedTrackIndices_1 = unmatchedTrackIndices; _a < unmatchedTrackIndices_1.length; _a++) {
                    var trackIndex = unmatchedTrackIndices_1[_a];
                    var similarity = simMatrix[detectionIndex][trackIndex];
                    if (similarity >= this.minSimilarity && similarity > maxSimilarity) {
                        maxTrackIndex = trackIndex;
                        maxSimilarity = similarity;
                    }
                }
                if (maxTrackIndex >= 0) {
                    // Link the detection with the highest scoring track.
                    var linkedTrack = this.tracks[maxTrackIndex];
                    linkedTrack = Object.assign(linkedTrack, this.createTrack(poses[detectionIndex], timestamp, linkedTrack.id));
                    poses[detectionIndex].id = linkedTrack.id;
                    var index = unmatchedTrackIndices.indexOf(maxTrackIndex);
                    unmatchedTrackIndices.splice(index, 1);
                }
                else {
                    unmatchedDetectionIndices.push(detectionIndex);
                }
            }
            // Spawn new tracks for all unmatched detections.
            for (var _b = 0, unmatchedDetectionIndices_1 = unmatchedDetectionIndices; _b < unmatchedDetectionIndices_1.length; _b++) {
                var detectionIndex = unmatchedDetectionIndices_1[_b];
                var newTrack = this.createTrack(poses[detectionIndex], timestamp);
                this.tracks.push(newTrack);
                poses[detectionIndex].id = newTrack.id;
            }
        };
        /**
         * Updates the stored tracks in the tracker. Specifically, the following
         * operations are applied in order:
         * 1. Tracks are sorted based on freshness (i.e. the most recently linked
         *    tracks are placed at the beginning of the array and the most stale are
         *    at the end).
         * 2. The tracks array is sliced to only contain `maxTracks` tracks (i.e. the
         *    most fresh tracks).
         * @param timestamp The current timestamp in microseconds.
         */
        Tracker.prototype.updateTracks = function (timestamp) {
            // Sort tracks from most recent to most stale, and then only keep the top
            // `maxTracks` tracks.
            this.tracks.sort(function (ta, tb) { return tb.lastTimestamp - ta.lastTimestamp; });
            this.tracks = this.tracks.slice(0, this.maxTracks);
        };
        /**
         * Creates a track from information in a pose.
         * @param pose A `Pose`.
         * @param timestamp The current timestamp in microseconds.
         * @param trackID The id to assign to the new track. If not provided,
         * will assign the next available id.
         * @returns A `Track`.
         */
        Tracker.prototype.createTrack = function (pose, timestamp, trackID) {
            var track = {
                id: trackID || this.nextTrackID(),
                lastTimestamp: timestamp,
                keypoints: __spreadArray([], pose.keypoints, true).map(function (keypoint) { return (__assign({}, keypoint)); })
            };
            if (pose.box !== undefined) {
                track.box = __assign({}, pose.box);
            }
            return track;
        };
        /**
         * Returns the next free track ID.
         */
        Tracker.prototype.nextTrackID = function () {
            var nextID = this.nextID;
            this.nextID += 1;
            return nextID;
        };
        /**
         * Removes specific tracks, based on their ids.
         */
        Tracker.prototype.remove = function () {
            var ids = [];
            for (var _i = 0; _i < arguments.length; _i++) {
                ids[_i] = arguments[_i];
            }
            this.tracks = this.tracks.filter(function (track) { return !ids.includes(track.id); });
        };
        /**
         * Resets tracks.
         */
        Tracker.prototype.reset = function () {
            this.tracks = [];
        };
        return Tracker;
    }());

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * https://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    /**
     * BoundingBoxTracker, which tracks objects based on bounding box similarity,
     * currently defined as intersection-over-union (IoU).
     */
    var BoundingBoxTracker = /** @class */ (function (_super) {
        __extends(BoundingBoxTracker, _super);
        function BoundingBoxTracker(config) {
            return _super.call(this, config) || this;
        }
        /**
         * Computes similarity based on intersection-over-union (IoU). See `Tracker`
         * for more details.
         */
        BoundingBoxTracker.prototype.computeSimilarity = function (poses) {
            var _this = this;
            if (poses.length === 0 || this.tracks.length === 0) {
                return [[]];
            }
            var simMatrix = poses.map(function (pose) {
                return _this.tracks.map(function (track) {
                    return _this.iou(pose, track);
                });
            });
            return simMatrix;
        };
        /**
         * Computes the intersection-over-union (IoU) between a pose and a track.
         * @param pose A `Pose`.
         * @param track A `Track`.
         * @returns The IoU  between the pose and the track. This number is
         * between 0 and 1, and larger values indicate more box similarity.
         */
        BoundingBoxTracker.prototype.iou = function (pose, track) {
            var xMin = Math.max(pose.box.xMin, track.box.xMin);
            var yMin = Math.max(pose.box.yMin, track.box.yMin);
            var xMax = Math.min(pose.box.xMax, track.box.xMax);
            var yMax = Math.min(pose.box.yMax, track.box.yMax);
            if (xMin >= xMax || yMin >= yMax) {
                return 0.0;
            }
            var intersection = (xMax - xMin) * (yMax - yMin);
            var areaPose = pose.box.width * pose.box.height;
            var areaTrack = track.box.width * track.box.height;
            return intersection / (areaPose + areaTrack - intersection);
        };
        return BoundingBoxTracker;
    }(Tracker));

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * https://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    /**
     * KeypointTracker, which tracks poses based on keypoint similarity. This
     * tracker assumes that keypoints are provided in normalized image
     * coordinates.
     */
    var KeypointTracker = /** @class */ (function (_super) {
        __extends(KeypointTracker, _super);
        function KeypointTracker(config) {
            var _this = _super.call(this, config) || this;
            _this.keypointThreshold =
                config.keypointTrackerParams.keypointConfidenceThreshold;
            _this.keypointFalloff = config.keypointTrackerParams.keypointFalloff;
            _this.minNumKeyoints = config.keypointTrackerParams.minNumberOfKeypoints;
            return _this;
        }
        /**
         * Computes similarity based on Object Keypoint Similarity (OKS). It's
         * assumed that the keypoints within each `Pose` are in normalized image
         * coordinates. See `Tracker` for more details.
         */
        KeypointTracker.prototype.computeSimilarity = function (poses) {
            if (poses.length === 0 || this.tracks.length === 0) {
                return [[]];
            }
            var simMatrix = [];
            for (var _i = 0, poses_1 = poses; _i < poses_1.length; _i++) {
                var pose = poses_1[_i];
                var row = [];
                for (var _a = 0, _b = this.tracks; _a < _b.length; _a++) {
                    var track = _b[_a];
                    row.push(this.oks(pose, track));
                }
                simMatrix.push(row);
            }
            return simMatrix;
        };
        /**
         * Computes the Object Keypoint Similarity (OKS) between a pose and track.
         * This is similar in spirit to the calculation used by COCO keypoint eval:
         * https://cocodataset.org/#keypoints-eval
         * In this case, OKS is calculated as:
         * (1/sum_i d(c_i, c_ti)) * \sum_i exp(-d_i^2/(2*a_ti*x_i^2))*d(c_i, c_ti)
         * where
         *   d(x, y) is an indicator function which only produces 1 if x and y
         *     exceed a given threshold (i.e. keypointThreshold), otherwise 0.
         *   c_i is the confidence of keypoint i from the new pose
         *   c_ti is the confidence of keypoint i from the track
         *   d_i is the Euclidean distance between the pose and track keypoint
         *   a_ti is the area of the track object (the box covering the keypoints)
         *   x_i is a constant that controls falloff in a Gaussian distribution,
         *    computed as 2*keypointFalloff[i].
         * @param pose A `Pose`.
         * @param track A `Track`.
         * @returns The OKS score between the pose and the track. This number is
         * between 0 and 1, and larger values indicate more keypoint similarity.
         */
        KeypointTracker.prototype.oks = function (pose, track) {
            var boxArea = this.area(track.keypoints) + 1e-6;
            var oksTotal = 0;
            var numValidKeypoints = 0;
            for (var i = 0; i < pose.keypoints.length; ++i) {
                var poseKpt = pose.keypoints[i];
                var trackKpt = track.keypoints[i];
                if (poseKpt.score < this.keypointThreshold ||
                    trackKpt.score < this.keypointThreshold) {
                    continue;
                }
                numValidKeypoints += 1;
                var dSquared = Math.pow(poseKpt.x - trackKpt.x, 2) +
                    Math.pow(poseKpt.y - trackKpt.y, 2);
                var x = 2 * this.keypointFalloff[i];
                oksTotal += Math.exp(-1 * dSquared / (2 * boxArea * Math.pow(x, 2)));
            }
            if (numValidKeypoints < this.minNumKeyoints) {
                return 0.0;
            }
            return oksTotal / numValidKeypoints;
        };
        /**
         * Computes the area of a bounding box that tightly covers keypoints.
         * @param Keypoint[] An array of `Keypoint`s.
         * @returns The area of the object.
         */
        KeypointTracker.prototype.area = function (keypoints) {
            var _this = this;
            var validKeypoint = keypoints.filter(function (kpt) { return kpt.score > _this.keypointThreshold; });
            var minX = Math.min.apply(Math, __spreadArray([1.0], validKeypoint.map(function (kpt) { return kpt.x; }), false));
            var maxX = Math.max.apply(Math, __spreadArray([0.0], validKeypoint.map(function (kpt) { return kpt.x; }), false));
            var minY = Math.min.apply(Math, __spreadArray([1.0], validKeypoint.map(function (kpt) { return kpt.y; }), false));
            var maxY = Math.max.apply(Math, __spreadArray([0.0], validKeypoint.map(function (kpt) { return kpt.y; }), false));
            return (maxX - minX) * (maxY - minY);
        };
        return KeypointTracker;
    }(Tracker));

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * https://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    (function (TrackerType) {
        TrackerType["Keypoint"] = "keypoint";
        TrackerType["BoundingBox"] = "boundingBox";
    })(exports.TrackerType || (exports.TrackerType = {}));

    (function (SupportedModels) {
        SupportedModels["MoveNet"] = "MoveNet";
        SupportedModels["BlazePose"] = "BlazePose";
        SupportedModels["PoseNet"] = "PoseNet";
    })(exports.SupportedModels || (exports.SupportedModels = {}));

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * https://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function getKeypointIndexBySide(model) {
        switch (model) {
            case exports.SupportedModels.BlazePose:
                return BLAZEPOSE_KEYPOINTS_BY_SIDE;
            case exports.SupportedModels.PoseNet:
            case exports.SupportedModels.MoveNet:
                return COCO_KEYPOINTS_BY_SIDE;
            default:
                throw new Error("Model ".concat(model, " is not supported."));
        }
    }
    function getAdjacentPairs(model) {
        switch (model) {
            case exports.SupportedModels.BlazePose:
                return BLAZEPOSE_CONNECTED_KEYPOINTS_PAIRS;
            case exports.SupportedModels.PoseNet:
            case exports.SupportedModels.MoveNet:
                return COCO_CONNECTED_KEYPOINTS_PAIRS;
            default:
                throw new Error("Model ".concat(model, " is not supported."));
        }
    }
    function getKeypointIndexByName(model) {
        switch (model) {
            case exports.SupportedModels.BlazePose:
                return BLAZEPOSE_KEYPOINTS.reduce(function (map, name, i) {
                    map[name] = i;
                    return map;
                }, {});
            case exports.SupportedModels.PoseNet:
            case exports.SupportedModels.MoveNet:
                return COCO_KEYPOINTS.reduce(function (map, name, i) {
                    map[name] = i;
                    return map;
                }, {});
            default:
                throw new Error("Model ".concat(model, " is not supported."));
        }
    }

    var util = /*#__PURE__*/Object.freeze({
        __proto__: null,
        getKeypointIndexBySide: getKeypointIndexBySide,
        getAdjacentPairs: getAdjacentPairs,
        getKeypointIndexByName: getKeypointIndexByName
    });

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * https://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    var SINGLEPOSE_LIGHTNING = 'SinglePose.Lightning';
    var SINGLEPOSE_THUNDER = 'SinglePose.Thunder';
    var MULTIPOSE_LIGHTNING = 'MultiPose.Lightning';
    var VALID_MODELS = [SINGLEPOSE_LIGHTNING, SINGLEPOSE_THUNDER, MULTIPOSE_LIGHTNING];
    var MOVENET_SINGLEPOSE_LIGHTNING_URL = 'https://tfhub.dev/google/tfjs-model/movenet/singlepose/lightning/4';
    var MOVENET_SINGLEPOSE_THUNDER_URL = 'https://tfhub.dev/google/tfjs-model/movenet/singlepose/thunder/4';
    var MOVENET_MULTIPOSE_LIGHTNING_URL = 'https://tfhub.dev/google/tfjs-model/movenet/multipose/lightning/1';
    var MOVENET_SINGLEPOSE_LIGHTNING_RESOLUTION = 192;
    var MOVENET_SINGLEPOSE_THUNDER_RESOLUTION = 256;
    var MOVENET_MULTIPOSE_DEFAULT_MAX_DIMENSION = 256;
    // The default configuration for loading MoveNet.
    var MOVENET_CONFIG = {
        modelType: SINGLEPOSE_LIGHTNING,
        enableSmoothing: true
    };
    var MOVENET_ESTIMATION_CONFIG = {};
    var KEYPOINT_FILTER_CONFIG = {
        frequency: 30,
        minCutOff: 2.5,
        beta: 300.0,
        derivateCutOff: 2.5,
        thresholdCutOff: 0.5,
        thresholdBeta: 5.0,
        disableValueScaling: true,
    };
    var CROP_FILTER_ALPHA = 0.9;
    var MIN_CROP_KEYPOINT_SCORE = 0.2;
    var DEFAULT_MIN_POSE_SCORE = 0.25;
    var NUM_KEYPOINTS = 17;
    var NUM_KEYPOINT_VALUES = 3; // [y, x, score]
    var MULTIPOSE_BOX_SIZE = 5; // [ymin, xmin, ymax, xmax, score]
    var MULTIPOSE_BOX_IDX = NUM_KEYPOINTS * NUM_KEYPOINT_VALUES;
    var MULTIPOSE_BOX_SCORE_IDX = MULTIPOSE_BOX_IDX + 4;
    var MULTIPOSE_INSTANCE_SIZE = NUM_KEYPOINTS * NUM_KEYPOINT_VALUES + MULTIPOSE_BOX_SIZE;
    var DEFAULT_KEYPOINT_TRACKER_CONFIG = {
        maxTracks: 18,
        maxAge: 1000,
        minSimilarity: 0.2,
        keypointTrackerParams: {
            keypointConfidenceThreshold: 0.3,
            // From COCO:
            // https://cocodataset.org/#keypoints-eval
            keypointFalloff: [
                0.026, 0.025, 0.025, 0.035, 0.035, 0.079, 0.079, 0.072, 0.072, 0.062,
                0.062, 0.107, 0.107, 0.087, 0.087, 0.089, 0.089
            ],
            minNumberOfKeypoints: 4
        }
    };
    var DEFAULT_BOUNDING_BOX_TRACKER_CONFIG = {
        maxTracks: 18,
        maxAge: 1000,
        minSimilarity: 0.15,
        trackerParams: {}
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * https://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    /**
     * Determines whether the torso of a person is visible.
     *
     * @param keypoints An array of `Keypoint`s associated with a person.
     * @param keypointIndexByName A map from keypoint name to index in the keypoints
     *     array.
     * @return A boolean indicating whether the torso is visible.
     */
    function torsoVisible(keypoints, keypointIndexByName) {
        return ((keypoints[keypointIndexByName['left_hip']].score >
            MIN_CROP_KEYPOINT_SCORE ||
            keypoints[keypointIndexByName['right_hip']].score >
                MIN_CROP_KEYPOINT_SCORE) &&
            (keypoints[keypointIndexByName['left_shoulder']].score >
                MIN_CROP_KEYPOINT_SCORE ||
                keypoints[keypointIndexByName['right_shoulder']].score >
                    MIN_CROP_KEYPOINT_SCORE));
    }
    /**
     * Calculates the maximum distance from each keypoint to the center location.
     * The function returns the maximum distances from the two sets of keypoints:
     * full 17 keypoints and 4 torso keypoints. The returned information will be
     * used to determine the crop size. See determineCropRegion for more detail.
     *
     * @param keypoints An array of `Keypoint`s associated with a person.
     * @param keypointIndexByName A map from keypoint name to index in the keypoints
     *     array.
     * @param targetKeypoints Maps from joint names to coordinates.
     * @param centerY The Y coordinate of the center of the person.
     * @param centerX The X coordinate of the center of the person.
     * @return An array containing information about the torso and body range in the
     *     image: [maxTorsoYrange, maxTorsoXrange, maxBodyYrange, maxBodyXrange].
     */
    function determineTorsoAndBodyRange(keypoints, keypointIndexByName, targetKeypoints, centerY, centerX) {
        var torsoJoints = ['left_shoulder', 'right_shoulder', 'left_hip', 'right_hip'];
        var maxTorsoYrange = 0.0;
        var maxTorsoXrange = 0.0;
        for (var i = 0; i < torsoJoints.length; i++) {
            var distY = Math.abs(centerY - targetKeypoints[torsoJoints[i]][0]);
            var distX = Math.abs(centerX - targetKeypoints[torsoJoints[i]][1]);
            if (distY > maxTorsoYrange) {
                maxTorsoYrange = distY;
            }
            if (distX > maxTorsoXrange) {
                maxTorsoXrange = distX;
            }
        }
        var maxBodyYrange = 0.0;
        var maxBodyXrange = 0.0;
        for (var _i = 0, _a = Object.keys(targetKeypoints); _i < _a.length; _i++) {
            var key = _a[_i];
            if (keypoints[keypointIndexByName[key]].score < MIN_CROP_KEYPOINT_SCORE) {
                continue;
            }
            var distY = Math.abs(centerY - targetKeypoints[key][0]);
            var distX = Math.abs(centerX - targetKeypoints[key][1]);
            if (distY > maxBodyYrange) {
                maxBodyYrange = distY;
            }
            if (distX > maxBodyXrange) {
                maxBodyXrange = distX;
            }
        }
        return [maxTorsoYrange, maxTorsoXrange, maxBodyYrange, maxBodyXrange];
    }
    /**
     * Determines the region to crop the image for the model to run inference on.
     * The algorithm uses the detected joints from the previous frame to estimate
     * the square region that encloses the full body of the target person and
     * centers at the midpoint of two hip joints. The crop size is determined by
     * the distances between each joint and the center point.
     * When the model is not confident with the four torso joint predictions, the
     * function returns a default crop which is the full image padded to square.
     *
     * @param currentCropRegion The crop region that was used for the current frame.
     *     Can be null for the very first frame that is handled by the detector.
     * @param keypoints An array of `Keypoint`s associated with a person.
     * @param keypointIndexByName A map from keypoint name to index in the keypoints
     *     array.
     * @param imageSize The size of the image that is being processed.
     * @return A `BoundingBox` that contains the new crop region.
     */
    function determineNextCropRegion(currentCropRegion, keypoints, keypointIndexByName, imageSize) {
        var targetKeypoints = {};
        for (var _i = 0, COCO_KEYPOINTS_1 = COCO_KEYPOINTS; _i < COCO_KEYPOINTS_1.length; _i++) {
            var key = COCO_KEYPOINTS_1[_i];
            targetKeypoints[key] = [
                keypoints[keypointIndexByName[key]].y * imageSize.height,
                keypoints[keypointIndexByName[key]].x * imageSize.width
            ];
        }
        if (torsoVisible(keypoints, keypointIndexByName)) {
            var centerY = (targetKeypoints['left_hip'][0] + targetKeypoints['right_hip'][0]) / 2;
            var centerX = (targetKeypoints['left_hip'][1] + targetKeypoints['right_hip'][1]) / 2;
            var _a = determineTorsoAndBodyRange(keypoints, keypointIndexByName, targetKeypoints, centerY, centerX), maxTorsoYrange = _a[0], maxTorsoXrange = _a[1], maxBodyYrange = _a[2], maxBodyXrange = _a[3];
            var cropLengthHalf = Math.max(maxTorsoXrange * 1.9, maxTorsoYrange * 1.9, maxBodyYrange * 1.2, maxBodyXrange * 1.2);
            cropLengthHalf = Math.min(cropLengthHalf, Math.max(centerX, imageSize.width - centerX, centerY, imageSize.height - centerY));
            var cropCorner = [centerY - cropLengthHalf, centerX - cropLengthHalf];
            if (cropLengthHalf > Math.max(imageSize.width, imageSize.height) / 2) {
                return initCropRegion(currentCropRegion == null, imageSize);
            }
            else {
                var cropLength = cropLengthHalf * 2;
                return {
                    yMin: cropCorner[0] / imageSize.height,
                    xMin: cropCorner[1] / imageSize.width,
                    yMax: (cropCorner[0] + cropLength) / imageSize.height,
                    xMax: (cropCorner[1] + cropLength) / imageSize.width,
                    height: (cropCorner[0] + cropLength) / imageSize.height -
                        cropCorner[0] / imageSize.height,
                    width: (cropCorner[1] + cropLength) / imageSize.width -
                        cropCorner[1] / imageSize.width
                };
            }
        }
        else {
            return initCropRegion(currentCropRegion == null, imageSize);
        }
    }
    /**
     * Provides initial crop region.
     *
     * The function provides the initial crop region when the algorithm cannot
     * reliably determine the crop region from the previous frame. There are two
     * scenarios:
     *   1) The very first frame: the function returns the best guess by cropping
     *      a square in the middle of the image.
     *   2) Not enough reliable keypoints detected from the previous frame: the
     *      function pads the full image from both sides to make it a square
     *      image.
     *
     * @param firstFrame A boolean indicating whether we are initializing a crop
     *     region for the very first frame.
     * @param imageSize The size of the image that is being processed.
     * @return A `BoundingBox` that contains the initial crop region.
     */
    function initCropRegion(firstFrame, imageSize) {
        var boxHeight, boxWidth, yMin, xMin;
        if (firstFrame) {
            // If it is the first frame, perform a best guess by making the square
            // crop at the image center to better utilize the image pixels and
            // create higher chance to enter the cropping loop.
            if (imageSize.width > imageSize.height) {
                boxHeight = 1.0;
                boxWidth = imageSize.height / imageSize.width;
                yMin = 0.0;
                xMin = (imageSize.width / 2 - imageSize.height / 2) / imageSize.width;
            }
            else {
                boxHeight = imageSize.width / imageSize.height;
                boxWidth = 1.0;
                yMin = (imageSize.height / 2 - imageSize.width / 2) / imageSize.height;
                xMin = 0.0;
            }
        }
        else {
            // No cropRegion was available from a previous estimatePoses() call, so
            // run the model on the full image with padding on both sides.
            if (imageSize.width > imageSize.height) {
                boxHeight = imageSize.width / imageSize.height;
                boxWidth = 1.0;
                yMin = (imageSize.height / 2 - imageSize.width / 2) / imageSize.height;
                xMin = 0.0;
            }
            else {
                boxHeight = 1.0;
                boxWidth = imageSize.height / imageSize.width;
                yMin = 0.0;
                xMin = (imageSize.width / 2 - imageSize.height / 2) / imageSize.width;
            }
        }
        return {
            yMin: yMin,
            xMin: xMin,
            yMax: yMin + boxHeight,
            xMax: xMin + boxWidth,
            height: boxHeight,
            width: boxWidth
        };
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * https://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function validateModelConfig$2(modelConfig) {
        var config = modelConfig == null ? MOVENET_CONFIG : __assign({}, modelConfig);
        if (config.modelType == null) {
            config.modelType = 'SinglePose.Lightning';
        }
        else if (VALID_MODELS.indexOf(config.modelType) < 0) {
            throw new Error("Invalid architecture ".concat(config.modelType, ". ") +
                "Should be one of ".concat(VALID_MODELS));
        }
        if (config.enableSmoothing == null) {
            config.enableSmoothing = true;
        }
        if (config.minPoseScore != null &&
            (config.minPoseScore < 0.0 || config.minPoseScore > 1.0)) {
            throw new Error("minPoseScore should be between 0.0 and 1.0");
        }
        if (config.multiPoseMaxDimension != null &&
            (config.multiPoseMaxDimension % 32 !== 0 ||
                config.multiPoseMaxDimension < 32)) {
            throw new Error("multiPoseMaxDimension must be a multiple of 32 and higher than 0");
        }
        if (config.modelType === MULTIPOSE_LIGHTNING &&
            config.enableTracking == null) {
            config.enableTracking = true;
        }
        if (config.modelType === MULTIPOSE_LIGHTNING &&
            config.enableTracking === true) {
            if (config.trackerType == null) {
                config.trackerType = exports.TrackerType.BoundingBox;
            }
            if (config.trackerType === exports.TrackerType.Keypoint) {
                if (config.trackerConfig != null) {
                    config.trackerConfig = mergeKeypointTrackerConfig(config.trackerConfig);
                }
                else {
                    config.trackerConfig = DEFAULT_KEYPOINT_TRACKER_CONFIG;
                }
            }
            else if (config.trackerType === exports.TrackerType.BoundingBox) {
                if (config.trackerConfig != null) {
                    config.trackerConfig =
                        mergeBoundingBoxTrackerConfig(config.trackerConfig);
                }
                else {
                    config.trackerConfig = DEFAULT_BOUNDING_BOX_TRACKER_CONFIG;
                }
            }
            else {
                throw new Error('Tracker type not supported by MoveNet');
            }
            // We don't need to validate the trackerConfig here because the tracker will
            // take care of that.
        }
        return config;
    }
    function validateEstimationConfig$1(estimationConfig) {
        var config = estimationConfig == null ? MOVENET_ESTIMATION_CONFIG : __assign({}, estimationConfig);
        return config;
    }
    function mergeBaseTrackerConfig(defaultConfig, userConfig) {
        var mergedConfig = {
            maxTracks: defaultConfig.maxTracks,
            maxAge: defaultConfig.maxAge,
            minSimilarity: defaultConfig.minSimilarity,
        };
        if (userConfig.maxTracks != null) {
            mergedConfig.maxTracks = userConfig.maxTracks;
        }
        if (userConfig.maxAge != null) {
            mergedConfig.maxAge = userConfig.maxAge;
        }
        if (userConfig.minSimilarity != null) {
            mergedConfig.minSimilarity = userConfig.minSimilarity;
        }
        return mergedConfig;
    }
    function mergeKeypointTrackerConfig(userConfig) {
        var mergedConfig = mergeBaseTrackerConfig(DEFAULT_KEYPOINT_TRACKER_CONFIG, userConfig);
        mergedConfig.keypointTrackerParams = __assign({}, DEFAULT_KEYPOINT_TRACKER_CONFIG.keypointTrackerParams);
        if (userConfig.keypointTrackerParams != null) {
            if (userConfig.keypointTrackerParams.keypointConfidenceThreshold != null) {
                mergedConfig.keypointTrackerParams.keypointConfidenceThreshold =
                    userConfig.keypointTrackerParams.keypointConfidenceThreshold;
            }
            if (userConfig.keypointTrackerParams.keypointFalloff != null) {
                mergedConfig.keypointTrackerParams.keypointFalloff =
                    userConfig.keypointTrackerParams.keypointFalloff;
            }
            if (userConfig.keypointTrackerParams.minNumberOfKeypoints != null) {
                mergedConfig.keypointTrackerParams.minNumberOfKeypoints =
                    userConfig.keypointTrackerParams.minNumberOfKeypoints;
            }
        }
        return mergedConfig;
    }
    function mergeBoundingBoxTrackerConfig(userConfig) {
        var mergedConfig = mergeBaseTrackerConfig(DEFAULT_BOUNDING_BOX_TRACKER_CONFIG, userConfig);
        return mergedConfig;
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * https://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    /**
     * MoveNet detector class.
     */
    var MoveNetDetector = /** @class */ (function () {
        function MoveNetDetector(moveNetModel, config) {
            this.moveNetModel = moveNetModel;
            this.modelInputResolution = { height: 0, width: 0 };
            this.keypointIndexByName = getKeypointIndexByName(exports.SupportedModels.MoveNet);
            // Only single-pose models have a fixed input resolution.
            if (config.modelType === SINGLEPOSE_LIGHTNING) {
                this.modelInputResolution.width = MOVENET_SINGLEPOSE_LIGHTNING_RESOLUTION;
                this.modelInputResolution.height =
                    MOVENET_SINGLEPOSE_LIGHTNING_RESOLUTION;
            }
            else if (config.modelType === SINGLEPOSE_THUNDER) {
                this.modelInputResolution.width = MOVENET_SINGLEPOSE_THUNDER_RESOLUTION;
                this.modelInputResolution.height = MOVENET_SINGLEPOSE_THUNDER_RESOLUTION;
            }
            this.multiPoseModel = config.modelType === MULTIPOSE_LIGHTNING;
            if (!this.multiPoseModel) {
                this.keypointFilter = new KeypointsOneEuroFilter(KEYPOINT_FILTER_CONFIG);
                this.cropRegionFilterYMin = new LowPassFilter(CROP_FILTER_ALPHA);
                this.cropRegionFilterXMin = new LowPassFilter(CROP_FILTER_ALPHA);
                this.cropRegionFilterYMax = new LowPassFilter(CROP_FILTER_ALPHA);
                this.cropRegionFilterXMax = new LowPassFilter(CROP_FILTER_ALPHA);
            }
            this.enableSmoothing = config.enableSmoothing;
            if (config.minPoseScore) {
                this.minPoseScore = config.minPoseScore;
            }
            else {
                this.minPoseScore = DEFAULT_MIN_POSE_SCORE;
            }
            if (config.multiPoseMaxDimension) {
                this.multiPoseMaxDimension = config.multiPoseMaxDimension;
            }
            else {
                this.multiPoseMaxDimension = MOVENET_MULTIPOSE_DEFAULT_MAX_DIMENSION;
            }
            this.enableTracking = config.enableTracking;
            if (this.multiPoseModel && this.enableTracking) {
                if (config.trackerType === exports.TrackerType.Keypoint) {
                    this.tracker = new KeypointTracker(config.trackerConfig);
                }
                else if (config.trackerType === exports.TrackerType.BoundingBox) {
                    this.tracker = new BoundingBoxTracker(config.trackerConfig);
                }
                if (this.enableSmoothing) {
                    this.keypointFilterMap = new Map();
                }
            }
        }
        /**
         * Runs inference on an image using a model that is assumed to be a single
         * person keypoint model that outputs 17 keypoints.
         *
         * @param inputImage 4D tensor containing the input image. Should be of size
         * [1, modelHeight, modelWidth, 3].
         * @return A `Pose`.
         */
        MoveNetDetector.prototype.runSinglePersonPoseModel = function (inputImage) {
            return __awaiter(this, void 0, void 0, function () {
                var outputTensor, inferenceResult, pose, numValidKeypoints, i;
                return __generator(this, function (_a) {
                    switch (_a.label) {
                        case 0:
                            outputTensor = this.moveNetModel.execute(inputImage);
                            // We expect an output tensor of shape [1, 1, 17, 3] (batch, person,
                            // keypoint, (y, x, score)).
                            if (outputTensor.shape.length !== 4 || outputTensor.shape[0] !== 1 ||
                                outputTensor.shape[1] !== 1 ||
                                outputTensor.shape[2] !== NUM_KEYPOINTS ||
                                outputTensor.shape[3] !== NUM_KEYPOINT_VALUES) {
                                outputTensor.dispose();
                                throw new Error("Unexpected output shape from model: [".concat(outputTensor.shape, "]"));
                            }
                            if (!(tf.getBackend() !== 'webgpu')) return [3 /*break*/, 1];
                            inferenceResult = outputTensor.dataSync();
                            return [3 /*break*/, 3];
                        case 1: return [4 /*yield*/, outputTensor.data()];
                        case 2:
                            inferenceResult = _a.sent();
                            _a.label = 3;
                        case 3:
                            outputTensor.dispose();
                            pose = { keypoints: [], score: 0.0 };
                            numValidKeypoints = 0;
                            for (i = 0; i < NUM_KEYPOINTS; ++i) {
                                pose.keypoints[i] = {
                                    y: inferenceResult[i * NUM_KEYPOINT_VALUES],
                                    x: inferenceResult[i * NUM_KEYPOINT_VALUES + 1],
                                    score: inferenceResult[i * NUM_KEYPOINT_VALUES + 2]
                                };
                                if (pose.keypoints[i].score > MIN_CROP_KEYPOINT_SCORE) {
                                    ++numValidKeypoints;
                                    pose.score += pose.keypoints[i].score;
                                }
                            }
                            if (numValidKeypoints > 0) {
                                pose.score /= numValidKeypoints;
                            }
                            return [2 /*return*/, pose];
                    }
                });
            });
        };
        /**
         * Runs inference on an image using a model that is assumed to be a
         * multi-person keypoint model that outputs 17 keypoints and a box for a
         * multiple persons.
         *
         * @param inputImage 4D tensor containing the input image. Should be of size
         * [1, width, height, 3], where width and height are divisible by 32.
         * @return An array of `Pose`s.
         */
        MoveNetDetector.prototype.runMultiPersonPoseModel = function (inputImage) {
            return __awaiter(this, void 0, void 0, function () {
                var outputTensor, inferenceResult, poses, numInstances, i, boxIndex, scoreIndex, j;
                return __generator(this, function (_a) {
                    switch (_a.label) {
                        case 0:
                            outputTensor = this.moveNetModel.execute(inputImage);
                            // Multi-pose model output is a [1, n, 56] tensor ([batch, num_instances,
                            // instance_keypoints_and_box]).
                            if (outputTensor.shape.length !== 3 || outputTensor.shape[0] !== 1 ||
                                outputTensor.shape[2] !== MULTIPOSE_INSTANCE_SIZE) {
                                outputTensor.dispose();
                                throw new Error("Unexpected output shape from model: [".concat(outputTensor.shape, "]"));
                            }
                            if (!(tf.getBackend() !== 'webgpu')) return [3 /*break*/, 1];
                            inferenceResult = outputTensor.dataSync();
                            return [3 /*break*/, 3];
                        case 1: return [4 /*yield*/, outputTensor.data()];
                        case 2:
                            inferenceResult = _a.sent();
                            _a.label = 3;
                        case 3:
                            outputTensor.dispose();
                            poses = [];
                            numInstances = inferenceResult.length / MULTIPOSE_INSTANCE_SIZE;
                            for (i = 0; i < numInstances; ++i) {
                                poses[i] = { keypoints: [] };
                                boxIndex = i * MULTIPOSE_INSTANCE_SIZE + MULTIPOSE_BOX_IDX;
                                poses[i].box = {
                                    yMin: inferenceResult[boxIndex],
                                    xMin: inferenceResult[boxIndex + 1],
                                    yMax: inferenceResult[boxIndex + 2],
                                    xMax: inferenceResult[boxIndex + 3],
                                    width: inferenceResult[boxIndex + 3] - inferenceResult[boxIndex + 1],
                                    height: inferenceResult[boxIndex + 2] - inferenceResult[boxIndex]
                                };
                                scoreIndex = i * MULTIPOSE_INSTANCE_SIZE + MULTIPOSE_BOX_SCORE_IDX;
                                poses[i].score = inferenceResult[scoreIndex];
                                poses[i].keypoints = [];
                                for (j = 0; j < NUM_KEYPOINTS; ++j) {
                                    poses[i].keypoints[j] = {
                                        y: inferenceResult[i * MULTIPOSE_INSTANCE_SIZE + j * NUM_KEYPOINT_VALUES],
                                        x: inferenceResult[i * MULTIPOSE_INSTANCE_SIZE + j * NUM_KEYPOINT_VALUES + 1],
                                        score: inferenceResult[i * MULTIPOSE_INSTANCE_SIZE + j * NUM_KEYPOINT_VALUES + 2]
                                    };
                                }
                            }
                            return [2 /*return*/, poses];
                    }
                });
            });
        };
        /**
         * Estimates poses for an image or video frame. This does standard ImageNet
         * pre-processing before inferring through the model. The image pixels should
         * have values [0-255]. It returns an array of poses.
         *
         * @param image ImageData|HTMLImageElement|HTMLCanvasElement|HTMLVideoElement
         * The input image to feed through the network.
         * @param config Optional. Currently not used.
         * @param timestamp Optional. In milliseconds. This is useful when image is
         * a tensor, which doesn't have timestamp info. Or to override timestamp in a
         * video.
         * @return An array of `Pose`s.
         */
        MoveNetDetector.prototype.estimatePoses = function (image, estimationConfig, timestamp) {
            if (estimationConfig === void 0) { estimationConfig = MOVENET_ESTIMATION_CONFIG; }
            return __awaiter(this, void 0, void 0, function () {
                var imageTensor3D, imageSize, imageTensor4D, poses, poseIdx, keypointIdx;
                return __generator(this, function (_a) {
                    switch (_a.label) {
                        case 0:
                            estimationConfig = validateEstimationConfig$1(estimationConfig);
                            if (image == null) {
                                this.reset();
                                return [2 /*return*/, []];
                            }
                            if (timestamp == null) {
                                if (isVideo(image)) {
                                    timestamp = image.currentTime * SECOND_TO_MICRO_SECONDS;
                                }
                            }
                            else {
                                timestamp = timestamp * MILLISECOND_TO_MICRO_SECONDS;
                            }
                            imageTensor3D = toImageTensor(image);
                            imageSize = getImageSize(imageTensor3D);
                            imageTensor4D = tf.expandDims(imageTensor3D, 0);
                            // Make sure we don't dispose the input image if it's already a tensor.
                            if (!(image instanceof tf.Tensor)) {
                                imageTensor3D.dispose();
                            }
                            poses = [];
                            if (!!this.multiPoseModel) return [3 /*break*/, 2];
                            return [4 /*yield*/, this.estimateSinglePose(imageTensor4D, imageSize, timestamp)];
                        case 1:
                            poses =
                                _a.sent();
                            return [3 /*break*/, 4];
                        case 2: return [4 /*yield*/, this.estimateMultiplePoses(imageTensor4D, imageSize, timestamp)];
                        case 3:
                            poses =
                                _a.sent();
                            _a.label = 4;
                        case 4:
                            // Convert keypoint coordinates from normalized coordinates to image space
                            // and add keypoint names.
                            for (poseIdx = 0; poseIdx < poses.length; ++poseIdx) {
                                for (keypointIdx = 0; keypointIdx < poses[poseIdx].keypoints.length; ++keypointIdx) {
                                    poses[poseIdx].keypoints[keypointIdx].name =
                                        COCO_KEYPOINTS[keypointIdx];
                                    poses[poseIdx].keypoints[keypointIdx].y *= imageSize.height;
                                    poses[poseIdx].keypoints[keypointIdx].x *= imageSize.width;
                                }
                            }
                            return [2 /*return*/, poses];
                    }
                });
            });
        };
        /**
         * Runs a single-person keypoint model on an image, including the image
         * cropping and keypoint filtering logic.
         *
         * @param imageTensor4D A tf.Tensor4D that contains the input image.
         * @param imageSize: The width and height of the input image.
         * @param timestamp Image timestamp in microseconds.
         * @return An array of `Pose`s.
         */
        MoveNetDetector.prototype.estimateSinglePose = function (imageTensor4D, imageSize, timestamp) {
            return __awaiter(this, void 0, void 0, function () {
                var croppedImage, pose, i, nextCropRegion;
                var _this = this;
                return __generator(this, function (_a) {
                    switch (_a.label) {
                        case 0:
                            if (!this.cropRegion) {
                                this.cropRegion = initCropRegion(this.cropRegion == null, imageSize);
                            }
                            croppedImage = tf.tidy(function () {
                                // Crop region is a [batch, 4] size tensor.
                                var cropRegionTensor = tf.tensor2d([[
                                        _this.cropRegion.yMin, _this.cropRegion.xMin, _this.cropRegion.yMax,
                                        _this.cropRegion.xMax
                                    ]]);
                                // The batch index that the crop should operate on. A [batch] size
                                // tensor.
                                var boxInd = tf.zeros([1], 'int32');
                                // Target size of each crop.
                                var cropSize = [_this.modelInputResolution.height, _this.modelInputResolution.width];
                                return tf.cast(tf.image.cropAndResize(imageTensor4D, cropRegionTensor, boxInd, cropSize, 'bilinear', 0), 'int32');
                            });
                            imageTensor4D.dispose();
                            return [4 /*yield*/, this.runSinglePersonPoseModel(croppedImage)];
                        case 1:
                            pose = _a.sent();
                            croppedImage.dispose();
                            if (pose.score < this.minPoseScore) {
                                this.reset();
                                return [2 /*return*/, []];
                            }
                            // Convert keypoints from crop coordinates to image coordinates.
                            for (i = 0; i < pose.keypoints.length; ++i) {
                                pose.keypoints[i].y =
                                    this.cropRegion.yMin + pose.keypoints[i].y * this.cropRegion.height;
                                pose.keypoints[i].x =
                                    this.cropRegion.xMin + pose.keypoints[i].x * this.cropRegion.width;
                            }
                            // Apply the sequential filter before estimating the cropping area to make
                            // it more stable.
                            if (timestamp != null && this.enableSmoothing) {
                                pose.keypoints = this.keypointFilter.apply(pose.keypoints, timestamp, 1 /* objectScale */);
                            }
                            nextCropRegion = determineNextCropRegion(this.cropRegion, pose.keypoints, this.keypointIndexByName, imageSize);
                            this.cropRegion = this.filterCropRegion(nextCropRegion);
                            return [2 /*return*/, [pose]];
                    }
                });
            });
        };
        /**
         * Runs a multi-person keypoint model on an image, including image
         * preprocessing.
         *
         * @param imageTensor4D A tf.Tensor4D that contains the input image.
         * @param imageSize: The width and height of the input image.
         * @param timestamp Image timestamp in microseconds.
         * @return An array of `Pose`s.
         */
        MoveNetDetector.prototype.estimateMultiplePoses = function (imageTensor4D, imageSize, timestamp) {
            return __awaiter(this, void 0, void 0, function () {
                var resizedImage, resizedWidth, resizedHeight, paddedImage, paddedWidth, paddedHeight, dimensionDivisor, paddedImageInt32, poses, i, j, i, trackIDs_1;
                var _this = this;
                return __generator(this, function (_a) {
                    switch (_a.label) {
                        case 0:
                            dimensionDivisor = 32;
                            if (imageSize.width > imageSize.height) {
                                resizedWidth = this.multiPoseMaxDimension;
                                resizedHeight = Math.round(this.multiPoseMaxDimension * imageSize.height / imageSize.width);
                                resizedImage =
                                    tf.image.resizeBilinear(imageTensor4D, [resizedHeight, resizedWidth]);
                                paddedWidth = resizedWidth;
                                paddedHeight =
                                    Math.ceil(resizedHeight / dimensionDivisor) * dimensionDivisor;
                                paddedImage = tf.pad(resizedImage, [[0, 0], [0, paddedHeight - resizedHeight], [0, 0], [0, 0]]);
                            }
                            else {
                                resizedWidth = Math.round(this.multiPoseMaxDimension * imageSize.width / imageSize.height);
                                resizedHeight = this.multiPoseMaxDimension;
                                resizedImage =
                                    tf.image.resizeBilinear(imageTensor4D, [resizedHeight, resizedWidth]);
                                paddedWidth =
                                    Math.ceil(resizedWidth / dimensionDivisor) * dimensionDivisor;
                                paddedHeight = resizedHeight;
                                paddedImage = tf.pad(resizedImage, [[0, 0], [0, 0], [0, paddedWidth - resizedWidth], [0, 0]]);
                            }
                            resizedImage.dispose();
                            imageTensor4D.dispose();
                            paddedImageInt32 = tf.cast(paddedImage, 'int32');
                            paddedImage.dispose();
                            return [4 /*yield*/, this.runMultiPersonPoseModel(paddedImageInt32)];
                        case 1:
                            poses = _a.sent();
                            paddedImageInt32.dispose();
                            poses = poses.filter(function (pose) { return pose.score >= _this.minPoseScore; });
                            // Convert keypoints from padded coordinates to normalized coordinates.
                            for (i = 0; i < poses.length; ++i) {
                                for (j = 0; j < poses[i].keypoints.length; ++j) {
                                    poses[i].keypoints[j].y *= paddedHeight / resizedHeight;
                                    poses[i].keypoints[j].x *= paddedWidth / resizedWidth;
                                }
                            }
                            if (this.enableTracking) {
                                this.tracker.apply(poses, timestamp);
                                if (this.enableSmoothing) {
                                    for (i = 0; i < poses.length; ++i) {
                                        if (!this.keypointFilterMap.has(poses[i].id)) {
                                            this.keypointFilterMap.set(poses[i].id, new KeypointsOneEuroFilter(KEYPOINT_FILTER_CONFIG));
                                        }
                                        poses[i].keypoints =
                                            this.keypointFilterMap.get(poses[i].id)
                                                .apply(poses[i].keypoints, timestamp, 1 /* objectScale */);
                                    }
                                    trackIDs_1 = this.tracker.getTrackIDs();
                                    this.keypointFilterMap.forEach(function (_, trackID) {
                                        if (!trackIDs_1.has(trackID)) {
                                            _this.keypointFilterMap.delete(trackID);
                                        }
                                    });
                                }
                            }
                            return [2 /*return*/, poses];
                    }
                });
            });
        };
        MoveNetDetector.prototype.filterCropRegion = function (newCropRegion) {
            if (!newCropRegion) {
                this.cropRegionFilterYMin.reset();
                this.cropRegionFilterXMin.reset();
                this.cropRegionFilterYMax.reset();
                this.cropRegionFilterXMax.reset();
                return null;
            }
            else {
                var filteredYMin = this.cropRegionFilterYMin.apply(newCropRegion.yMin);
                var filteredXMin = this.cropRegionFilterXMin.apply(newCropRegion.xMin);
                var filteredYMax = this.cropRegionFilterYMax.apply(newCropRegion.yMax);
                var filteredXMax = this.cropRegionFilterXMax.apply(newCropRegion.xMax);
                return {
                    yMin: filteredYMin,
                    xMin: filteredXMin,
                    yMax: filteredYMax,
                    xMax: filteredXMax,
                    height: filteredYMax - filteredYMin,
                    width: filteredXMax - filteredXMin
                };
            }
        };
        MoveNetDetector.prototype.dispose = function () {
            this.moveNetModel.dispose();
        };
        MoveNetDetector.prototype.reset = function () {
            this.cropRegion = null;
            this.resetFilters();
        };
        MoveNetDetector.prototype.resetFilters = function () {
            this.keypointFilter.reset();
            this.cropRegionFilterYMin.reset();
            this.cropRegionFilterXMin.reset();
            this.cropRegionFilterYMax.reset();
            this.cropRegionFilterXMax.reset();
        };
        return MoveNetDetector;
    }());
    /**
     * Loads the MoveNet model instance from a checkpoint. The model to be loaded
     * is configurable using the config dictionary `ModelConfig`. Please find more
     * details in the documentation of the `ModelConfig`.
     *
     * @param config `ModelConfig` dictionary that contains parameters for
     * the MoveNet loading process. Please find more details of each parameter
     * in the documentation of the `ModelConfig` interface.
     */
    function load$2(modelConfig) {
        if (modelConfig === void 0) { modelConfig = MOVENET_CONFIG; }
        return __awaiter(this, void 0, void 0, function () {
            var config, model, fromTFHub, modelUrl;
            return __generator(this, function (_a) {
                switch (_a.label) {
                    case 0:
                        config = validateModelConfig$2(modelConfig);
                        fromTFHub = true;
                        if (!!!config.modelUrl) return [3 /*break*/, 2];
                        fromTFHub = typeof config.modelUrl === 'string' &&
                            config.modelUrl.indexOf('https://tfhub.dev') > -1;
                        return [4 /*yield*/, tfconv.loadGraphModel(config.modelUrl, { fromTFHub: fromTFHub })];
                    case 1:
                        model = _a.sent();
                        return [3 /*break*/, 4];
                    case 2:
                        modelUrl = void 0;
                        if (config.modelType === SINGLEPOSE_LIGHTNING) {
                            modelUrl = MOVENET_SINGLEPOSE_LIGHTNING_URL;
                        }
                        else if (config.modelType === SINGLEPOSE_THUNDER) {
                            modelUrl = MOVENET_SINGLEPOSE_THUNDER_URL;
                        }
                        else if (config.modelType === MULTIPOSE_LIGHTNING) {
                            modelUrl = MOVENET_MULTIPOSE_LIGHTNING_URL;
                        }
                        return [4 /*yield*/, tfconv.loadGraphModel(modelUrl, { fromTFHub: fromTFHub })];
                    case 3:
                        model = _a.sent();
                        _a.label = 4;
                    case 4:
                        if (tf.getBackend() === 'webgl') {
                            // MoveNet has a top-k op that runs faster on GPU for the size of our last
                            // dimension (6400). There are three checks that could make the top-k op run
                            // on CPU (see
                            // https://github.com/tensorflow/tfjs/blob/master/tfjs-backend-webgl/src/kernels/TopK.ts)
                            //
                            // 1. All input shapes < 128
                            // 2. lastDim < TOPK_LAST_DIM_CPU_HANDOFF_SIZE_THRESHOLD
                            // 3. k > TOPK_K_CPU_HANDOFF_THRESHOLD
                            //
                            // In our case, setting TOPK_LAST_DIM_CPU_HANDOFF_SIZE_THRESHOLD = 0 will
                            // will disable the CPU forwarding.
                            tf.env().set('TOPK_LAST_DIM_CPU_HANDOFF_SIZE_THRESHOLD', 0);
                        }
                        return [2 /*return*/, new MoveNetDetector(model, config)];
                }
            });
        });
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * https://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    // The default configuration for loading MobileNetV1 based PoseNet.
    //
    // (And for references, the default configuration for loading ResNet
    // based PoseNet is also included).
    //
    // ```
    // const RESNET_CONFIG = {
    //   architecture: 'ResNet50',
    //   outputStride: 32,
    //   quantBytes: 2,
    // } as ModelConfig;
    // ```
    var MOBILENET_V1_CONFIG = {
        architecture: 'MobileNetV1',
        outputStride: 16,
        multiplier: 0.75,
        inputResolution: { height: 257, width: 257 }
    };
    var VALID_ARCHITECTURE = ['MobileNetV1', 'ResNet50'];
    var VALID_STRIDE = {
        'MobileNetV1': [8, 16],
        'ResNet50': [16]
    };
    var VALID_OUTPUT_STRIDES = [8, 16, 32];
    var VALID_MULTIPLIER = {
        'MobileNetV1': [0.50, 0.75, 1.0],
        'ResNet50': [1.0]
    };
    var VALID_QUANT_BYTES = [1, 2, 4];
    var SINGLE_PERSON_ESTIMATION_CONFIG = {
        maxPoses: 1,
        flipHorizontal: false
    };
    var MULTI_PERSON_ESTIMATION_CONFIG = {
        maxPoses: 5,
        flipHorizontal: false,
        scoreThreshold: 0.5,
        nmsRadius: 20
    };
    var RESNET_MEAN = [-123.15, -115.90, -103.06];
    // A point (y, x) is considered as root part candidate if its score is a
    // maximum in a window |y - y'| <= kLocalMaximumRadius, |x - x'| <=
    // kLocalMaximumRadius.
    var K_LOCAL_MAXIMUM_RADIUS = 1;
    var NUM_KEYPOINTS$1 = 17;
    /*
     * Define the skeleton. This defines the parent->child relationships of our
     * tree. Arbitrarily this defines the nose as the root of the tree, however
     * since we will infer the displacement for both parent->child and
     * child->parent, we can define the tree root as any node.
     */
    var POSE_CHAIN = [
        ['nose', 'left_eye'], ['left_eye', 'left_ear'], ['nose', 'right_eye'],
        ['right_eye', 'right_ear'], ['nose', 'left_shoulder'],
        ['left_shoulder', 'left_elbow'], ['left_elbow', 'left_wrist'],
        ['left_shoulder', 'left_hip'], ['left_hip', 'left_knee'],
        ['left_knee', 'left_ankle'], ['nose', 'right_shoulder'],
        ['right_shoulder', 'right_elbow'], ['right_elbow', 'right_wrist'],
        ['right_shoulder', 'right_hip'], ['right_hip', 'right_knee'],
        ['right_knee', 'right_ankle']
    ];

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    // algorithm based on Coursera Lecture from Algorithms, Part 1:
    // https://www.coursera.org/learn/algorithms-part1/lecture/ZjoSM/heapsort
    function half(k) {
        return Math.floor(k / 2);
    }
    var MaxHeap = /** @class */ (function () {
        function MaxHeap(maxSize, getElementValue) {
            this.priorityQueue = new Array(maxSize);
            this.numberOfElements = -1;
            this.getElementValue = getElementValue;
        }
        MaxHeap.prototype.enqueue = function (x) {
            this.priorityQueue[++this.numberOfElements] = x;
            this.swim(this.numberOfElements);
        };
        MaxHeap.prototype.dequeue = function () {
            var max = this.priorityQueue[0];
            this.exchange(0, this.numberOfElements--);
            this.sink(0);
            this.priorityQueue[this.numberOfElements + 1] = null;
            return max;
        };
        MaxHeap.prototype.empty = function () {
            return this.numberOfElements === -1;
        };
        MaxHeap.prototype.size = function () {
            return this.numberOfElements + 1;
        };
        MaxHeap.prototype.all = function () {
            return this.priorityQueue.slice(0, this.numberOfElements + 1);
        };
        MaxHeap.prototype.max = function () {
            return this.priorityQueue[0];
        };
        MaxHeap.prototype.swim = function (k) {
            while (k > 0 && this.less(half(k), k)) {
                this.exchange(k, half(k));
                k = half(k);
            }
        };
        MaxHeap.prototype.sink = function (k) {
            while (2 * k <= this.numberOfElements) {
                var j = 2 * k;
                if (j < this.numberOfElements && this.less(j, j + 1)) {
                    j++;
                }
                if (!this.less(k, j)) {
                    break;
                }
                this.exchange(k, j);
                k = j;
            }
        };
        MaxHeap.prototype.getValueAt = function (i) {
            return this.getElementValue(this.priorityQueue[i]);
        };
        MaxHeap.prototype.less = function (i, j) {
            return this.getValueAt(i) < this.getValueAt(j);
        };
        MaxHeap.prototype.exchange = function (i, j) {
            var t = this.priorityQueue[i];
            this.priorityQueue[i] = this.priorityQueue[j];
            this.priorityQueue[j] = t;
        };
        return MaxHeap;
    }());

    function scoreIsMaximumInLocalWindow(keypointId, score, heatmapY, heatmapX, localMaximumRadius, scores) {
        var _a = scores.shape, height = _a[0], width = _a[1];
        var localMaximum = true;
        var yStart = Math.max(heatmapY - localMaximumRadius, 0);
        var yEnd = Math.min(heatmapY + localMaximumRadius + 1, height);
        for (var yCurrent = yStart; yCurrent < yEnd; ++yCurrent) {
            var xStart = Math.max(heatmapX - localMaximumRadius, 0);
            var xEnd = Math.min(heatmapX + localMaximumRadius + 1, width);
            for (var xCurrent = xStart; xCurrent < xEnd; ++xCurrent) {
                if (scores.get(yCurrent, xCurrent, keypointId) > score) {
                    localMaximum = false;
                    break;
                }
            }
            if (!localMaximum) {
                break;
            }
        }
        return localMaximum;
    }
    /**
     * Builds a priority queue with part candidate positions for a specific image in
     * the batch. For this we find all local maxima in the score maps with score
     * values above a threshold. We create a single priority queue across all parts.
     */
    function buildPartWithScoreQueue(scoreThreshold, localMaximumRadius, scores) {
        var _a = scores.shape, height = _a[0], width = _a[1], numKeypoints = _a[2];
        var queue = new MaxHeap(height * width * numKeypoints, function (_a) {
            var score = _a.score;
            return score;
        });
        for (var heatmapY = 0; heatmapY < height; ++heatmapY) {
            for (var heatmapX = 0; heatmapX < width; ++heatmapX) {
                for (var keypointId = 0; keypointId < numKeypoints; ++keypointId) {
                    var score = scores.get(heatmapY, heatmapX, keypointId);
                    // Only consider parts with score greater or equal to threshold as
                    // root candidates.
                    if (score < scoreThreshold) {
                        continue;
                    }
                    // Only consider keypoints whose score is maximum in a local window.
                    if (scoreIsMaximumInLocalWindow(keypointId, score, heatmapY, heatmapX, localMaximumRadius, scores)) {
                        queue.enqueue({ score: score, part: { heatmapY: heatmapY, heatmapX: heatmapX, id: keypointId } });
                    }
                }
            }
        }
        return queue;
    }

    function toTensorBuffers3D(tensors) {
        return __awaiter(this, void 0, void 0, function () {
            return __generator(this, function (_a) {
                return [2 /*return*/, Promise.all(tensors.map(function (tensor) { return tensor.buffer(); }))];
            });
        });
    }
    function getOffsetPoint(y, x, keypoint, offsets) {
        return {
            y: offsets.get(y, x, keypoint),
            x: offsets.get(y, x, keypoint + NUM_KEYPOINTS$1)
        };
    }
    function getImageCoords(part, outputStride, offsets) {
        var heatmapY = part.heatmapY, heatmapX = part.heatmapX, keypoint = part.id;
        var _a = getOffsetPoint(heatmapY, heatmapX, keypoint, offsets), y = _a.y, x = _a.x;
        return {
            x: part.heatmapX * outputStride + x,
            y: part.heatmapY * outputStride + y
        };
    }
    function squaredDistance(y1, x1, y2, x2) {
        var dy = y2 - y1;
        var dx = x2 - x1;
        return dy * dy + dx * dx;
    }
    function withinNmsRadiusOfCorrespondingPoint(poses, squaredNmsRadius, _a, keypointId) {
        var x = _a.x, y = _a.y;
        return poses.some(function (_a) {
            var keypoints = _a.keypoints;
            return squaredDistance(y, x, keypoints[keypointId].y, keypoints[keypointId].x) <=
                squaredNmsRadius;
        });
    }
    var partIds = 
    // tslint:disable-next-line: no-unnecessary-type-assertion
    COCO_KEYPOINTS.reduce(function (result, jointName, i) {
        result[jointName] = i;
        return result;
    }, {});
    var parentChildrenTuples = POSE_CHAIN.map(function (_a) {
        var parentJoinName = _a[0], childJoinName = _a[1];
        return ([partIds[parentJoinName], partIds[childJoinName]]);
    });
    var parentToChildEdges = parentChildrenTuples.map(function (_a) {
        var childJointId = _a[1];
        return childJointId;
    });
    var childToParentEdges = parentChildrenTuples.map(function (_a) {
        var parentJointId = _a[0];
        return parentJointId;
    });
    function clamp(a, min, max) {
        if (a < min) {
            return min;
        }
        if (a > max) {
            return max;
        }
        return a;
    }
    function getStridedIndexNearPoint(point, outputStride, height, width) {
        return {
            y: clamp(Math.round(point.y / outputStride), 0, height - 1),
            x: clamp(Math.round(point.x / outputStride), 0, width - 1)
        };
    }
    function getDisplacement(edgeId, point, displacements) {
        var numEdges = displacements.shape[2] / 2;
        return {
            y: displacements.get(point.y, point.x, edgeId),
            x: displacements.get(point.y, point.x, numEdges + edgeId)
        };
    }
    function addVectors(a, b) {
        return { x: a.x + b.x, y: a.y + b.y };
    }
    /**
     * We get a new keypoint along the `edgeId` for the pose instance, assuming
     * that the position of the `idSource` part is already known. For this, we
     * follow the displacement vector from the source to target part (stored in
     * the `i`-t channel of the displacement tensor). The displaced keypoint
     * vector is refined using the offset vector by `offsetRefineStep` times.
     */
    function traverseToTargetKeypoint(edgeId, sourceKeypoint, targetKeypointId, scoresBuffer, offsets, outputStride, displacements, offsetRefineStep) {
        if (offsetRefineStep === void 0) { offsetRefineStep = 2; }
        var _a = scoresBuffer.shape, height = _a[0], width = _a[1];
        var point = { y: sourceKeypoint.y, x: sourceKeypoint.x };
        // Nearest neighbor interpolation for the source->target displacements.
        var sourceKeypointIndices = getStridedIndexNearPoint(point, outputStride, height, width);
        var displacement = getDisplacement(edgeId, sourceKeypointIndices, displacements);
        var displacedPoint = addVectors(point, displacement);
        var targetKeypoint = displacedPoint;
        for (var i = 0; i < offsetRefineStep; i++) {
            var targetKeypointIndices = getStridedIndexNearPoint(targetKeypoint, outputStride, height, width);
            var offsetPoint = getOffsetPoint(targetKeypointIndices.y, targetKeypointIndices.x, targetKeypointId, offsets);
            targetKeypoint = addVectors({
                x: targetKeypointIndices.x * outputStride,
                y: targetKeypointIndices.y * outputStride
            }, { x: offsetPoint.x, y: offsetPoint.y });
        }
        var targetKeyPointIndices = getStridedIndexNearPoint(targetKeypoint, outputStride, height, width);
        var score = scoresBuffer.get(targetKeyPointIndices.y, targetKeyPointIndices.x, targetKeypointId);
        return {
            y: targetKeypoint.y,
            x: targetKeypoint.x,
            name: COCO_KEYPOINTS[targetKeypointId],
            score: score
        };
    }
    /**
     * Follows the displacement fields to decode the full pose of the object
     * instance given the position of a part that acts as root.
     *
     * @return An array of decoded keypoints and their scores for a single pose
     */
    function decodePose(root, scores, offsets, outputStride, displacementsFwd, displacementsBwd) {
        var numParts = scores.shape[2];
        var numEdges = parentToChildEdges.length;
        var instanceKeypoints = new Array(numParts);
        // Start a new detection instance at the position of the root.
        var rootPart = root.part, rootScore = root.score;
        var rootPoint = getImageCoords(rootPart, outputStride, offsets);
        instanceKeypoints[rootPart.id] = {
            score: rootScore,
            name: COCO_KEYPOINTS[rootPart.id],
            y: rootPoint.y,
            x: rootPoint.x
        };
        // Decode the part positions upwards in the tree, following the backward
        // displacements.
        for (var edge = numEdges - 1; edge >= 0; --edge) {
            var sourceKeypointId = parentToChildEdges[edge];
            var targetKeypointId = childToParentEdges[edge];
            if (instanceKeypoints[sourceKeypointId] &&
                !instanceKeypoints[targetKeypointId]) {
                instanceKeypoints[targetKeypointId] = traverseToTargetKeypoint(edge, instanceKeypoints[sourceKeypointId], targetKeypointId, scores, offsets, outputStride, displacementsBwd);
            }
        }
        // Decode the part positions downwards in the tree, following the forward
        // displacements.
        for (var edge = 0; edge < numEdges; ++edge) {
            var sourceKeypointId = childToParentEdges[edge];
            var targetKeypointId = parentToChildEdges[edge];
            if (instanceKeypoints[sourceKeypointId] &&
                !instanceKeypoints[targetKeypointId]) {
                instanceKeypoints[targetKeypointId] = traverseToTargetKeypoint(edge, instanceKeypoints[sourceKeypointId], targetKeypointId, scores, offsets, outputStride, displacementsFwd);
            }
        }
        return instanceKeypoints;
    }
    /* Score the newly proposed object instance without taking into account
     * the scores of the parts that overlap with any previously detected
     * instance.
     */
    function getInstanceScore(existingPoses, squaredNmsRadius, instanceKeypoints) {
        var notOverlappedKeypointScores = instanceKeypoints.reduce(function (result, _a, keypointId) {
            var y = _a.y, x = _a.x, score = _a.score;
            if (!withinNmsRadiusOfCorrespondingPoint(existingPoses, squaredNmsRadius, { y: y, x: x }, keypointId)) {
                result += score;
            }
            return result;
        }, 0.0);
        return notOverlappedKeypointScores /= instanceKeypoints.length;
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    /**
     * Detects multiple poses and finds their parts from part scores and
     * displacement vectors. It returns up to `maxDetections` object instance
     * detections in decreasing root score order. It works as follows: We first
     * create a priority queue with local part score maxima above
     * `scoreThreshold`, considering all parts at the same time. Then we
     * iteratively pull the top  element of the queue (in decreasing score order)
     * and treat it as a root candidate for a new object instance. To avoid
     * duplicate detections, we reject the root candidate if it is within a disk
     * of `nmsRadius` pixels from the corresponding part of a previously detected
     * instance, which is a form of part-based non-maximum suppression (NMS). If
     * the root candidate passes the NMS check, we start a new object instance
     * detection, treating the corresponding part as root and finding the
     * positions of the remaining parts by following the displacement vectors
     * along the tree-structured part graph. We assign to the newly detected
     * instance a score equal to the sum of scores of its parts which have not
     * been claimed by a previous instance (i.e., those at least `nmsRadius`
     * pixels away from the corresponding part of all previously detected
     * instances), divided by the total number of parts `numParts`.
     *
     * @param heatmapScores 3-D tensor with shape `[height, width, numParts]`.
     * The value of heatmapScores[y, x, k]` is the score of placing the `k`-th
     * object part at position `(y, x)`.
     *
     * @param offsets 3-D tensor with shape `[height, width, numParts * 2]`.
     * The value of [offsets[y, x, k], offsets[y, x, k + numParts]]` is the
     * short range offset vector of the `k`-th  object part at heatmap
     * position `(y, x)`.
     *
     * @param displacementsFwd 3-D tensor of shape
     * `[height, width, 2 * num_edges]`, where `num_edges = num_parts - 1` is the
     * number of edges (parent-child pairs) in the tree. It contains the forward
     * displacements between consecutive part from the root towards the leaves.
     *
     * @param displacementsBwd 3-D tensor of shape
     * `[height, width, 2 * num_edges]`, where `num_edges = num_parts - 1` is the
     * number of edges (parent-child pairs) in the tree. It contains the backward
     * displacements between consecutive part from the root towards the leaves.
     *
     * @param outputStride The output stride that was used when feed-forwarding
     * through the PoseNet model.  Must be 32, 16, or 8.
     *
     * @param maxPoseDetections Maximum number of returned instance detections per
     * image.
     *
     * @param scoreThreshold Only return instance detections that have root part
     * score greater or equal to this value. Defaults to 0.5.
     *
     * @param nmsRadius Non-maximum suppression part distance. It needs to be
     * strictly positive. Two parts suppress each other if they are less than
     * `nmsRadius` pixels away. Defaults to 20.
     *
     * @return An array of poses and their scores, each containing keypoints and
     * the corresponding keypoint scores.
     */
    function decodeMultiplePoses(heatmapScores, offsets, displacementFwd, displacementBwd, outputStride, maxPoseDetections, scoreThreshold, nmsRadius) {
        if (scoreThreshold === void 0) { scoreThreshold = 0.5; }
        if (nmsRadius === void 0) { nmsRadius = 20; }
        return __awaiter(this, void 0, void 0, function () {
            var _a, scoresBuffer, offsetsBuffer, displacementsFwdBuffer, displacementsBwdBuffer, poses, queue, squaredNmsRadius, root, rootImageCoords, keypoints, score;
            return __generator(this, function (_b) {
                switch (_b.label) {
                    case 0: return [4 /*yield*/, toTensorBuffers3D([heatmapScores, offsets, displacementFwd, displacementBwd])];
                    case 1:
                        _a = _b.sent(), scoresBuffer = _a[0], offsetsBuffer = _a[1], displacementsFwdBuffer = _a[2], displacementsBwdBuffer = _a[3];
                        poses = [];
                        queue = buildPartWithScoreQueue(scoreThreshold, K_LOCAL_MAXIMUM_RADIUS, scoresBuffer);
                        squaredNmsRadius = nmsRadius * nmsRadius;
                        // Generate at most maxDetections object instances per image in
                        // decreasing root part score order.
                        while (poses.length < maxPoseDetections && !queue.empty()) {
                            root = queue.dequeue();
                            rootImageCoords = getImageCoords(root.part, outputStride, offsetsBuffer);
                            if (withinNmsRadiusOfCorrespondingPoint(poses, squaredNmsRadius, rootImageCoords, root.part.id)) {
                                continue;
                            }
                            keypoints = decodePose(root, scoresBuffer, offsetsBuffer, outputStride, displacementsFwdBuffer, displacementsBwdBuffer);
                            score = getInstanceScore(poses, squaredNmsRadius, keypoints);
                            poses.push({ keypoints: keypoints, score: score });
                        }
                        return [2 /*return*/, poses];
                }
            });
        });
    }

    /**
     * @license
     * Copyright 2019 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const ENV = tf.env();
    /** The batched dispatching calls size in the device queue. */
    ENV.registerFlag('WEBGPU_DEFERRED_SUBMIT_BATCH_SIZE', () => 15);
    /**
     * Whether we forward execution to the CPU backend if tensors are small and
     * reside on the CPU.
     */
    ENV.registerFlag('WEBGPU_CPU_FORWARD', () => true);
    /**
     * This flag is used to test different types of matmul programs.
     *
     * See MatMulProgramType in webgpu_util.ts for a list of available values.
     */
    ENV.registerFlag('WEBGPU_MATMUL_PROGRAM_TYPE', () => -1);
    /**
     * Whether to use conv2dTranspose_naive which directly implement the
     * conv2dTranspose logic rather than using a matmul to simulate.
     */
    ENV.registerFlag('WEBGPU_USE_NAIVE_CONV2D_TRANSPOSE', () => false);
    /**
     * Whether we use low power GPU. Otherwise, a high performance GPU will be
     * requested.
     */
    ENV.registerFlag('WEBGPU_USE_LOW_POWER_GPU', () => false);
    /**
     * Threshold for input tensor size that determines whether WebGPU backend will
     * delegate computation to CPU.
     *
     * Default value is 1000.
     */
    ENV.registerFlag('WEBGPU_CPU_HANDOFF_SIZE_THRESHOLD', () => 1000);
    /**
     * Whether to use a dummy canvas to make profiling tools like PIX work with
     * TFJS webgpu backend.
     */
    ENV.registerFlag('WEBGPU_USE_PROFILE_TOOL', () => false);
    /**
     * Whether to use import API.
     */
    ENV.registerFlag('WEBGPU_IMPORT_EXTERNAL_TEXTURE', () => true);
    /**
     * Whether to use conv2dNaive for debugging.
     */
    ENV.registerFlag('WEBGPU_USE_NAIVE_CONV2D_DEBUG', () => false);
    /**
     * Threshold to increase dispatched workgroups for matmul. If too few workgroups
     * are dispatched, it means the hardware may be in low occupancy.
     * 0 means it's not set by the user. A default strategy will be applied.
     */
    ENV.registerFlag('WEBGPU_THRESHOLD_TO_INCREASE_WORKGROUPS_FOR_MATMUL', () => 0);
    /**
     * Whether we will run im2col as a separate shader for convolution.
     */
    ENV.registerFlag('WEBGPU_CONV_SEPARATE_IM2COL_SHADER', () => false);

    /**
     * @license
     * Copyright 2022 Google LLC.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    class AdapterInfo {
        constructor(adapterInfo) {
            if (adapterInfo) {
                this.vendor = adapterInfo.vendor;
                this.architecture = adapterInfo.architecture;
                this.intelGPUGeneration = this.getIntelGPUGeneration();
            }
        }
        getIntelGPUGeneration() {
            if (this.isIntel()) {
                if (this.architecture.startsWith('gen')) {
                    return Number(this.architecture.match(/\d+/));
                }
                else if (this.architecture.startsWith('xe')) {
                    return 12;
                }
            }
            return 0;
        }
        isIntel() {
            return this.vendor === 'intel';
        }
    }

    /**
     * @license
     * Copyright 2019 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    class BufferManager {
        constructor(device) {
            this.device = device;
            this.numUsedBuffers = 0;
            this.numFreeBuffers = 0;
            this.freeBuffers = new Map();
            this.usedBuffers = new Map();
            this.numBytesUsed = 0;
            this.numBytesAllocated = 0;
        }
        acquireUploadBuffer(size, usage) {
            return this.acquireBuffer(size, usage, true);
        }
        acquireBuffer(size, usage, mappedAtCreation = false) {
            const key = getBufferKey(size, usage);
            if (!this.freeBuffers.has(key)) {
                this.freeBuffers.set(key, []);
            }
            if (!this.usedBuffers.has(key)) {
                this.usedBuffers.set(key, []);
            }
            this.numBytesUsed += size;
            this.numUsedBuffers++;
            if (this.freeBuffers.get(key).length > 0) {
                this.numFreeBuffers--;
                const newBuffer = this.freeBuffers.get(key).shift();
                this.usedBuffers.get(key).push(newBuffer);
                return newBuffer;
            }
            this.numBytesAllocated += size;
            const newBuffer = this.device.createBuffer({ size, usage, mappedAtCreation });
            this.usedBuffers.get(key).push(newBuffer);
            return newBuffer;
        }
        releaseBuffer(buffer, size, usage) {
            if (this.freeBuffers.size === 0) {
                return;
            }
            const key = getBufferKey(size, usage);
            if (!this.freeBuffers.has(key)) {
                this.freeBuffers.set(key, []);
            }
            this.freeBuffers.get(key).push(buffer);
            this.numFreeBuffers++;
            this.numUsedBuffers--;
            const bufferList = this.usedBuffers.get(key);
            const bufferIndex = bufferList.indexOf(buffer);
            if (bufferIndex < 0) {
                throw new Error('Cannot release a buffer that was never provided by this ' +
                    'buffer manager');
            }
            bufferList.splice(bufferIndex, 1);
            this.numBytesUsed -= size;
        }
        releaseUploadBuffer(buffer, size, usage) {
            buffer.mapAsync(GPUMapMode.WRITE)
                .then(() => {
                this.releaseBuffer(buffer, size, usage);
            }, (err) => {
                // Do nothing;
            });
        }
        getNumUsedBuffers() {
            return this.numUsedBuffers;
        }
        getNumFreeBuffers() {
            return this.numFreeBuffers;
        }
        dispose() {
            this.freeBuffers.forEach((buffers, key) => {
                buffers.forEach(buffer => {
                    buffer.destroy();
                });
            });
            this.usedBuffers.forEach((buffers, key) => {
                buffers.forEach(buffer => {
                    buffer.destroy();
                });
            });
            this.freeBuffers = new Map();
            this.usedBuffers = new Map();
            this.numUsedBuffers = 0;
            this.numFreeBuffers = 0;
            this.numBytesUsed = 0;
            this.numBytesAllocated = 0;
        }
    }
    function getBufferKey(size, usage) {
        return `${size}_${usage}`;
    }

    /**
     * @license
     * Copyright 2022 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    class TextureManager {
        constructor(device) {
            this.device = device;
            this.numUsedTextures = 0;
            this.numFreeTextures = 0;
            this.freeTextures = new Map();
            this.usedTextures = new Map();
            this.numBytesUsed = 0;
            this.numBytesAllocated = 0;
        }
        acquireTexture(width, height, format, usage) {
            const bytesPerElement = getBytesPerElement(format);
            const byteSize = width * height * bytesPerElement;
            const key = getTextureKey(width, height, format, usage);
            if (!this.freeTextures.has(key)) {
                this.freeTextures.set(key, []);
            }
            if (!this.usedTextures.has(key)) {
                this.usedTextures.set(key, []);
            }
            this.numBytesUsed += byteSize;
            this.numUsedTextures++;
            if (this.freeTextures.get(key).length > 0) {
                this.numFreeTextures--;
                const newTexture = this.freeTextures.get(key).shift();
                this.usedTextures.get(key).push(newTexture);
                return newTexture;
            }
            this.numBytesAllocated += byteSize;
            const newTexture = this.device.createTexture({
                size: [width, height],
                format,
                usage,
            });
            this.usedTextures.get(key).push(newTexture);
            return newTexture;
        }
        releaseTexture(texture, width, height, format, usage) {
            if (this.freeTextures.size === 0) {
                return;
            }
            const key = getTextureKey(width, height, format, usage);
            if (!this.freeTextures.has(key)) {
                this.freeTextures.set(key, []);
            }
            this.freeTextures.get(key).push(texture);
            this.numFreeTextures++;
            this.numUsedTextures--;
            const textureList = this.usedTextures.get(key);
            const textureIndex = textureList.indexOf(texture);
            if (textureIndex < 0) {
                throw new Error('Cannot release a texture that was never provided by this ' +
                    'texture manager');
            }
            textureList.splice(textureIndex, 1);
            const bytesPerElement = getBytesPerElement(format);
            const byteSize = width * height * bytesPerElement;
            this.numBytesUsed -= byteSize;
        }
        getNumUsedTextures() {
            return this.numUsedTextures;
        }
        getNumFreeTextures() {
            return this.numFreeTextures;
        }
        dispose() {
            this.freeTextures.forEach((textures, key) => {
                textures.forEach(texture => {
                    texture.destroy();
                });
            });
            this.usedTextures.forEach((textures, key) => {
                textures.forEach(texture => {
                    texture.destroy();
                });
            });
            this.freeTextures = new Map();
            this.usedTextures = new Map();
            this.numUsedTextures = 0;
            this.numFreeTextures = 0;
            this.numBytesUsed = 0;
            this.numBytesAllocated = 0;
        }
    }
    function getTextureKey(width, height, format, usage) {
        return `${width}_${height}_${format}_${usage}`;
    }
    function getBytesPerElement(format) {
        if (format === 'rgba8unorm') {
            return 16;
        }
        else {
            throw new Error(`${format} is not supported!`);
        }
    }

    /**
     * @license
     * Copyright 2019 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    // Generates WGSL that computes strides.
    function symbolicallyComputeStrides(indicesArr, variableName) {
        if (Math.max(...indicesArr) > 3) {
            throw new Error('Cannot symbolically compute strides for rank > 4 tensor.');
        }
        const numCoords = indicesArr.length;
        const shape = indicesArr.map(d => `${variableName}[${d}]`);
        const strides = new Array(numCoords - 1);
        strides[numCoords - 2] = shape[numCoords - 1];
        for (let i = numCoords - 3; i >= 0; --i) {
            strides[i] = `(${strides[i + 1]} * ${shape[i + 1]})`;
        }
        return strides;
    }
    const atomicAddSnippet = (ptr, v, type) => {
        if (type === 'int32') {
            return `atomicAdd(${ptr}, bitcast<i32>(${v}));`;
        }
        else {
            // atomicAdd only supports uint/int type. For float, we use
            // atomicCompareExchangeWeak to simulate.
            return `
          {
            var oldValue = 0;
            loop {
              let newValueF32 = bitcast<f32>(oldValue) + (${v});
              let newValue = bitcast<i32>(newValueF32);
              let res = atomicCompareExchangeWeak(${ptr}, oldValue, newValue);
              if res.exchanged {
                break;
              }
              oldValue = res.old_value;
            }
          }`;
        }
    };

    /**
     * @license
     * Copyright 2022 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const compileProgram = (device, program, inputsData, output) => {
        const outputData = { dtype: output.dtype, shape: output.shape };
        const source = makeShader(inputsData, outputData, program);
        const module = device.createShaderModule({ code: source, label: program.constructor.name });
        const pipeline = device.createComputePipeline({
            compute: { module, entryPoint: '_start' },
            label: program.constructor.name,
            layout: 'auto'
        });
        return pipeline;
    };
    function getCoordsDataType(rank) {
        if (rank <= 1) {
            return 'i32';
        }
        else if (rank === 2) {
            return `vec2<i32>`;
        }
        else if (rank === 3) {
            return `vec3<i32>`;
        }
        else if (rank === 4) {
            return `vec4<i32>`;
        }
        else if (rank === 5) {
            return `vec5`;
        }
        else if (rank === 6) {
            return `vec6`;
        }
        else {
            throw Error(`GPU for rank ${rank} is not yet supported`);
        }
    }
    function getCoordsXYZ(index) {
        if (index === 0) {
            return 'x';
        }
        else if (index === 1) {
            return 'y';
        }
        else if (index === 2) {
            return 'z';
        }
        else if (index === 3) {
            return 'w';
        }
        else if (index === 4) {
            return 'u';
        }
        else if (index === 5) {
            return 'v';
        }
        else {
            throw Error(`Index ${index} is not yet supported`);
        }
    }
    function getMainHeaderString(...params) {
        let snippet;
        switch (params.length) {
            case 0:
                snippet = `
        fn main()
      `;
                break;
            case 1:
                snippet = `
        fn main(${params[0]} : i32)
      `;
                break;
            default:
                throw Error('Unreachable');
        }
        return snippet;
    }
    function getStartHeaderString(useGlobalIndex, program) {
        let snippet;
        snippet = `
     ${getWorkgroupSizeString(program)}
      fn _start(@builtin(local_invocation_id) LocalId : vec3<u32>,
                @builtin(global_invocation_id) GlobalId : vec3<u32>,
                @builtin(local_invocation_index) LocalIndex: u32,
                @builtin(workgroup_id) WorkgroupId : vec3<u32>,
                @builtin(num_workgroups) NumWorkgroups : vec3<u32>) {
        localId = LocalId;
        localIndex = LocalIndex;
        globalId = GlobalId;
        numWorkgroups = NumWorkgroups;
        workgroupId = WorkgroupId;
        ${useGlobalIndex ? `main(getGlobalIndex());` : `main();`};
      }
    `;
        return snippet;
    }
    function getWorkgroupSizeString(program) {
        return `
  @compute @workgroup_size(${program.workgroupSize[0]}, ${program.workgroupSize[1]}, ${program.workgroupSize[2]})
`;
    }
    function makeShader(inputInfo, outputData, program) {
        const prefixSnippets = [];
        const flatWorkgroupSize = program.workgroupSize[0] *
            program.workgroupSize[1] * program.workgroupSize[2];
        prefixSnippets.push(`

      var<private> localId: vec3<u32>;
      var<private> localIndex: u32;
      var<private> globalId: vec3<u32>;
      var<private> numWorkgroups: vec3<u32>;
      var<private> workgroupId: vec3<u32>;

      // Only used when the y/z dimension of workgroup size is 1.
      fn getGlobalIndex() -> i32 {
        ${isFlatDispatch(program) ?
        `  return i32(globalId.x);` :
        `  return i32((workgroupId.z * numWorkgroups.x * numWorkgroups.y +
                workgroupId.y * numWorkgroups.x + workgroupId.x) * ${flatWorkgroupSize}u +
                localIndex);
        `}
      }
    `);
        if (program.isFromPixels) {
            prefixSnippets.push(`
        struct Uniform {
          size            : i32,
          numChannels     : i32,
          outShapeStrides : vec2<i32>,
        };

        @group(0) @binding(0) var<storage, read_write> result: array<${mapToWgslTypes(outputData.dtype, program.isVec4)}>;
        @group(0) @binding(2) var<uniform> uniforms: Uniform;
      `);
            const useGlobalIndex = isFlatDispatchLayout(program);
            return [
                commonSnippet,
                prefixSnippets.join('\n'),
                getCoordsFromIndexSnippet(outputData.shape),
                program.getUserCode(),
                getStartHeaderString(useGlobalIndex, program),
            ].join('\n');
        }
        let uniformDeclaration = 'struct Uniforms { NAN : f32, INFINITY : f32, ';
        program.variableNames.forEach((x, i) => {
            const perDataType = getCoordsDataType(inputInfo[i].shape.length);
            uniformDeclaration +=
                `${x.charAt(0).toLowerCase() + x.slice(1)}Shape : ${perDataType}, `;
        });
        const outputDataType = getCoordsDataType(outputData.shape.length);
        uniformDeclaration += `outShape : ${outputDataType}, `;
        const stridesLength = outputData.shape.length - 1;
        const stridesDataType = getCoordsDataType(stridesLength);
        uniformDeclaration += `
         outShapeStrides: ${stridesDataType}, `;
        if (program.size) {
            uniformDeclaration += 'size : i32, ';
        }
        if (program.uniforms) {
            uniformDeclaration += program.uniforms;
        }
        uniformDeclaration += '};';
        uniformDeclaration = insertAlignment(uniformDeclaration);
        prefixSnippets.push(uniformDeclaration);
        // Output buffer.
        if (program.atomic) {
            prefixSnippets.push(`
      @group(0) @binding(0) var<storage, read_write> result: array<atomic<i32>>;
    `);
        }
        else {
            prefixSnippets.push(`
      @group(0) @binding(0) var<storage, read_write> result: array<${mapToWgslTypes(outputData.dtype, program.isVec4)}>;
    `);
        }
        program.variableNames.forEach((x, i) => {
            prefixSnippets.push(`
      @group(0) @binding(${1 + i}) var<storage, read> ${x}: array<${program.variableTypes ?
            program.variableTypes[i] :
            mapToWgslTypes(inputInfo[i].dtype, program.isVec4)}>;
        `);
        });
        if (uniformDeclaration !== '') {
            prefixSnippets.push(`
      @group(0) @binding(${1 + program.variableNames.length}) var<uniform> uniforms: Uniforms;
      `);
        }
        const coordsSnippet = getOutputCoordsSnippet(outputData.shape, program.dispatchLayout);
        const sources = [
            commonSnippet, prefixSnippets.join('\n') + isInfSnippet,
            getCoordsFromIndexSnippet(outputData.shape), coordsSnippet,
            getOutputIndexFromCoordsSnippet(outputData.shape.length)
        ];
        if (!program.atomic) {
            sources.push(setOutputSnippet(outputData.shape, outputData.dtype, program.isVec4));
        }
        const inputSnippet = inputInfo
            .map((x, i) => getInputSnippet(x, outputData.shape, program.variableTypes ?
            (program.variableTypes[i] === 'vec4<f32>') :
            program.isVec4, program.dispatchLayout.x.length === outputData.shape.length))
            .join('\n');
        sources.push(inputSnippet);
        sources.push(program.getUserCode());
        const useGlobalIndex = isFlatDispatchLayout(program);
        sources.push(getStartHeaderString(useGlobalIndex, program));
        const source = sources.join('\n');
        return source;
    }
    function makeShaderKey(program, shapes, inputsData, output) {
        let key = program.shaderKey;
        if (program.isFromPixels) {
            return key;
        }
        const types = inputsData.map(d => d.dtype).concat(output.dtype);
        const broadcastDims = inputsData.map(d => tf.backend_util.getBroadcastDims(d.shape, output.shape));
        const inputShapesEqualsOutShape = inputsData.map(d => tf.util.arraysEqual(d.shape, output.shape)).join('_');
        const broadcastDimsKey = broadcastDims.map(d => d.join('_')).join(';');
        const flatDispatchString = isFlatDispatch(program) ? 'flatDispatch' : '';
        key += '_' + (program.workgroupSize ? program.workgroupSize.join(',') : '') +
            shapes.map(shape => shape.length).join(',') + types.join(',') +
            program.variableNames.join(',') + broadcastDimsKey +
            inputShapesEqualsOutShape + flatDispatchString;
        return key;
    }
    const commonSnippet = `
  struct vec5 {x: i32, y: i32, z: i32, w: i32, u: i32};
  struct vec6 {x: i32, y: i32, z: i32, w: i32, u: i32, v: i32};

  // Checks whether coordinates lie within the bounds of the shape.
  fn coordsInBounds2D(coord : vec2<i32>, shape : vec2<i32>) -> bool {
    return all(coord >= vec2<i32>(0)) && all(coord < shape);
  }
  fn coordsInBounds3D(coord : vec3<i32>, shape : vec3<i32>) -> bool {
    return all(coord >= vec3<i32>(0)) && all(coord < shape);
  }
  fn coordsInBounds4D(coord : vec4<i32>, shape : vec4<i32>) -> bool {
    return all(coord >= vec4<i32>(0)) && all(coord < shape);
  }

  fn getIndexFromCoords1D(coord : i32, shape : i32) -> i32 {
    return coord;
  }
  fn getIndexFromCoords2D(coords : vec2<i32>, shape : vec2<i32>) -> i32 {
    return dot(coords, vec2<i32>(shape.y, 1));
  }
  fn getIndexFromCoords3D(coords : vec3<i32>, shape : vec3<i32>) -> i32 {
    return dot(coords, vec3<i32>(shape.y * shape.z, shape.z, 1));
  }
  fn getIndexFromCoords4D(coords : vec4<i32>, shape : vec4<i32>) -> i32 {
    return dot(coords, vec4<i32>(
        shape.y * shape.z * shape.w, shape.z * shape.w, shape.w, 1));
  }
  fn getIndexFromCoords5D(coords : vec5, shape : vec5) -> i32 {
    let shapeStrides: vec5 = vec5(shape.y * shape.z * shape.w * shape.u, shape.z * shape.w * shape.u, shape.w * shape.u, shape.u, 1);
    return coords.x*shapeStrides.x + coords.y*shapeStrides.y + coords.z*shapeStrides.z + coords.w*shapeStrides.w + coords.u*shapeStrides.u;
  }
  fn getIndexFromCoords6D(coords : vec6, shape : vec6) -> i32 {
    let shapeStrides: vec6 = vec6(shape.y * shape.z * shape.w * shape.u * shape.v, shape.z * shape.w * shape.u * shape.v, shape.w * shape.u * shape.v, shape.u * shape.v, shape.v, 1);
    return coords.x*shapeStrides.x + coords.y*shapeStrides.y + coords.z*shapeStrides.z + coords.w*shapeStrides.w + coords.u*shapeStrides.u + coords.v*shapeStrides.v;
  }

  fn idiv(a: i32, b: i32, sign: f32) -> i32 {
    var res: i32 = a / b;
    let modulo: i32 = a % b;
    if (sign < 0. && modulo != 0) {
      res = res - 1;
    }
    return res;
  }

  // NaN defination in IEEE 754-1985 is :
  //   - sign = either 0 or 1.
  //   - biased exponent = all 1 bits.
  //   - fraction = anything except all 0 bits (since all 0 bits represents infinity).
  // https://en.wikipedia.org/wiki/IEEE_754-1985#Representation_of_non-numbers
  fn isnan(val: f32) -> bool {
    let floatToUint: u32 = bitcast<u32>(val);
    return (floatToUint & 0x7fffffffu) > 0x7f800000u;
  }
  fn isnanVec4(val : vec4<f32>) -> vec4<bool> {
    let floatToUint: vec4<u32> = bitcast<vec4<u32>>(val);
    return (floatToUint & vec4<u32>(0x7fffffffu)) > vec4<u32>(0x7f800000u);
  }
`;
    const isInfSnippet = `
  fn isinf(val: f32) -> bool {
    return abs(val) == uniforms.INFINITY;
  }
`;
    /**
     * Derives logical coordinates from a flat index. Performs integer division
     * with each stride and decrements the index until the index equals the final
     * dimension coordinate.
     */
    function getCoordsFromIndexSnippet(shape) {
        const rank = shape.length;
        if (rank <= 1) {
            return `fn getCoordsFromIndex(index : i32) -> i32 { return index; }`;
        }
        const strides = tf.util.computeStrides(shape);
        const dtype = getCoordsDataType(rank);
        const coords = [];
        for (let i = 0; i < rank; i++) {
            coords.push(`d${i}`);
        }
        if (strides.length === 1) {
            return `    fn getCoordsFromIndex(index : i32) -> vec2<i32> {
      let d0 = index / uniforms.outShapeStrides; let d1 = index - d0 * uniforms.outShapeStrides;
      return vec2<i32>(d0, d1);
    }`;
        }
        let snippet;
        snippet = 'var index2 = index;' +
            strides
                .map((_, i) => {
                const line1 = `let ${coords[i]} = index2 / uniforms.outShapeStrides.${getCoordsXYZ(i)}`;
                const line2 = i === strides.length - 1 ?
                    `let ${coords[i + 1]} = index2 - ${coords[i]} * uniforms.outShapeStrides.${getCoordsXYZ(i)}` :
                    `index2 = index2 - ${coords[i]} * uniforms.outShapeStrides.${getCoordsXYZ(i)}`;
                return `${line1}; ${line2};`;
            })
                .join('');
        return `
    fn getCoordsFromIndex(index : i32) -> ${dtype} {
      ${snippet}
      return ${dtype}(${coords.join(',')});
    }
  `;
    }
    function getInputAtCoordsSnippet(inputInfo, isVec4) {
        const texName = inputInfo.name;
        const rank = inputInfo.shape.length;
        const type = getCoordsDataType(rank);
        const funcName = 'get' + texName.charAt(0).toUpperCase() + texName.slice(1);
        const dims = ['d0', 'd1', 'd2', 'd3', 'd4', 'd5'].slice(0, rank);
        const inputs = dims.map(d => `${d} : i32`).join(', ');
        if (rank < 1) {
            if (isVec4) {
                return `
        fn ${funcName}() -> vec4<f32> {
          return vec4<f32>(${texName}[0]);
        }
      `;
            }
            return `
      fn ${funcName}() ->f32 {
        return f32(${texName}[0]);
      }
    `;
        }
        const shapeStr = `uniforms.${texName.charAt(0).toLowerCase() + texName.slice(1)}Shape`;
        let rankStr = `${rank}D`;
        if (rank === 0) {
            rankStr = '1D';
        }
        if (isVec4) {
            return `
      fn ${funcName}(${inputs}) -> vec4<f32> {
        return vec4<f32>(${texName}[getIndexFromCoords${rankStr}(${type}(${dims.join(',')}),
          ${shapeStr}) / 4]);
      }
      `;
        }
        return `
    fn ${funcName}(${inputs}) -> f32 {
      return f32(${texName}[getIndexFromCoords${rankStr}(${type}(${dims.join(',')}),
        ${shapeStr})]);
    }
   `;
    }
    function getInputByOutputSnippet(inputInfo, outShape, isVec4, isFlatDispatchLayout) {
        const texName = inputInfo.name;
        const texFuncSnippet = texName.charAt(0).toUpperCase() + texName.slice(1);
        const funcName = 'get' + texFuncSnippet + 'ByOutput';
        const inRank = inputInfo.shape.length;
        const outRank = outShape.length;
        const type = getCoordsDataType(outRank);
        // If the inShape equals the outShape and the dispatch layout is flat, we can
        // directly use |gl_GlobalInvocationID.x| as the index and don't need coords
        // conversion between these two shapes.
        if (tf.util.arraysEqual(inputInfo.shape, outShape) && isFlatDispatchLayout) {
            if (isVec4) {
                return `
      fn ${funcName}Index(globalIndex : i32) -> vec4<f32> {
        return vec4<f32>(${texName}[globalIndex]);
      }

      fn ${funcName}Coords(coords : ${type}) -> vec4<f32> {
        return vec4<f32>(${texName}[${outRank > 1 ? 'getOutputIndexFromCoords(coords)' : 'coords'} / 4]);
      }
      `;
            }
            else {
                return `
    fn ${funcName}Index(globalIndex : i32) -> f32 {
      return f32(${texName}[globalIndex]);
    }

    fn ${funcName}Coords(coords : ${type}) -> f32 {
      return f32(${texName}[${outRank > 1 ? 'getOutputIndexFromCoords(coords)' : 'coords'}]);
    }
    `;
            }
        }
        const broadcastDims = tf.backend_util.getBroadcastDims(inputInfo.shape, outShape);
        const rankDiff = outRank - inRank;
        let coordsSnippet = '';
        if (inRank === 0) {
            if (isVec4) {
                return `
    fn ${funcName}Index(globalIndex : i32) -> vec4<f32> {
      return get${texFuncSnippet}();
    }

    fn ${funcName}Coords(coords : ${type}) -> vec4<f32> {
      return get${texFuncSnippet}();
    }
  `;
            }
            return `
    fn ${funcName}Index(globalIndex : i32) -> f32{
      return get${texFuncSnippet}();
    }

    fn ${funcName}Coords(coords : ${type}) -> f32{
      return get${texFuncSnippet}();
    }
  `;
        }
        else {
            if (outRank < 2 && broadcastDims.length >= 1) {
                coordsSnippet = 'coords = 0;';
            }
            else {
                coordsSnippet =
                    broadcastDims.map(d => `coords.${getCoordsXYZ(d + rankDiff)} = 0;`)
                        .join('\n');
            }
        }
        let unpackedCoordsSnippet = '';
        if (outRank < 2 && inRank > 0) {
            unpackedCoordsSnippet = 'coords';
        }
        else {
            if (outRank > 1) {
                const coordsType = getCoordsDataType(inRank);
                const coordsValues = inputInfo.shape.map((s, i) => `coords.${getCoordsXYZ(i + rankDiff)}`)
                    .join(', ');
                unpackedCoordsSnippet = `${coordsType}(${coordsValues})`;
            }
            else {
                unpackedCoordsSnippet = 'coords';
            }
        }
        const shapeStr = `uniforms.${texName.charAt(0).toLowerCase() + texName.slice(1)}Shape`;
        const rankStr = `${inRank}D`;
        if (isVec4) {
            return `
    fn ${funcName}Index(globalIndex : i32) -> vec4<f32> {
      var coords = getCoordsFromIndex(globalIndex);
      ${coordsSnippet}
      return ${texName}[getIndexFromCoords${rankStr}(${unpackedCoordsSnippet}, ${shapeStr}) / 4];
    }

    fn ${funcName}Coords(coordsIn : ${type}) -> vec4<f32> {
      var coords = coordsIn;
      ${coordsSnippet}
      return ${texName}[getIndexFromCoords${rankStr}(${unpackedCoordsSnippet}, ${shapeStr}) / 4];
    }
  `;
        }
        return `
  fn ${funcName}Index(globalIndex : i32) -> f32 {
    var coords = getCoordsFromIndex(globalIndex);
    ${coordsSnippet}
    return f32(${texName}[getIndexFromCoords${rankStr}(${unpackedCoordsSnippet}, ${shapeStr})]);
  }

  fn ${funcName}Coords(coordsIn : ${type}) -> f32 {
    var coords = coordsIn;
    ${coordsSnippet}
    return f32(${texName}[getIndexFromCoords${rankStr}(${unpackedCoordsSnippet}, ${shapeStr})]);
  }
`;
    }
    function getInputSnippet(inputInfo, outShape, isVec4, isFlatDispatchLayout) {
        let res = getInputAtCoordsSnippet(inputInfo, isVec4);
        const inShape = inputInfo.shape;
        if (inShape.length <= outShape.length) {
            res += getInputByOutputSnippet(inputInfo, outShape, isVec4, isFlatDispatchLayout);
        }
        return res;
    }
    /**
     * Generates getOutputCoords() function that computes output coordinates from
     * dispatch geometry to reduce arithmetic.
     */
    function getOutputCoordsSnippet(outShape, dispatchLayout) {
        const { x, y = [], z = [] } = dispatchLayout;
        const outRank = outShape.length;
        const rank = x.length + y.length + z.length;
        // getOutputCoords is only meaningful when the output rank is same with
        // dispatch layout rank.
        if (rank !== outRank) {
            return '';
        }
        if (x.length === outRank) {
            const dtype = getCoordsDataType(outRank);
            const snippet = `fn getOutputCoords() -> ${dtype}{
    let globalIndex = getGlobalIndex();
    return getCoordsFromIndex(globalIndex);
  }
  `;
            return snippet;
        }
        let gatherDimensionsStr = '';
        const dims = [x, y, z];
        for (let i = 0; i < dims.length; i++) {
            const arr = dims[i];
            if (arr.length === 0) {
                continue;
            }
            if (arr.length === 1) {
                gatherDimensionsStr += `let d${arr[0]} = i32(globalId[${i}]);`;
            }
            else {
                const strides = symbolicallyComputeStrides(arr, 'uniforms.outShape');
                gatherDimensionsStr += `var index${i} = i32(globalId[${i}]);`;
                for (let j = 0; j < strides.length; j++) {
                    gatherDimensionsStr += `let d${arr[j]} = index${i} / ${strides[j]};`;
                    if (j === strides.length - 1) {
                        gatherDimensionsStr += `let d${arr[j + 1]} = ` +
                            `index${i} - d${arr[j]} * ${strides[j]};`;
                    }
                    else {
                        gatherDimensionsStr +=
                            `index${i} = index${i} - d${arr[j]} * ${strides[j]};`;
                    }
                }
            }
        }
        const dimensions = [];
        for (let i = 0; i < rank; i++) {
            dimensions.push(`d${i}`);
        }
        const dtype = getCoordsDataType(rank);
        let snippet = `fn getOutputCoords() -> ${dtype} {
  ${gatherDimensionsStr}
`;
        if (dimensions.length === 0) {
            snippet += `return ${dtype}(0); }`;
        }
        else {
            snippet += `return ${dtype}(${dimensions.join(',')}); }`;
        }
        return snippet;
    }
    function getOutputIndexFromCoordsSnippet(outRank) {
        let snippet = '';
        switch (outRank) {
            case 0:
            case 1:
                snippet += `
        fn getOutputIndexFromCoords(coords : i32) -> i32 {
          return coords;
        }
        `;
                break;
            case 2:
                snippet += `
        fn getOutputIndexFromCoords(coords : vec2<i32>) -> i32 {
          return dot(coords, vec2<i32>(uniforms.outShapeStrides, 1));
        }
        `;
                break;
            case 3:
                snippet += `
        fn getOutputIndexFromCoords(coords : vec3<i32>) -> i32 {
          return dot(coords, vec3<i32>(uniforms.outShapeStrides.x, uniforms.outShapeStrides.y, 1));
        }
        `;
                break;
            case 4:
                snippet += `
        fn getOutputIndexFromCoords(coords : vec4<i32>) -> i32 {
          return dot(coords, vec4<i32>(
            uniforms.outShapeStrides.x, uniforms.outShapeStrides.y, uniforms.outShapeStrides.z, 1));
        }
        `;
                break;
            case 5:
                snippet += `
        fn getOutputIndexFromCoords(coords : vec5) -> i32 {
          return coords.x * uniforms.outShapeStrides.x +
              coords.y * uniforms.outShapeStrides.y +
              coords.z * uniforms.outShapeStrides.z +
              coords.w * uniforms.outShapeStrides.w +
              coords.u;
        }
        `;
                break;
            case 6:
                snippet += `
        fn getOutputIndexFromCoords(coords : vec6) -> i32 {
          return coords.x * uniforms.outShapeStrides.x +
              coords.y * uniforms.outShapeStrides.y +
              coords.z * uniforms.outShapeStrides.z +
              coords.w * uniforms.outShapeStrides.w +
              coords.u * uniforms.outShapeStrides.u +
              coords.v;
        }
        `;
                break;
            default:
                tf.util.assert(false, () => `Unsupported ${outRank}D shape`);
                break;
        }
        return snippet;
    }
    function isFlatDispatch(program) {
        return program.dispatch[1] === 1 && program.dispatch[2] === 1;
    }
    function mapToWgslTypes(type, isVec4) {
        if (type === 'float32') {
            return isVec4 ? 'vec4<f32>' : 'f32';
        }
        else if (type === 'int32') {
            return isVec4 ? 'vec4<i32>' : 'i32';
        }
        else if (type === 'bool') {
            // Type 'bool' cannot be used in storage class,
            // https://www.w3.org/TR/WGSL/#host-shareable-types.
            return isVec4 ? 'vec4<i32>' : 'i32';
        }
        return type;
    }
    function setOutputSnippet(outShape, outBufferType, isVec4) {
        const outRank = outShape.length;
        const wgslType = mapToWgslTypes(outBufferType, isVec4);
        let snippet;
        if (isVec4) {
            snippet = `fn setOutputAtIndex(flatIndex : i32, value : vec4<f32>) {
      result[flatIndex] = ${wgslType}(value);
    }
    fn setOutputAtIndexI32(flatIndex : i32, value : vec4<i32>) {
      result[flatIndex] = ${wgslType}(value);
    }`;
        }
        else {
            snippet = `fn setOutputAtIndex(flatIndex : i32, value : f32) {
      result[flatIndex] = ${wgslType}(value);
    }
    fn setOutputAtIndexI32(flatIndex : i32, value : i32) {
      result[flatIndex] = ${wgslType}(value);
    }`;
        }
        if (outRank >= 2) {
            const dims = ['d0', 'd1', 'd2', 'd3', 'd4', 'd5'].slice(0, outRank);
            const type = getCoordsDataType(outRank);
            if (isVec4) {
                snippet += `
      fn setOutputAtCoords(${dims.map(d => `${d} : i32`).join(', ')}, value : vec4<f32>) {
        let flatIndex = getOutputIndexFromCoords(${type}(${dims.join(', ')}));
        setOutputAtIndex(flatIndex / 4, value);
      }
      fn setOutputAtCoordsI32(${dims.map(d => `${d} : i32`).join(', ')}, value : vec4<i32>) {
        let flatIndex = getOutputIndexFromCoords(${type}(${dims.join(', ')}));
        setOutputAtIndexI32(flatIndex / 4, value);
      }
    `;
            }
            else {
                snippet += `
      fn setOutputAtCoords(${dims.map(d => `${d} : i32`).join(', ')}, value : f32) {
        let flatIndex = getOutputIndexFromCoords(${type}(${dims.join(', ')}));
        setOutputAtIndex(flatIndex, value);
      }
      fn setOutputAtCoordsI32(${dims.map(d => `${d} : i32`).join(', ')}, value : i32) {
        let flatIndex = getOutputIndexFromCoords(${type}(${dims.join(', ')}));
        setOutputAtIndexI32(flatIndex, value);
      }
    `;
            }
        }
        return snippet;
    }
    function insertAlignment(uniformShader) {
        // insert alignment when current pattern is vec5 or vec6
        const curInsertRe = /(\w+)\s*:\s*vec(5|6)/g;
        uniformShader = uniformShader.replace(curInsertRe, (match) => {
            return '@align(16) ' + match;
        });
        // insert alignment when previous pattern is vec5 or vec6
        const preInsertRe = /vec(5|6)\s*,\s*(\w+)/g;
        uniformShader = uniformShader.replace(preInsertRe, (_, p1, p2) => {
            return `vec${p1}, @align(16) ${p2}`;
        });
        return uniformShader;
    }
    function isFlatDispatchLayout(program) {
        if (program.dispatchLayout.hasOwnProperty('y') &&
            program.dispatchLayout.y.length !== 0) {
            return false;
        }
        if (program.dispatchLayout.hasOwnProperty('z') &&
            program.dispatchLayout.z.length !== 0) {
            return false;
        }
        return true;
    }

    /**
     * @license
     * Copyright 2019 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const arrayProduct = (arr) => {
        let product = 1;
        for (let i = 0; i < arr.length; i++) {
            product *= arr[i];
        }
        return product;
    };
    // Computes dispatch geometry based on layout of output dimensions and
    // workgroupSize.
    function computeDispatch(layout, outputShape, workgroupSize = [1, 1, 1], elementsPerThread = [1, 1, 1]) {
        const [dispatchX, dispatchY, dispatchZ] = [
            Math.ceil(arrayProduct(layout.x.map(d => outputShape[d])) /
                (workgroupSize[0] * elementsPerThread[0])),
            layout.y ? Math.ceil(arrayProduct(layout.y.map(d => outputShape[d])) /
                (workgroupSize[1] * elementsPerThread[1])) :
                1,
            layout.z ? Math.ceil(arrayProduct(layout.z.map(d => outputShape[d])) /
                (workgroupSize[2] * elementsPerThread[2])) :
                1
        ];
        return [dispatchX, dispatchY, dispatchZ];
    }
    function computeWorkgroupInfoForMatMul(dimAOuter, dimInner, dimBOuter, transposeA = false) {
        // These are experimental values. Usually, we need to adjust the work group
        // size based on the input shapes to improve the EU occupancy.
        // TODO: WebGPU limits the maximum allowed shared memory size as 16K. To make
        // sure it doesn't exceed this limitations. Temporarily reduce the work group
        // size to [8, 8, 1] and the work per thread size is [4, 4, 1]. But we should
        // revisit it and find the balance between work group size and work per thread
        // size.
        const workgroupSize = [8, 8, 1];
        const elementsPerThread = [4, 4, 1];
        if (!transposeA) {
            if (dimAOuter <= 8) {
                elementsPerThread[1] = 1;
            }
            if (dimInner <= 16 && dimBOuter <= 16) {
                workgroupSize[0] = 4;
            }
        }
        return { workgroupSize, elementsPerThread };
    }
    function computeWorkgroupSizeForConv2d(layout, outputShape, isVec4 = false) {
        if (isVec4) {
            return [8, 8, 1];
        }
        const dim0 = arrayProduct(layout.x.map(d => outputShape[d]));
        const dim1 = arrayProduct(layout.y.map(d => outputShape[d]));
        // TODO(jiajia.qin@intel.com): More fine tune based on outputShape.
        // These are experimental values. Usually, we need to adjust the work group
        // size based on the output shape. For example, when one dimension is smaller
        // than 4, it will be wasteful if we assign a larger size for this dimension,
        // which results lots of threads doing useless work and reduces parallelism
        // of hardware threads. But it is always a balance between work group size
        // and shared memory. If one dimension is too small, such as 1, shared memory
        // will won't be fully utilized.
        if (dim0 <= 4) {
            return [4, 16, 1];
        }
        if (dim1 <= 4) {
            return [16, 4, 1];
        }
        return [16, 16, 1];
    }
    function computeWorkPerThreadForConv2d(layout, outputShape, isVec4 = false) {
        if (isVec4) {
            return [4, 4, 1];
        }
        const dim0 = arrayProduct(layout.x.map(d => outputShape[d]));
        const dim1 = arrayProduct(layout.y.map(d => outputShape[d]));
        // TODO(jiajia.qin@intel.com): More fine tune based on outputShape.
        // The following conditions correspond to the values set in
        // computeWorkgroupSizeForConv2d.
        if (dim0 <= 4) {
            return [1, 2, 1];
        }
        if (dim1 <= 4) {
            return [2, 1, 1];
        }
        return [2, 2, 1];
    }
    function flatDispatchLayout(shape) {
        return { x: shape.map((d, i) => i) };
    }
    function GPUBytesPerElement(dtype) {
        if (dtype === 'float32' || dtype === 'int32' || dtype === 'bool' ||
            dtype === 'string') {
            return 4;
        }
        else if (dtype === 'complex64') {
            return 8;
        }
        else {
            throw new Error(`Unknown dtype ${dtype}`);
        }
    }
    function isWebGPUSupported() {
        return ((typeof window !== 'undefined') ||
            //@ts-ignore
            (typeof WorkerGlobalScope !== 'undefined')) &&
            !!navigator.gpu;
    }
    function assertNotComplex(tensor, opName) {
        if (!Array.isArray(tensor)) {
            tensor = [tensor];
        }
        tensor.forEach(t => {
            if (t != null) {
                tf.util.assert(t.dtype !== 'complex64', () => `${opName} does not support complex64 tensors ` +
                    'in the WebGPU backend.');
            }
        });
    }
    var MatMulProgramType;
    (function (MatMulProgramType) {
        MatMulProgramType[MatMulProgramType["MatMulReduceProgram"] = 0] = "MatMulReduceProgram";
        MatMulProgramType[MatMulProgramType["MatMulSplitKProgram"] = 1] = "MatMulSplitKProgram";
        MatMulProgramType[MatMulProgramType["MatMulSmallOutputSizeProgram"] = 2] = "MatMulSmallOutputSizeProgram";
        MatMulProgramType[MatMulProgramType["MatMulPackedProgram"] = 3] = "MatMulPackedProgram";
        MatMulProgramType[MatMulProgramType["MatMulMax"] = 4] = "MatMulMax";
    })(MatMulProgramType || (MatMulProgramType = {}));

    /**
     * @license
     * Copyright 2019 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    // Empirically determined constant used to determine size threshold for handing
    // off execution to the CPU.
    const CPU_HANDOFF_SIZE_THRESHOLD = tf.env().getNumber('WEBGPU_CPU_HANDOFF_SIZE_THRESHOLD');
    // Reshape dispatch, not to exceed device limits.
    const reshapeDispatch = (device, program) => {
        const MAX_COMPUTE_PER_DIMENSION_DISPATCH_SIZE = device.limits.maxComputeWorkgroupsPerDimension;
        const layout = program['dispatchLayout'];
        const dispatch = program['dispatch'];
        if (dispatch.every((d) => d <= MAX_COMPUTE_PER_DIMENSION_DISPATCH_SIZE)) {
            return dispatch;
        }
        tf.util.assert(dispatch[0] > MAX_COMPUTE_PER_DIMENSION_DISPATCH_SIZE &&
            layout.y === undefined && layout.z === undefined, () => 'Dispatch size exceeds WebGPU limits in Y or Z dimension.');
        let dispatchAverage = Math.ceil(Math.sqrt(dispatch[0]));
        if (dispatchAverage > MAX_COMPUTE_PER_DIMENSION_DISPATCH_SIZE) {
            dispatchAverage = Math.ceil(Math.cbrt(dispatch[0]));
            tf.util.assert(dispatchAverage <= MAX_COMPUTE_PER_DIMENSION_DISPATCH_SIZE, () => 'Total dispatch size exceeds WebGPU maximum.');
            return [dispatchAverage, dispatchAverage, dispatchAverage];
        }
        else {
            return [dispatchAverage, dispatchAverage, 1];
        }
    };
    class WebGPUBackend extends tf.KernelBackend {
        constructor(device, adapterInfo) {
            super();
            this.commandQueueOwnedIds = new WeakSet();
            this.dispatchNumberInEncoder = 0;
            this.disposed = false;
            this.downloadWaitMs = 0;
            this.tensorDataPendingDisposal = [];
            this.stagingPendingDisposal = [];
            this.uniformPendingDisposal = [];
            this.uploadWaitMs = 0;
            if (!isWebGPUSupported()) {
                throw new Error('WebGPU is not supported on this device');
            }
            this.pipelineCache = {};
            this.device = device;
            this.queue = device.queue;
            this.currentCommandEncoder = null;
            this.currentComputePass = null;
            this.supportTimeQuery =
                device.features.has('timestamp-query-inside-passes');
            this.adapterInfo = new AdapterInfo(adapterInfo);
            this.thresholdToIncreaseWorkgroups =
                this.adapterInfo.intelGPUGeneration >= 12 ? 16 : 8;
            this.bufferManager = new BufferManager(this.device);
            this.textureManager = new TextureManager(this.device);
            this.tensorMap = new tf.DataStorage(this, tf.engine());
            if (this.supportTimeQuery) {
                this.querySet = this.device.createQuerySet({
                    type: 'timestamp',
                    count: 2,
                });
            }
            // Profiling tools like PIX needs this dummy canvas to
            // trigger capturing a frame.
            if (tf.env().getBool('WEBGPU_USE_PROFILE_TOOL')) {
                this.dummyCanvas = document.createElement('canvas');
                this.dummyCanvas.width = 1;
                this.dummyCanvas.height = 1;
                this.dummyContext = this.dummyCanvas.getContext('webgpu');
                this.dummyContext.configure({
                    device,
                    format: 'bgra8unorm',
                });
                document.body.appendChild(this.dummyCanvas);
            }
        }
        nextDataId() {
            return WebGPUBackend.nextDataId++;
        }
        floatPrecision() {
            return 32;
        }
        defaultGpuBufferUsage() {
            return GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC |
                GPUBufferUsage.COPY_DST;
        }
        /**
         * Dispose the memory if the dataId has 0 refCount. Return true if the memory
         * is released or memory is not managed in this backend, false if memory is
         * not cleared.
         * @param dataId
         * @oaram force Optional, remove the data regardless of refCount
         */
        disposeData(dataId, force = false) {
            if (this.tensorDataPendingDisposal.indexOf(dataId) >= 0) {
                return false;
            }
            if (!this.tensorMap.has(dataId)) {
                return true;
            }
            const tensorData = this.tensorMap.get(dataId);
            this.decRef(dataId);
            if (!force && tensorData.refCount > 0) {
                return false;
            }
            // complex is never in commandQueueOwnedIds
            if (this.commandQueueOwnedIds.has(dataId)) {
                this.tensorDataPendingDisposal.push(dataId);
                return false;
            }
            const { complexTensorInfos } = this.tensorMap.get(dataId);
            if (complexTensorInfos != null) {
                this.disposeData(complexTensorInfos.real.dataId, force);
                this.disposeData(complexTensorInfos.imag.dataId, force);
            }
            this.releaseResource(dataId);
            this.tensorMap.delete(dataId);
            return true;
        }
        memory() {
            return {
                numBytesInGPU: this.bufferManager.numBytesUsed,
                numBytesAllocatedInGPU: this.bufferManager.numBytesAllocated,
                unreliable: false
            };
        }
        releaseResource(dataId) {
            const tensorData = this.tensorMap.get(dataId);
            if (!tensorData || !tensorData.resourceInfo) {
                return;
            }
            // If tensor's resource is from external, do not release.
            if (tensorData.external) {
                tensorData.resourceInfo = null;
                return;
            }
            if ('texture' in tensorData.resourceInfo) {
                const textureInfo = tensorData.resourceInfo;
                if (textureInfo.texture instanceof GPUTexture) {
                    this.textureManager.releaseTexture(textureInfo.texture, textureInfo.width, textureInfo.height, textureInfo.format, textureInfo.usage);
                }
                textureInfo.texture = null;
            }
            else {
                const bufferInfo = tensorData.resourceInfo;
                this.bufferManager.releaseBuffer(bufferInfo.buffer, bufferInfo.size, bufferInfo.usage);
                bufferInfo.buffer = null;
            }
            tensorData.resourceInfo = null;
        }
        /** Return refCount of a `TensorData`. */
        refCount(dataId) {
            if (this.tensorMap.has(dataId)) {
                const tensorData = this.tensorMap.get(dataId);
                return tensorData.refCount;
            }
            return 0;
        }
        /** Increase refCount of a `TensorData`. */
        incRef(dataId) {
            const tensorData = this.tensorMap.get(dataId);
            tensorData.refCount++;
        }
        /** Decrease refCount of a `TensorData`. */
        decRef(dataId) {
            if (this.tensorMap.has(dataId)) {
                const tensorData = this.tensorMap.get(dataId);
                tensorData.refCount--;
            }
        }
        write(values, shape, dtype) {
            if (dtype === 'complex64' && values != null) {
                throw new Error(`Cannot write to a complex64 dtype. ` +
                    `Please use tf.complex(real, imag).`);
            }
            const dataId = { id: this.nextDataId() };
            this.tensorMap.set(dataId, { dtype, shape, values, refCount: 1 });
            return dataId;
        }
        move(dataId, values, shape, dtype, refCount) {
            if (dtype === 'complex64') {
                throw new Error(`Cannot write to a complex64 dtype. ` +
                    `Please use tf.complex(real, imag).`);
            }
            this.tensorMap.set(dataId, { dtype, shape, values, refCount });
        }
        submitQueue() {
            this.ensureComputePassEnded();
            this.queue.submit([this.currentCommandEncoder.finish()]);
            this.currentCommandEncoder = null;
            this.dispatchNumberInEncoder = 0;
            this.commandQueueOwnedIds = new WeakSet();
            this.tensorDataPendingDisposal.forEach(d => {
                this.releaseResource(d);
                this.tensorMap.delete(d);
            });
            this.uniformPendingDisposal.forEach(d => this.bufferManager.releaseBuffer(d.buffer, d.size, d.usage));
            this.stagingPendingDisposal.forEach(d => this.bufferManager.releaseUploadBuffer(d.buffer, d.size, d.usage));
            this.tensorDataPendingDisposal = [];
            this.uniformPendingDisposal = [];
            this.stagingPendingDisposal = [];
        }
        ensureCommandEncoderReady() {
            if (!this.currentCommandEncoder) {
                this.currentCommandEncoder = this.device.createCommandEncoder();
            }
        }
        ensureComputePassEnded() {
            if (this.currentComputePass) {
                this.currentComputePass.end();
                this.currentComputePass = null;
            }
        }
        getComputePass() {
            if (!this.currentComputePass) {
                this.currentComputePass = this.currentCommandEncoder.beginComputePass();
            }
            return this.currentComputePass;
        }
        async getBufferData(buffer, size) {
            const staging = this.bufferManager.acquireBuffer(size, GPUBufferUsage.COPY_DST | GPUBufferUsage.MAP_READ);
            this.ensureCommandEncoderReady();
            this.ensureComputePassEnded();
            this.currentCommandEncoder.copyBufferToBuffer(buffer, 0, staging, 0, size);
            this.submitQueue();
            await staging.mapAsync(GPUMapMode.READ);
            const values = staging.getMappedRange().slice(0);
            staging.unmap();
            if (staging != null) {
                this.bufferManager.releaseBuffer(staging, size, GPUBufferUsage.COPY_DST | GPUBufferUsage.MAP_READ);
            }
            // Need to get texture from swapChain to enable profiling tool
            // to capture a frame
            if (tf.env().getBool('WEBGPU_USE_PROFILE_TOOL')) {
                tf.util.assert(this.dummyContext !== undefined, () => `Fail to get context for profiling tool`);
                this.dummyContext.getCurrentTexture();
            }
            return values;
        }
        convertAndCacheOnCPU(dataId, data) {
            const tensorData = this.tensorMap.get(dataId);
            this.releaseResource(dataId);
            tensorData.values = data;
            return tensorData.values;
        }
        // TODO: Remove once this is fixed:
        // https://github.com/tensorflow/tfjs/issues/1595
        readSync(dataId) {
            const tensorData = this.tensorMap.get(dataId);
            const { values } = tensorData;
            if (values == null) {
                throw new Error('WebGPU readSync is only available for CPU-resident tensors.');
            }
            return values;
        }
        async read(dataId) {
            if (!this.tensorMap.has(dataId)) {
                throw new Error(`Tensor ${dataId} was not registered!`);
            }
            const tensorData = this.tensorMap.get(dataId);
            const { values } = tensorData;
            if (values != null) {
                return this.convertAndCacheOnCPU(dataId, values);
            }
            // Download the values from the GPU.
            let vals;
            if (tensorData.dtype === 'complex64') {
                const ps = await Promise.all([
                    this.read(tensorData.complexTensorInfos.real.dataId),
                    this.read(tensorData.complexTensorInfos.imag.dataId)
                ]);
                const realValues = ps[0];
                const imagValues = ps[1];
                vals = tf.backend_util.mergeRealAndImagArrays(realValues, imagValues);
            }
            else {
                const bufferInfo = tensorData.resourceInfo;
                const data = await this.getBufferData(bufferInfo.buffer, bufferInfo.size);
                vals = tf.util.convertBackendValuesAndArrayBuffer(data, tensorData.dtype);
            }
            this.convertAndCacheOnCPU(dataId, vals);
            return vals;
        }
        // The source GPUBuffer and destination GPUBuffer have the same size and
        // usage.
        copyBuffer(srcBuffer, size, usage) {
            const dstBuffer = this.bufferManager.acquireBuffer(size, usage);
            this.ensureCommandEncoderReady();
            this.ensureComputePassEnded();
            this.currentCommandEncoder.copyBufferToBuffer(srcBuffer, 0, dstBuffer, 0, size);
            this.submitQueue();
            return dstBuffer;
        }
        /**
         * Create a TF.js tensor out of an existing WebGPU buffer.
         */
        createTensorFromGPUData(values, shape, dtype) {
            let buffer = values.buffer;
            if (dtype === 'complex64') {
                throw new Error(`Cannot write to a complex64 dtype. `);
            }
            const dataId = { id: this.nextDataId() };
            this.tensorMap.set(dataId, { dtype, shape, values: null, refCount: 1, external: values.zeroCopy });
            const tensorData = this.tensorMap.get(dataId);
            const size = GPUBytesPerElement(tensorData.dtype) *
                tf.util.sizeFromShape(tensorData.shape);
            if (values.buffer.size < size) {
                throw new Error(`GPUBuffer size(${values.buffer.size}) is smaller than tensor size(${size})!`);
            }
            else if ((values.buffer.usage &
                (GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC)) !==
                (GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC)) {
                throw new Error('GPUBuffer.usage should include GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC!');
            }
            // Do buffer copy by default.
            if (values.zeroCopy !== true) {
                buffer = this.copyBuffer(buffer, size, buffer.usage);
            }
            tensorData.resourceInfo = { size: buffer.size, usage: buffer.usage, buffer };
            return tf.engine().makeTensorFromDataId(dataId, shape, dtype, this);
        }
        /**
         * Read tensor to a new GPUBuffer.
         * @param dataId The source tensor.
         */
        readToGPU(dataId) {
            const srcTensorData = this.tensorMap.get(dataId);
            const { values, dtype, shape, resourceInfo } = srcTensorData;
            if (dtype === 'complex64') {
                throw new Error('Does not support reading buffer for complex64 dtype.');
            }
            if (resourceInfo == null) {
                if (values != null) {
                    throw new Error('Data is not on GPU but on CPU.');
                }
                else {
                    throw new Error('There is no data on GPU or CPU.');
                }
            }
            const size = resourceInfo.size;
            const buffer = this.bufferManager.acquireBuffer(size, resourceInfo.usage);
            this.ensureCommandEncoderReady();
            this.ensureComputePassEnded();
            this.currentCommandEncoder.copyBufferToBuffer(resourceInfo.buffer, 0, buffer, 0, size);
            this.submitQueue();
            const tensorInfo = this.makeTensorInfo(shape, dtype);
            // Make engine track this tensor, so that we can dispose it later.
            const tensorRef = tf.engine().makeTensorFromTensorInfo(tensorInfo);
            const tensorData = this.tensorMap.get(tensorInfo.dataId);
            tensorData
                .resourceInfo = { size, usage: this.defaultGpuBufferUsage(), buffer };
            return { tensorRef, buffer, bufSize: size };
        }
        bufferSync(t) {
            const data = this.readSync(t.dataId);
            if (t.dtype === 'string') {
                try {
                    // Decode the bytes into string.
                    const strings = data.map(d => tf.util.decodeString(d));
                    return tf.buffer(t.shape, t.dtype, strings);
                }
                catch (_a) {
                    throw new Error('Failed to decode encoded string bytes into utf-8');
                }
            }
            return tf.buffer(t.shape, t.dtype, data);
        }
        async time(f) {
            if (!this.supportTimeQuery) {
                console.warn(`This device doesn't support timestamp-query-inside-passes extension. ` +
                    `Start Chrome browser with flag ` +
                    `--disable-dawn-features=disallow_unsafe_apis then try again. ` +
                    `Otherwise, zero will be shown for the kernel time when profiling ` +
                    `mode is enabled. Using performance.now is not workable for webgpu ` +
                    `since it doesn't support synchronous data read from GPU.`);
            }
            const oldActiveTimers = this.activeTimers;
            const newActiveTimers = [];
            let outerMostTime = false;
            if (this.programTimersStack == null) {
                this.programTimersStack = newActiveTimers;
                outerMostTime = true;
            }
            else {
                this.activeTimers.push(newActiveTimers);
            }
            this.activeTimers = newActiveTimers;
            f();
            const flattenedActiveTimerQueries = tf.util.flatten(this.activeTimers.map((d) => d.query))
                .filter(d => d != null);
            const flattenedActiveTimerNames = tf.util.flatten(this.activeTimers.map((d) => d.name))
                .filter(d => d != null);
            this.activeTimers = oldActiveTimers;
            if (outerMostTime) {
                this.programTimersStack = null;
            }
            const res = {
                uploadWaitMs: this.uploadWaitMs,
                downloadWaitMs: this.downloadWaitMs,
                kernelMs: null,
                wallMs: null
            };
            const kernelMs = await Promise.all(flattenedActiveTimerQueries);
            res['kernelMs'] = tf.util.sum(kernelMs);
            res['getExtraProfileInfo'] = () => kernelMs.map((d, i) => ({ name: flattenedActiveTimerNames[i], ms: d }))
                .map(d => `${d.name}: ${d.ms}`)
                .join(', ');
            this.uploadWaitMs = 0;
            this.downloadWaitMs = 0;
            return res;
        }
        makeTensorInfo(shape, dtype, values) {
            if (dtype === 'string' && values != null && values.length > 0 &&
                tf.util.isString(values[0])) {
                values = values.map(d => tf.util.encodeString(d));
            }
            const dataId = this.write(values, shape, dtype);
            return { dataId, shape, dtype };
        }
        tensorToBinding(tensor) {
            if (!tensor) {
                return null;
            }
            const tensorData = this.tensorMap.get(tensor.dataId);
            if ('texture' in tensorData.resourceInfo) {
                const info = tensorData.resourceInfo;
                if (info.texture instanceof GPUExternalTexture) {
                    return info.texture;
                }
                else {
                    return info.texture.createView();
                }
            }
            const bufferInfo = tensorData.resourceInfo;
            return { offset: 0, size: bufferInfo.size, buffer: bufferInfo.buffer };
        }
        async getQueryTime(query) {
            if (this.supportTimeQuery) {
                return this.getTimeFromQuerySet(query);
            }
            else {
                return 0;
            }
        }
        uploadToGPU(dataId) {
            const tensorData = this.tensorMap.get(dataId);
            // Already on the GPU.
            if (tensorData.resourceInfo) {
                return;
            }
            const size = GPUBytesPerElement(tensorData.dtype) *
                tf.util.sizeFromShape(tensorData.shape);
            const buffer = this.bufferManager.acquireBuffer(size, this.defaultGpuBufferUsage());
            tensorData
                .resourceInfo = { size, usage: this.defaultGpuBufferUsage(), buffer };
            if (tensorData.values) {
                const stagingBuffer = this.bufferManager.acquireUploadBuffer(size, GPUBufferUsage.MAP_WRITE | GPUBufferUsage.COPY_SRC);
                const arrayBuffer = stagingBuffer.getMappedRange();
                if (tensorData.dtype === 'int32' || tensorData.dtype === 'bool') {
                    new Int32Array(arrayBuffer).set(tensorData.values);
                }
                else {
                    new Float32Array(arrayBuffer).set(tensorData.values);
                }
                stagingBuffer.unmap();
                this.ensureCommandEncoderReady();
                this.ensureComputePassEnded();
                this.currentCommandEncoder.copyBufferToBuffer(stagingBuffer, 0, buffer, 0, size);
                const stagingInfo = {
                    size,
                    usage: GPUBufferUsage.MAP_WRITE | GPUBufferUsage.COPY_SRC,
                    buffer: stagingBuffer
                };
                this.stagingPendingDisposal.push(stagingInfo);
                // TODO: WebGPU doesn't support read data synchronously from GPU to CPU.
                // So it will report error when switching backend from WebGPU to others.
                // There are two situations: 1) swithcing the backend after running a
                // model; 2) swithcing the backend within the model. Temporarilly keep
                // the values on CPU to solve the first issue. tensorData.values = null;
            }
        }
        makeUniforms(programUniform) {
            let currentOffset = 0;
            let preLength = 0;
            const offsets = [];
            let maxAlignmentOfField = 1;
            programUniform.forEach((d) => {
                if (d.data.length === 0) {
                    d.data = [1];
                }
                // https://www.w3.org/TR/WGSL/#alignof
                let baseAlignment;
                switch (d.data.length) {
                    case 1:
                        baseAlignment = 4;
                        break;
                    case 2:
                        baseAlignment = 8;
                        break;
                    case 3:
                        baseAlignment = 16;
                        break;
                    case 4:
                        baseAlignment = 16;
                        break;
                    case 5:
                        baseAlignment = 16;
                        break;
                    case 6:
                        baseAlignment = 16;
                        break;
                    default:
                        tf.util.assert(false, () => `Unsupported ${d.data.length}D shape`);
                }
                if (preLength === 5 || preLength === 6) {
                    baseAlignment = 16;
                }
                if (baseAlignment > maxAlignmentOfField) {
                    maxAlignmentOfField = baseAlignment;
                }
                currentOffset = Math.ceil(currentOffset / baseAlignment) * baseAlignment;
                preLength = d.data.length;
                offsets.push(currentOffset);
                currentOffset += d.data.length * 4;
            });
            currentOffset =
                Math.ceil(currentOffset / maxAlignmentOfField) * maxAlignmentOfField;
            const arrayBuffer = new ArrayBuffer(currentOffset);
            programUniform.forEach((d, i) => {
                const offset = offsets[i];
                if (d.type === 'int32') {
                    new Int32Array(arrayBuffer, offset, d.data.length).set(d.data);
                }
                else if (d.type === 'uint32') {
                    new Uint32Array(arrayBuffer, offset, d.data.length).set(d.data);
                }
                else {
                    new Float32Array(arrayBuffer, offset, d.data.length).set(d.data);
                }
            });
            const uniformBuffer = this.bufferManager.acquireBuffer(currentOffset, GPUBufferUsage.COPY_DST | GPUBufferUsage.UNIFORM);
            this.queue.writeBuffer(uniformBuffer, 0, arrayBuffer, 0, currentOffset);
            const uniformInfo = {
                size: currentOffset,
                usage: GPUBufferUsage.COPY_DST | GPUBufferUsage.UNIFORM,
                buffer: uniformBuffer
            };
            this.uniformPendingDisposal.push(uniformInfo);
            return { offset: 0, size: currentOffset, buffer: uniformBuffer };
        }
        runWebGPUProgram(program, inputs, outputDtype, programDefinedUniform, output) {
            if (!output) {
                output = this.makeTensorInfo(program.outputShape, outputDtype);
            }
            if (tf.util.sizeFromShape(output.shape) === 0) {
                // Short-circuit the computation since the result is empty (has 0 in its
                // shape).
                this.tensorMap.get(output.dataId).values =
                    tf.util.getTypedArrayFromDType(output.dtype, 0);
                return output;
            }
            this.uploadToGPU(output.dataId);
            program.dispatch = reshapeDispatch(this.device, program);
            // There are six kinds of uniforms: NAN, INFINITY, shapes, shape strides,
            // program size, program defined uniforms.
            let programUniform = [];
            let bufferShapes = [];
            if (!program.isFromPixels) {
                programUniform.push({ type: 'float32', data: [NaN] }, { type: 'float32', data: [Infinity] });
                bufferShapes = inputs.concat(output).map(d => d.shape);
                const uniformsType = 'int32';
                bufferShapes.map(d => {
                    programUniform.push({ type: uniformsType, data: d });
                });
                const strides = tf.util.computeStrides(output.shape);
                programUniform.push({ type: uniformsType, data: strides });
                if (program.size) {
                    const size = tf.util.sizeFromShape(program.outputShape);
                    programUniform.push({ type: uniformsType, data: [program.isVec4 ? size / 4 : size] });
                }
            }
            const inputsData = inputs.map((input, i) => {
                if (input.dtype === 'complex64') {
                    throw new Error(`GPGPUProgram does not support complex64 input. For complex64 ` +
                        `dtypes, please separate the program into real and imaginary ` +
                        `parts.`);
                }
                this.uploadToGPU(input.dataId);
                return {
                    // Returning dtype from tensorMap because it reflects dtype
                    // of underlying buffer, rather than abstract dtype.
                    dtype: this.tensorMap.get(input.dataId).dtype,
                    shape: input.shape,
                    name: program.variableNames[i]
                };
            });
            const key = makeShaderKey(program, bufferShapes, inputsData, output);
            let pipeline;
            if (key in this.pipelineCache) {
                pipeline = this.pipelineCache[key];
            }
            else {
                pipeline = compileProgram(this.device, program, inputsData, output);
                this.pipelineCache[key] = pipeline;
            }
            if (programDefinedUniform) {
                programUniform = [...programUniform, ...programDefinedUniform];
            }
            const bindings = [
                this.tensorToBinding(output), ...inputs.map(t => this.tensorToBinding(t)),
                this.makeUniforms(programUniform)
            ];
            const bindGroup = this.device.createBindGroup({
                layout: pipeline.getBindGroupLayout(0),
                entries: bindings.map((b, i) => ({ binding: i, resource: b })),
            });
            this.ensureCommandEncoderReady();
            const pass = this.getComputePass();
            const shouldTimeProgram = this.activeTimers != null;
            if (shouldTimeProgram) {
                if (this.supportTimeQuery) {
                    // tslint:disable-next-line:no-any
                    pass.writeTimestamp(this.querySet, 0);
                }
            }
            pass.setPipeline(pipeline);
            pass.setBindGroup(0, bindGroup);
            pass.dispatchWorkgroups(program.dispatch[0], program.dispatch[1], program.dispatch[2]);
            if (shouldTimeProgram) {
                if (this.supportTimeQuery) {
                    // tslint:disable-next-line:no-any
                    pass.writeTimestamp(this.querySet, 1);
                }
            }
            this.dispatchNumberInEncoder++;
            inputs.forEach(input => {
                this.commandQueueOwnedIds.add(input.dataId);
            });
            this.commandQueueOwnedIds.add(output.dataId);
            if (tf.env().get('WEBGPU_DEFERRED_SUBMIT_BATCH_SIZE') <= this.dispatchNumberInEncoder) {
                this.submitQueue();
            }
            if (shouldTimeProgram) {
                this.activeTimers.push({
                    name: program.constructor.name,
                    query: this.getQueryTime(this.querySet)
                });
            }
            return output;
        }
        async getTimeFromQuerySet(querySet) {
            const queryBuffer = this.bufferManager.acquireBuffer(16, GPUBufferUsage.COPY_SRC | GPUBufferUsage.QUERY_RESOLVE);
            const dst = this.bufferManager.acquireBuffer(16, GPUBufferUsage.MAP_READ | GPUBufferUsage.COPY_DST);
            this.ensureCommandEncoderReady();
            this.ensureComputePassEnded();
            this.currentCommandEncoder.resolveQuerySet(querySet, 0, 2, queryBuffer, 0);
            this.currentCommandEncoder.copyBufferToBuffer(queryBuffer, 0, dst, 0, 16);
            this.submitQueue();
            await dst.mapAsync(GPUMapMode.READ);
            const arrayBuf = new BigUint64Array(dst.getMappedRange());
            const timeElapsedNanos = Number((arrayBuf[1] - arrayBuf[0]));
            dst.unmap();
            this.bufferManager.releaseBuffer(dst, 16, GPUBufferUsage.MAP_READ | GPUBufferUsage.COPY_DST);
            this.bufferManager.releaseBuffer(queryBuffer, 16, GPUBufferUsage.COPY_SRC | GPUBufferUsage.QUERY_RESOLVE);
            // Return milliseconds.
            return timeElapsedNanos / 1000000;
        }
        shouldExecuteOnCPU(inputs, sizeThreshold = CPU_HANDOFF_SIZE_THRESHOLD) {
            return tf.env().getBool('WEBGPU_CPU_FORWARD') &&
                inputs.every(input => this.tensorMap.get(input.dataId).resourceInfo == null &&
                    tf.util.sizeFromShape(input.shape) < sizeThreshold);
        }
        numDataIds() {
            return this.tensorMap.numDataIds() - this.tensorDataPendingDisposal.length;
        }
        dispose() {
            if (this.disposed) {
                return;
            }
            this.bufferManager.dispose();
            this.textureManager.dispose();
            this.disposed = true;
        }
    }
    WebGPUBackend.nextDataId = 0;

    /**
     * @license
     * Copyright 2022 Google Inc. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    if (isWebGPUSupported()) {
        tf.registerBackend('webgpu', async () => {
            // Remove it once we figure out how to correctly read the tensor data
            // before the tensor is disposed in profiling mode.
            tf.env().set('CHECK_COMPUTATION_FOR_ERRORS', false);
            const gpuDescriptor = {
                powerPreference: tf.env().get('WEBGPU_USE_LOW_POWER_GPU') ?
                    'low-power' :
                    'high-performance'
            };
            const adapter = await navigator.gpu.requestAdapter(gpuDescriptor);
            const deviceDescriptor = {};
            // Note that timestamp-query-inside-passes is not formally in spec as
            // timestamp within a pass is not generally supported on all the platforms.
            // More details can be found at
            // https://github.com/gpuweb/gpuweb/blob/main/proposals/timestamp-query-inside-passes.md
            if (adapter.features.has('timestamp-query-inside-passes')) {
                deviceDescriptor.requiredFeatures =
                    // tslint:disable-next-line:no-any
                    ['timestamp-query-inside-passes'];
            }
            const adapterLimits = adapter.limits;
            deviceDescriptor.requiredLimits = {
                'maxComputeWorkgroupStorageSize': adapterLimits.maxComputeWorkgroupStorageSize,
                'maxComputeWorkgroupsPerDimension': adapterLimits.maxComputeWorkgroupsPerDimension,
                'maxStorageBufferBindingSize': adapterLimits.maxStorageBufferBindingSize,
            };
            const device = await adapter.requestDevice(deviceDescriptor);
            const adapterInfo = await adapter.requestAdapterInfo();
            return new WebGPUBackend(device, adapterInfo);
        }, 3 /*priority*/);
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    var BinaryOpType;
    (function (BinaryOpType) {
        BinaryOpType[BinaryOpType["ADD"] = 0] = "ADD";
        BinaryOpType[BinaryOpType["ATAN2"] = 1] = "ATAN2";
        BinaryOpType[BinaryOpType["COMPLEX_MULTIPLY_IMAG"] = 2] = "COMPLEX_MULTIPLY_IMAG";
        BinaryOpType[BinaryOpType["COMPLEX_MULTIPLY_REAL"] = 3] = "COMPLEX_MULTIPLY_REAL";
        BinaryOpType[BinaryOpType["DIV"] = 4] = "DIV";
        BinaryOpType[BinaryOpType["EQUAL"] = 5] = "EQUAL";
        BinaryOpType[BinaryOpType["GREATER"] = 6] = "GREATER";
        BinaryOpType[BinaryOpType["GREATER_EQUAL"] = 7] = "GREATER_EQUAL";
        BinaryOpType[BinaryOpType["INT_DIV"] = 8] = "INT_DIV";
        BinaryOpType[BinaryOpType["LESS"] = 9] = "LESS";
        BinaryOpType[BinaryOpType["LESS_EQUAL"] = 10] = "LESS_EQUAL";
        BinaryOpType[BinaryOpType["LOGICAL_AND"] = 11] = "LOGICAL_AND";
        BinaryOpType[BinaryOpType["LOGICAL_OR"] = 12] = "LOGICAL_OR";
        BinaryOpType[BinaryOpType["MAX"] = 13] = "MAX";
        BinaryOpType[BinaryOpType["MIN"] = 14] = "MIN";
        BinaryOpType[BinaryOpType["MOD"] = 15] = "MOD";
        BinaryOpType[BinaryOpType["MUL"] = 16] = "MUL";
        BinaryOpType[BinaryOpType["NOT_EQUAL"] = 17] = "NOT_EQUAL";
        BinaryOpType[BinaryOpType["POW"] = 18] = "POW";
        BinaryOpType[BinaryOpType["PRELU"] = 19] = "PRELU";
        BinaryOpType[BinaryOpType["SQUARED_DIFFERENCE"] = 20] = "SQUARED_DIFFERENCE";
        BinaryOpType[BinaryOpType["SUB"] = 21] = "SUB";
    })(BinaryOpType || (BinaryOpType = {}));
    const CHECK_NAN_SNIPPET = `
  if (isnan(a)) { return a; }
  if (isnan(b)) { return b; }
  `;
    const CHECK_NAN_SNIPPET_VEC4 = `
  resultTemp = select(
      resultTemp, vec4<f32>(valueForNaN),
      vec4<bool>(isNaN) | isnanVec4(a) | isnanVec4(b));
  `;
    const ADD = 'return a + b;';
    // (Ar + Ai)(Br + Bi) =
    // ArBr + ArBi + AiBr + AiBi = ArBr - AB + ArBi + AiBr
    // Yr = ArBr - AB
    // Yi = ArBi + AiBr
    const COMPLEX_MULTIPLY_REAL = 'return areal * breal - aimag * bimag;';
    const COMPLEX_MULTIPLY_IMAG = 'return areal * bimag + aimag * breal;';
    const DIV = 'return a / b;';
    const EQUAL = 'return f32(a == b);';
    const EQUAL_VEC4 = 'return vec4<f32>(a == b);';
    const GREATER = 'return f32(a > b);';
    const GREATER_VEC4 = 'return vec4<f32>(a > b);';
    const GREATER_EQUAL = 'return f32(a >= b);';
    const GREATER_EQUAL_VEC4 = 'return vec4<f32>(a >= b);';
    const INT_DIV = `
  let s = sign(a) * sign(b);
  let ia = i32(round(a));
  let ib = i32(round(b));
  return f32(idiv(ia, ib, s));
`;
    const INT_DIV_VEC4 = `
  let ia = vec4<i32>(round(a));
  let ib = vec4<i32>(round(b));
  let cond = ib != vec4<i32>(0);
  var resultTemp = vec4<i32>(0);
  let s = sign(a) * sign(b);

  // Windows (D3D) wants guaranteed non-zero int division at compile-time.
  if (cond[0]) {
    resultTemp[0] = idiv(ia[0], ib[0], s[0]);
  }
  if (cond[1]) {
    resultTemp[1] = idiv(ia[1], ib[1], s[1]);
  }
  if (cond[2]) {
    resultTemp[2] = idiv(ia[2], ib[2], s[2]);
  }
  if (cond[3]) {
    resultTemp[3] = idiv(ia[3], ib[3], s[3]);
  }
  return vec4<f32>(resultTemp);
`;
    const LESS = 'return f32(a < b);';
    const LESS_VEC4 = 'return vec4<f32>(a < b);';
    const LESS_EQUAL = 'return f32(a <= b);';
    const LESS_EQUAL_VEC4 = 'return vec4<f32>(a <= b);';
    const LOGICAL_AND = 'return f32(a >= 1.0 && b >= 1.0);';
    const LOGICAL_AND_VEC4 = `return (vec4<f32>(a >= vec4<f32>(1.0)) *
  vec4<f32>(b >= vec4<f32>(1.0)));`;
    const LOGICAL_OR = 'return f32(a >= 1.0 || b >= 1.0);';
    const LOGICAL_OR_VEC4 = `return min(vec4<f32>(a >= vec4<f32>(1.0)) +
  vec4<f32>(b >= vec4<f32>(1.0)), vec4<f32>(1.0));`;
    const MOD = `
  ${CHECK_NAN_SNIPPET}
  if (b == 0.) {
    return uniforms.NAN;
  }
  var resultTemp = a % b;
  if ((a < 0. && b < 0.) || (a >= 0. && b > 0.)) {
    return resultTemp;
  } else {
    return (resultTemp + b) % b;
  }
`;
    const MOD_VEC4 = `
  let isNaN = !vec4<bool>(b);
  let valueForNaN = uniforms.NAN;
  var resultTemp = vec4<f32>(a % b);
  ${CHECK_NAN_SNIPPET_VEC4}

  if (!((a[0] < 0. && b[0] < 0.) || (a[0] >= 0. && b[0] > 0.))) {
    resultTemp[0] = (resultTemp[0] + b[0]) % b[0];
  }
  if (!((a[1] < 0. && b[1] < 0.) || (a[1] >= 0. && b[1] > 0.))) {
    resultTemp[1] = (resultTemp[1] + b[1]) % b[1];
  }
  if (!((a[2] < 0. && b[2] < 0.) || (a[2] >= 0. && b[2] > 0.))) {
    resultTemp[2] = (resultTemp[2] + b[2]) % b[2];
  }
  if (!((a[3] < 0. && b[3] < 0.) || (a[3] >= 0. && b[3] > 0.))) {
    resultTemp[3] = (resultTemp[3] + b[3]) % b[3];
  }

  return resultTemp;
`;
    const MUL = 'return a * b;';
    const NOT_EQUAL = `
  if (isnan(a) || isnan(b)) {
    return 1.0;
  }
  return f32(a != b);
`;
    const NOT_EQUAL_VEC4 = `
  var resultTemp = vec4<f32>(a != b);
  let valueForNaN = 1.0;
  ${CHECK_NAN_SNIPPET_VEC4}

  return resultTemp;
`;
    const POW = `
  if(a < 0.0 && floor(b) < b) {
    return uniforms.NAN;
  }
  if (b == 0.0) {
    return 1.0;
  }
  if (round(abs(b) % 2.0) != 1.0) {
    return pow(abs(a), b);
  }
  return sign(a) * pow(abs(a), b);
`;
    const POW_VEC4 = `
  let isModRound1Bool = vec4<i32>(round(abs(b) % vec4<f32>(2.0))) == vec4<i32>(1);
  let isModRound1 = vec4<f32>(isModRound1Bool);
  let multiplier = sign(a) * isModRound1 + (vec4<f32>(1.0) - isModRound1);
  var resultTemp = multiplier * pow(abs(a), b);

  // Ensure that a^0 = 1, including 0^0 = 1 as this correspond to TF and JS
  let isExpZero = b == vec4<f32>(0.0);
  if (isExpZero.r) {
    resultTemp.r = 1.0;
  }
  if (isExpZero.g) {
    resultTemp.g = 1.0;
  }
  if (isExpZero.b) {
    resultTemp.b = 1.0;
  }
  if (isExpZero.a) {
    resultTemp.a = 1.0;
  }
  let isNaN = (a < vec4<f32>(0.0)) & (floor(b) < b);
  let valueForNaN = uniforms.NAN;
  ${CHECK_NAN_SNIPPET_VEC4}
  return resultTemp;
`;
    const PRELU = `if (a < 0.0) { return b * a; }  return a;`;
    const PRELU_VEC4 = `
  let aLessThanZero = vec4<f32>(a < vec4<f32>(0.0));
  return (aLessThanZero * (b * a)) + ((vec4<f32>(1.0) - aLessThanZero) * a);
`;
    const SQUARED_DIFFERENCE = 'return (a - b) * (a - b);';
    const SUB = 'return a - b;';
    function getBinaryWithNanString(op, useVec4, valueForNaN = 'uniforms.NAN') {
        const checkNanSnippet = useVec4 ? CHECK_NAN_SNIPPET_VEC4 : CHECK_NAN_SNIPPET;
        return useVec4 ? `
    let valueForNaN = ${valueForNaN};
    var resultTemp = vec4<f32>(${op}(a, b));
    ` + checkNanSnippet +
            `
    return resultTemp;
  ` :
            checkNanSnippet + `
    return ${op}(a, b);
  `;
    }
    function getBinaryOpString(type, useVec4) {
        switch (type) {
            case BinaryOpType.ADD:
                return ADD;
            case BinaryOpType.ATAN2:
                return getBinaryWithNanString('atan2', useVec4);
            case BinaryOpType.COMPLEX_MULTIPLY_IMAG:
                return COMPLEX_MULTIPLY_IMAG;
            case BinaryOpType.COMPLEX_MULTIPLY_REAL:
                return COMPLEX_MULTIPLY_REAL;
            case BinaryOpType.DIV:
                return DIV;
            case BinaryOpType.EQUAL:
                return useVec4 ? EQUAL_VEC4 : EQUAL;
            case BinaryOpType.GREATER:
                return useVec4 ? GREATER_VEC4 : GREATER;
            case BinaryOpType.GREATER_EQUAL:
                return useVec4 ? GREATER_EQUAL_VEC4 : GREATER_EQUAL;
            case BinaryOpType.INT_DIV:
                return useVec4 ? INT_DIV_VEC4 : INT_DIV;
            case BinaryOpType.LESS:
                return useVec4 ? LESS_VEC4 : LESS;
            case BinaryOpType.LESS_EQUAL:
                return useVec4 ? LESS_EQUAL_VEC4 : LESS_EQUAL;
            case BinaryOpType.LOGICAL_AND:
                return useVec4 ? LOGICAL_AND_VEC4 : LOGICAL_AND;
            case BinaryOpType.LOGICAL_OR:
                return useVec4 ? LOGICAL_OR_VEC4 : LOGICAL_OR;
            case BinaryOpType.MAX:
                return getBinaryWithNanString('max', useVec4);
            case BinaryOpType.MIN:
                return getBinaryWithNanString('min', useVec4);
            case BinaryOpType.MOD:
                return useVec4 ? MOD_VEC4 : MOD;
            case BinaryOpType.MUL:
                return MUL;
            case BinaryOpType.NOT_EQUAL:
                return useVec4 ? NOT_EQUAL_VEC4 : NOT_EQUAL;
            case BinaryOpType.POW:
                return useVec4 ? POW_VEC4 : POW;
            case BinaryOpType.PRELU:
                return useVec4 ? PRELU_VEC4 : PRELU;
            case BinaryOpType.SQUARED_DIFFERENCE:
                return SQUARED_DIFFERENCE;
            case BinaryOpType.SUB:
                return SUB;
            default:
                throw new Error(`BinaryType ${type} is not implemented!`);
        }
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    var UnaryOpType;
    (function (UnaryOpType) {
        UnaryOpType[UnaryOpType["ABS"] = 0] = "ABS";
        UnaryOpType[UnaryOpType["ACOS"] = 1] = "ACOS";
        UnaryOpType[UnaryOpType["ACOSH"] = 2] = "ACOSH";
        UnaryOpType[UnaryOpType["ASIN"] = 3] = "ASIN";
        UnaryOpType[UnaryOpType["ASINH"] = 4] = "ASINH";
        UnaryOpType[UnaryOpType["ATAN"] = 5] = "ATAN";
        UnaryOpType[UnaryOpType["ATANH"] = 6] = "ATANH";
        UnaryOpType[UnaryOpType["CEIL"] = 7] = "CEIL";
        UnaryOpType[UnaryOpType["COS"] = 8] = "COS";
        UnaryOpType[UnaryOpType["COSH"] = 9] = "COSH";
        UnaryOpType[UnaryOpType["ELU"] = 10] = "ELU";
        UnaryOpType[UnaryOpType["ERF"] = 11] = "ERF";
        UnaryOpType[UnaryOpType["EXP"] = 12] = "EXP";
        UnaryOpType[UnaryOpType["EXPM1"] = 13] = "EXPM1";
        UnaryOpType[UnaryOpType["FLOOR"] = 14] = "FLOOR";
        UnaryOpType[UnaryOpType["IS_FINITE"] = 15] = "IS_FINITE";
        UnaryOpType[UnaryOpType["IS_INF"] = 16] = "IS_INF";
        UnaryOpType[UnaryOpType["IS_NAN"] = 17] = "IS_NAN";
        UnaryOpType[UnaryOpType["LINEAR"] = 18] = "LINEAR";
        UnaryOpType[UnaryOpType["LOG"] = 19] = "LOG";
        UnaryOpType[UnaryOpType["LOG1P"] = 20] = "LOG1P";
        UnaryOpType[UnaryOpType["LOGICAL_NOT"] = 21] = "LOGICAL_NOT";
        UnaryOpType[UnaryOpType["NEG"] = 22] = "NEG";
        UnaryOpType[UnaryOpType["RELU"] = 23] = "RELU";
        UnaryOpType[UnaryOpType["RELU6"] = 24] = "RELU6";
        UnaryOpType[UnaryOpType["LEAKYRELU"] = 25] = "LEAKYRELU";
        UnaryOpType[UnaryOpType["RECIPROCAL"] = 26] = "RECIPROCAL";
        UnaryOpType[UnaryOpType["ROUND"] = 27] = "ROUND";
        UnaryOpType[UnaryOpType["RSQRT"] = 28] = "RSQRT";
        UnaryOpType[UnaryOpType["SELU"] = 29] = "SELU";
        UnaryOpType[UnaryOpType["SIGMOID"] = 30] = "SIGMOID";
        UnaryOpType[UnaryOpType["SIGN"] = 31] = "SIGN";
        UnaryOpType[UnaryOpType["SIN"] = 32] = "SIN";
        UnaryOpType[UnaryOpType["SINH"] = 33] = "SINH";
        UnaryOpType[UnaryOpType["SOFTPLUS"] = 34] = "SOFTPLUS";
        UnaryOpType[UnaryOpType["SQRT"] = 35] = "SQRT";
        UnaryOpType[UnaryOpType["SQUARE"] = 36] = "SQUARE";
        UnaryOpType[UnaryOpType["STEP"] = 37] = "STEP";
        UnaryOpType[UnaryOpType["TAN"] = 38] = "TAN";
        UnaryOpType[UnaryOpType["TANH"] = 39] = "TANH";
        UnaryOpType[UnaryOpType["TO_INT"] = 40] = "TO_INT";
    })(UnaryOpType || (UnaryOpType = {}));
    const ABS = `return abs(a);`;
    const ACOS = `
  if (abs(a) > 1.) {
    return uniforms.NAN;
  }
  return acos(a);
`;
    const ACOSH = `
  if (a < 1.) {
    return uniforms.NAN;
  }
  return acosh(a);
`;
    const ASIN = `
  if (abs(a) > 1.) {
    return uniforms.NAN;
  }
  return asin(a);
`;
    const ASINH = `return asinh(a);`;
    const ATAN = `
  if (isnan(a)) {
    return uniforms.NAN;
  }
  return atan(a);
`;
    const ATANH = `
  if (abs(a) > 1.) {
    return uniforms.NAN;
  }
  if (a == 1.) {
    return uniforms.INFINITY;
  }
  if (a == -1.) {
    return -uniforms.INFINITY;
  }
  return atanh(a);
`;
    const CEIL = `return ceil(a);`;
    const COS = `return cos(a);`;
    const COSH = `
  let e2x = exp(-a);
  return (e2x + 1.0 / e2x) / 2.0;
`;
    const EXPM1 = `return exp(a) - 1.0;`;
    const ELU = `if (a >= 0.0) { return a; }  return (exp(a) - 1.0);`;
    const ELU_VEC4 = `
  var resFloat = exp(a) - vec4<f32>(1.0);
  if (a.r >= 0.0) {
    resFloat.r = a.r;
  }
  if (a.g >= 0.0) {
    resFloat.g = a.g;
  }
  if (a.b >= 0.0) {
    resFloat.b = a.b;
  }
  if (a.a >= 0.0) {
    resFloat.a = a.a;
  }
  return resFloat;
`;
    const ERF = `
  // Error function is calculated approximately with elementary function.
  // See "Handbook of Mathematical Functions with Formulas,
  // Graphs, and Mathematical Tables", Abramowitz and Stegun.
  let p = ${tf.backend_util.ERF_P};
  let a1 = ${tf.backend_util.ERF_A1};
  let a2 = ${tf.backend_util.ERF_A2};
  let a3 = ${tf.backend_util.ERF_A3};
  let a4 = ${tf.backend_util.ERF_A4};
  let a5 = ${tf.backend_util.ERF_A5};

  let sign = sign(a);
  let absA = abs(a);
  let t = 1.0 / (1.0 + p * absA);
  return sign * (1.0 - (((((a5 * t + a4) * t) + a3) * t + a2) * t + a1) * t * exp(-absA * absA));
`;
    const EXP = `return exp(a);`;
    const FLOOR = `return floor(a);`;
    const IS_FINITE = `return f32(!isnan(a) && !isinf(a));`;
    const IS_INF = `return f32(isinf(a));`;
    const IS_NAN = `return f32(isnan(a));`;
    const LINEAR = `return a;`;
    const LOG = `if (a < 0.0) { return uniforms.NAN; }
  return log(a);`;
    const LOG1P = `
  if (isnan(a)) { return a; }
  return log(1.0 + a);
`;
    const LOGICAL_NOT = `return f32(!(a >= 1.0));`;
    const NEG = `return -a;`;
    const LEAKYRELU = `if (a < 0.0) { return uniforms.alpha * a; } return a;`;
    const LEAKYRELU_VEC4 = `
  let aLessThanZero = vec4<f32>(a < vec4<f32>(0.0));
  return (aLessThanZero * (uniforms.alpha * a)) + ((vec4<f32>(1.0) - aLessThanZero) * a);
`;
    const RECIPROCAL = `return 1.0 / a;`;
    const RELU = `return select(a, 0.0, a < 0.0);`;
    const RELU6 = 'return clamp(a, 0.0, 6.0);';
    const RELU6_VEC4 = 'return clamp(a, vec4<f32>(0.0, 0.0, 0.0, 0.0), vec4<f32>(6.0, 6.0, 6.0, 6.0));';
    const RELU_VEC4 = `
  return select(a, vec4<f32>(0.0), a < vec4<f32>(0.0));
`;
    const ROUND = `return round(a);`;
    const RSQRT = `return inverseSqrt(a);`;
    // Stable and Attracting Fixed Point (0, 1) for Normalized Weights.
    // See: https://arxiv.org/abs/1706.02515
    const SELU = `
  if (a >= 0.0) {
    return ${tf.backend_util.SELU_SCALE} * a;
  } else {
    return ${tf.backend_util.SELU_SCALEALPHA} * (exp(a) - 1.0);
  }
`;
    const SIGMOID = `return 1.0 / (1.0 + exp(-1.0 * a));`;
    const SIGN = `return sign(a);`;
    const SIN = `return sin(a);`;
    const SINH = `
  let e2x = exp(a);
  return (e2x - 1.0 / e2x) / 2.0;
`;
    const SOFTPLUS = `
  let epsilon = 1.1920928955078125e-7;
  let threshold = log(epsilon) + 2.0;

  let too_large = a > -threshold;
  let too_small = a < threshold;
  let exp_a = exp(a);

  if (too_large) {
    return a;
  } else if (too_small) {
    return exp_a;
  } else {
    return log(exp_a + 1.0);
  }
`;
    const SQRT = `return sqrt(a);`;
    const SQUARE = `return a * a;`;
    const STEP = `
  if (isnan(a)) {
    return a;
  }

  return select(uniforms.stepAlpha, 1.0, a > 0.0);
`;
    const TAN = `return tan(a);`;
    const TANH = `
  let e2x = exp(-2.0 * abs(a));
  return sign(a) * (1.0 - e2x) / (1.0 + e2x);
`;
    const TO_INT = `return f32(i32((a)));`;
    function getUnaryOpString(type, useVec4) {
        switch (type) {
            case UnaryOpType.ABS:
                return ABS;
            case UnaryOpType.ACOS:
                return ACOS;
            case UnaryOpType.ACOSH:
                return ACOSH;
            case UnaryOpType.ASIN:
                return ASIN;
            case UnaryOpType.ASINH:
                return ASINH;
            case UnaryOpType.ATAN:
                return ATAN;
            case UnaryOpType.ATANH:
                return ATANH;
            case UnaryOpType.COS:
                return COS;
            case UnaryOpType.COSH:
                return COSH;
            case UnaryOpType.CEIL:
                return CEIL;
            case UnaryOpType.ELU:
                return useVec4 ? ELU_VEC4 : ELU;
            case UnaryOpType.ERF:
                return ERF;
            case UnaryOpType.EXP:
                return EXP;
            case UnaryOpType.EXPM1:
                return EXPM1;
            case UnaryOpType.FLOOR:
                return FLOOR;
            case UnaryOpType.IS_FINITE:
                return IS_FINITE;
            case UnaryOpType.IS_INF:
                return IS_INF;
            case UnaryOpType.IS_NAN:
                return IS_NAN;
            case UnaryOpType.LINEAR:
                return LINEAR;
            case UnaryOpType.LOG:
                return LOG;
            case UnaryOpType.LOG1P:
                return LOG1P;
            case UnaryOpType.LOGICAL_NOT:
                return LOGICAL_NOT;
            case UnaryOpType.NEG:
                return NEG;
            case UnaryOpType.LEAKYRELU:
                return useVec4 ? LEAKYRELU_VEC4 : LEAKYRELU;
            case UnaryOpType.RECIPROCAL:
                return RECIPROCAL;
            case UnaryOpType.RELU:
                return useVec4 ? RELU_VEC4 : RELU;
            case UnaryOpType.RELU6:
                return useVec4 ? RELU6_VEC4 : RELU6;
            case UnaryOpType.ROUND:
                return ROUND;
            case UnaryOpType.RSQRT:
                return RSQRT;
            case UnaryOpType.SELU:
                return SELU;
            case UnaryOpType.SIGMOID:
                return SIGMOID;
            case UnaryOpType.SIGN:
                return SIGN;
            case UnaryOpType.SIN:
                return SIN;
            case UnaryOpType.SINH:
                return SINH;
            case UnaryOpType.SOFTPLUS:
                return SOFTPLUS;
            case UnaryOpType.SQRT:
                return SQRT;
            case UnaryOpType.SQUARE:
                return SQUARE;
            case UnaryOpType.STEP:
                return STEP;
            case UnaryOpType.TAN:
                return TAN;
            case UnaryOpType.TANH:
                return TANH;
            case UnaryOpType.TO_INT:
                return TO_INT;
            default:
                throw new Error(`BinaryType ${type} is not implemented!`);
        }
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const typeSnippet = (component) => {
        switch (component) {
            case 1:
                return 'f32';
            case 2:
                return 'vec2<f32>';
            case 3:
                return 'vec3<f32>';
            case 4:
                return 'vec4<f32>';
            default:
                throw new Error(`${component}-component is not supported.`);
        }
    };
    function activationFnSnippet(activation, hasPreluActivationWeights = false, packed = false, coordsLength = 3) {
        if (activation === null) {
            return '';
        }
        let activationOpSnippet = '';
        if (activation === 'linear') {
            activationOpSnippet = getUnaryOpString(UnaryOpType.LINEAR);
        }
        else if (activation === 'relu') {
            activationOpSnippet = getUnaryOpString(UnaryOpType.RELU, packed);
        }
        else if (activation === 'elu') {
            activationOpSnippet = getUnaryOpString(UnaryOpType.ELU, packed);
        }
        else if (activation === 'relu6') {
            activationOpSnippet = getUnaryOpString(UnaryOpType.RELU6, packed);
        }
        else if (activation === 'prelu') {
            activationOpSnippet = getBinaryOpString(BinaryOpType.PRELU, packed);
        }
        else if (activation === 'sigmoid') {
            activationOpSnippet = getUnaryOpString(UnaryOpType.SIGMOID, packed);
        }
        else if (activation === 'leakyrelu') {
            activationOpSnippet = getUnaryOpString(UnaryOpType.LEAKYRELU, packed);
        }
        else {
            throw new Error(`Activation ${activation} has not been implemented for the WebGPU backend.`);
        }
        const elementSize = packed ? 4 : 1;
        const dataType = typeSnippet(elementSize);
        let activationFnSnippet = '';
        if (hasPreluActivationWeights) {
            activationFnSnippet = `
      fn activation(a : ${dataType}, coords : vec${coordsLength}<i32>) -> ${dataType} {
        let b = getPreluActivationWeightsByOutputCoords(coords);
        ${activationOpSnippet}
      }`;
        }
        else {
            activationFnSnippet = `
      fn activation(a : ${dataType}, coords : vec${coordsLength}<i32>) -> ${dataType} {
        ${activationOpSnippet}
      }`;
        }
        return activationFnSnippet;
    }
    function biasActivationSnippet(hasBias, activation) {
        return `
      ${hasBias ? 'value = value + getBiasByOutputCoords(coords);' : ''}
      ${activation ? 'value = activation(value, coords);' : ''}
      `;
    }

    /**
     * @license
     * Copyright 2019 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function matMulReadFnSource(transposeA, transposeB, fitAOuter = false, fitBOuter = false, fitInner = false, component = 1) {
        tf.util.assert(transposeA && component === 1 || !transposeA, () => `transposeA ${transposeA} is not compatible with component size ${component}`);
        const sampleA = `
      ${transposeA ? `value = getA(batch, col, row);` :
        `value = getA(batch, row, col);`}

    `;
        const sampleB = transposeB ? `value = getB(batch, col, row);` :
            `value = getB(batch, row, col);`;
        return `
  fn mm_readA(batch: i32, row: i32, colIn: i32) -> ${typeSnippet(component)} {
    var value = ${typeSnippet(component)}(0.0);
    let col = colIn * ${component};
    ${fitAOuter && fitInner ?
        sampleA :
        `
    ${transposeA ?
            `if(row < uniforms.dimAOuter && col < uniforms.dimInner)` :
            `if(row < uniforms.aShape[1] && col < uniforms.aShape[2])`}
    {
      ${sampleA}
    }
    `}
    return value;
  }

  fn mm_readB(batch: i32, row: i32, colIn: i32) -> ${typeSnippet(component)} {
    let col = colIn * ${component};
    var value = ${typeSnippet(component)}(0.0);
    ${sampleB}
    return value;
  }
  `;
    }
    function matMulReadWriteFnSource(hasBias, activation, transposeA, transposeB, fitAOuter = false, fitBOuter = false, fitInner = false, component = 1) {
        return `
  ${matMulReadFnSource(transposeA, transposeB, fitAOuter, fitBOuter, fitInner, component)}
  fn mm_write(batch: i32, row: i32, colIn: i32, valueIn: ${typeSnippet(component)}) {
    let col = colIn * ${component};
    ${fitAOuter && fitBOuter ?
        '' :
        'if (row < uniforms.dimAOuter && col < uniforms.dimBOuter)'}
    {
      var value = valueIn;
      let coords = vec3<i32>(batch, row, col);
      ${biasActivationSnippet(hasBias, activation)}
      setOutputAtCoords(coords[0], coords[1], coords[2], value);
    }
  }
  `;
    }
    const writeDataToSubAVec4Snippet = (transpose, innerElementSize) => {
        if (transpose) {
            return `
        mm_Asub[inputRow][inputCol] = mm_readA(batchA,
          kStart + inputRow,
          globalRowStart / ${innerElementSize} + inputCol);
        `;
        }
        else {
            return `
        mm_Asub[inputRow][inputCol] = mm_readA(batchA,
          globalRow + innerRow,
          kStart / ${innerElementSize} + inputCol);
        `;
        }
    };
    const calculateResultSnippet = (transposeA, innerElementSize, rowPerThread) => {
        if (transposeA) {
            return `
        let ACached0 = mm_Asub[k * ${innerElementSize}][localRow];
        let ACached1 = mm_Asub[k * ${innerElementSize} + 1][localRow];
        let ACached2 = mm_Asub[k * ${innerElementSize} + 2][localRow];
        ${innerElementSize === 3 ? '' :
            `let ACached3 = mm_Asub[k * ${innerElementSize} + 3][localRow];`}
        for (var i = 0; i < ${rowPerThread}; i++) {
          acc[i] = BCached0 * ACached0[i] + acc[i];
          acc[i] = BCached1 * ACached1[i] + acc[i];
          acc[i] = BCached2 * ACached2[i] + acc[i];
          ${innerElementSize === 3 ?
            '' :
            'acc[i] = BCached3 * ACached3[i] + acc[i];'}
        }`;
        }
        else {
            return `
        for (var i = 0; i < ${rowPerThread}; i++) {
          let ACached = mm_Asub[tileRow + i][k];
          acc[i] = BCached0 * ACached.x + acc[i];
          acc[i] = BCached1 * ACached.y + acc[i];
          acc[i] = BCached2 * ACached.z + acc[i];
          ${innerElementSize === 3 ? '' :
            'acc[i] = BCached3 * ACached.w + acc[i];'}
        }`;
        }
    };
    function makeMatMulPackedVec4Source(workPerThread, workgroupSize, transposeA = false, tileInner = 32, splitK = false, splitedDimInner = 32, isVectorA = false, broadcastBatch = false) {
        const tileAOuter = workgroupSize[1] * workPerThread[1];
        const tileBOuter = workgroupSize[0] * workPerThread[0];
        const tileAWidth = transposeA ? tileAOuter : tileInner;
        const tileAHight = transposeA ? tileInner : tileAOuter;
        const innerElementSize = tileAWidth / workgroupSize[0];
        const rowPerThreadB = tileInner / workgroupSize[1];
        const rowPerThread = workPerThread[1];
        tf.util.assert(((transposeA && innerElementSize === 4 && workPerThread[1] === 4) ||
            (!transposeA && (innerElementSize === 3 || innerElementSize === 4))) &&
            tileAWidth % workgroupSize[0] === 0 &&
            tileInner % workgroupSize[1] === 0 && workPerThread[0] === 4, () => `If transposeA ${transposeA} is true, innerElementSize ${innerElementSize} and workPerThread[1] ${workPerThread[1]} must be 4.
          Otherwise, innerElementSize ${innerElementSize} must be 3 or 4.
      tileAWidth ${tileAWidth} must be divisible by workgroupSize[0]${workgroupSize[0]}. tileInner ${tileInner} must be divisible by workgroupSize[1] ${workgroupSize[1]}. colPerThread ${workPerThread[0]} must be 4.`);
        return `
  var<workgroup> mm_Asub : array<array<vec${innerElementSize}<f32>, ${tileAWidth / innerElementSize}>, ${tileAHight}>;
  var<workgroup> mm_Bsub : array<array<vec4<f32>, ${tileBOuter / workPerThread[0]}>, ${tileInner}>;

  ${getMainHeaderString()} {
    let localRow = i32(localId.y);
    let tileRow = ${isVectorA ? '0' : `localRow * ${rowPerThread}`};
    let tileCol = i32(localId.x);

    let globalRow = ${isVectorA ? '0' : `i32(globalId.y) * ${rowPerThread}`};
    let globalCol = i32(globalId.x);
    let batch = ${splitK ? '0' : 'i32(globalId.z)'};
    let batchA = ${splitK || !broadcastBatch ? 'batch' : 'batch % uniforms.aShape[0]'};
    let batchB = ${splitK || !broadcastBatch ? 'batch' : 'batch % uniforms.bShape[0]'};
    let globalRowStart = i32(workgroupId.y) * ${tileAOuter};

    let numTiles = ${splitK ? `${Math.ceil(splitedDimInner / tileInner)}` :
        `(uniforms.dimInner - 1) / ${tileInner} + 1`};
    var kStart = ${splitK ? `i32(globalId.z) * ${splitedDimInner}` : '0'};

    var acc: array<vec4<f32>, ${rowPerThread}>;

    // Loop over shared dimension.
    let tileRowB = localRow * ${rowPerThreadB};
    for (var t = 0; t < numTiles; t++) {
        // Load one tile of A into local memory.
        for (var innerRow = 0; innerRow < ${rowPerThread}; innerRow++) {
            let inputRow = tileRow + innerRow;
            let inputCol = tileCol;
            ${writeDataToSubAVec4Snippet(transposeA, innerElementSize)}
        }

        // Load one tile of B into local memory.
        for (var innerRow = 0; innerRow < ${rowPerThreadB}; innerRow++) {
            let inputRow = tileRowB + innerRow;
            let inputCol = tileCol;
            mm_Bsub[inputRow][inputCol] = mm_readB(batchB, kStart + inputRow, globalCol);
        }
        kStart = kStart + ${tileInner};
        workgroupBarrier();

        // Compute acc values for a single thread.
        for (var k = 0; k < ${tileInner / innerElementSize}; k++) {
            let BCached0 = mm_Bsub[k * ${innerElementSize}][tileCol];
            let BCached1 = mm_Bsub[k * ${innerElementSize} + 1][tileCol];
            let BCached2 = mm_Bsub[k * ${innerElementSize} + 2][tileCol];
            ${innerElementSize === 3 ?
        '' :
        `let BCached3 = mm_Bsub[k * ${innerElementSize} + 3][tileCol];`}

            ${calculateResultSnippet(transposeA, innerElementSize, rowPerThread)}
        }

        workgroupBarrier();
    }

    for (var innerRow = 0; innerRow < ${rowPerThread}; innerRow++) {
        mm_write(batch, globalRow + innerRow, globalCol, acc[innerRow]);
    }
  }`;
    }
    const writeDataToSubASnippet = (transpose) => {
        if (transpose) {
            return `
        mm_Asub[inputRow][inputCol] = mm_readA(batchA,
          kStart + inputRow,
          globalRowStart + inputCol);
        `;
        }
        else {
            return `
        mm_Asub[inputRow][inputCol] = mm_readA(batchA,
          globalRowStart + inputRow,
          kStart + inputCol);
        `;
        }
    };
    const readDataFromSubASnippet = (transposeA) => {
        return transposeA ? 'let ACached = mm_Asub[k][tileRow + innerRow];' :
            'let ACached = mm_Asub[tileRow + innerRow][k];';
    };
    // sequentialAccessByThreads means sequential data in memory is accessed by
    // threads, instead of a single thread (default behavior).
    function makeMatMulPackedSource(workPerThread, workgroupSize, transposeA = false, tileInner = 32, splitK = false, splitedDimInner = 32, sequentialAccessByThreads = false, broadcastBatch = false) {
        const tileAOuter = workPerThread[1] * workgroupSize[1];
        const tileBOuter = workPerThread[0] * workgroupSize[0];
        const tileAWidth = transposeA ? tileAOuter : tileInner;
        const tileAHight = transposeA ? tileInner : tileAOuter;
        tf.util.assert(tileAHight % workgroupSize[1] === 0 &&
            tileAWidth % workgroupSize[0] === 0 &&
            tileInner % workgroupSize[1] === 0, () => `tileAHight ${tileAHight} must be divisible by workgroupSize[1]${workgroupSize[1]}, tileAWidth ${tileAWidth} must be divisible by workgroupSize[0]${workgroupSize[0]}, tileInner ${tileInner} must be divisible by workgroupSize[1]${workgroupSize[1]}`);
        const rowPerThreadA = tileAHight / workgroupSize[1];
        const colPerThreadA = tileAWidth / workgroupSize[0];
        const rowPerThreadB = tileInner / workgroupSize[1];
        const rowPerThread = workPerThread[1];
        const colPerThread = workPerThread[0];
        const matmulSnippet = sequentialAccessByThreads ?
            `
      let localRow = i32(localId.y);
      let localCol = i32(localId.x);
      let globalRowStart = i32(workgroupId.y) * ${tileAOuter};
      let globalColStart = i32(workgroupId.x) * ${tileBOuter};

      // Loop over shared dimension.
      for (var t = 0; t < numTiles; t++) {
        // Load one tile of A into local memory.
        for (var inputRow = localRow; inputRow < ${tileAHight}; inputRow = inputRow + ${workgroupSize[1]}) {
          for (var inputCol = localCol; inputCol < ${tileAWidth}; inputCol = inputCol + ${workgroupSize[0]}) {
            ${writeDataToSubASnippet(transposeA)}
          }
        }
        // Load one tile of B into local memory.
        for (var inputRow = localRow; inputRow < ${tileInner}; inputRow = inputRow + ${workgroupSize[1]}) {
              for (var inputCol = localCol; inputCol < ${tileBOuter}; inputCol = inputCol + ${workgroupSize[0]}) {
            mm_Bsub[inputRow][inputCol] = mm_readB(batchB,
              kStart + inputRow,
              globalColStart + inputCol);
          }
        }
        kStart = kStart + ${tileInner};
        workgroupBarrier();

        // Compute acc values for a single thread.
        var BCached : array<f32, ${colPerThread}>;
        for (var k = 0; k < ${tileInner}; k++) {
          for (var inner = 0; inner < ${colPerThread}; inner++) {
            BCached[inner] = mm_Bsub[k][localCol + inner * ${workgroupSize[0]}];
          }
          for (var innerRow = 0; innerRow < ${rowPerThread}; innerRow++) {
            let ACached = ${transposeA ?
            `mm_Asub[k][localRow + innerRow * ${workgroupSize[1]}];` :
            `mm_Asub[localRow + innerRow * ${workgroupSize[1]}][k];`}
            for (var innerCol = 0; innerCol < ${colPerThread}; innerCol++) {
              acc[innerRow][innerCol] = acc[innerRow][innerCol] +
                  ACached * BCached[innerCol];
            }
          }
        }
        workgroupBarrier();
      }
      for (var innerRow = 0; innerRow < ${rowPerThread}; innerRow++) {
        let gRow = globalRowStart + localRow + innerRow * ${workgroupSize[1]};
        for (var innerCol = 0; innerCol < ${colPerThread}; innerCol++) {
          let gCol = globalColStart + localCol + innerCol * ${workgroupSize[0]};
          mm_write(batch, gRow, gCol, acc[innerRow][innerCol]);
        }
      }
      ` :
            `
  let tileRow = i32(localId.y) * ${rowPerThread};
  let tileCol = i32(localId.x) * ${colPerThread};

  let globalRow = i32(globalId.y) * ${rowPerThread};
  let globalCol = i32(globalId.x) * ${colPerThread};
  let globalRowStart = i32(workgroupId.y) * ${tileAOuter};

  let tileRowA = i32(localId.y) * ${rowPerThreadA};
  let tileColA = i32(localId.x) * ${colPerThreadA};
  let tileRowB = i32(localId.y) * ${rowPerThreadB};
  // Loop over shared dimension.
  for (var t = 0; t < numTiles; t++) {
    // Load one tile of A into local memory.
    for (var innerRow = 0; innerRow < ${rowPerThreadA}; innerRow++) {
      for (var innerCol = 0; innerCol < ${colPerThreadA}; innerCol++) {
        let inputRow = tileRowA + innerRow;
        let inputCol = tileColA + innerCol;
        ${writeDataToSubASnippet(transposeA)}
      }
    }

    // Load one tile of B into local memory.
    for (var innerRow = 0; innerRow < ${rowPerThreadB}; innerRow++) {
      for (var innerCol = 0; innerCol < ${colPerThread}; innerCol++) {
        let inputRow = tileRowB + innerRow;
        let inputCol = tileCol + innerCol;
        mm_Bsub[inputRow][inputCol] = mm_readB(batchB,
          kStart + inputRow,
          globalCol + innerCol);
      }
    }
    kStart = kStart + ${tileInner};
    workgroupBarrier();

    // Compute acc values for a single thread.
    var BCached : array<f32, ${colPerThread}>;
    for (var k = 0; k < ${tileInner}; k++) {
      for (var inner = 0; inner < ${colPerThread}; inner++) {
        BCached[inner] = mm_Bsub[k][tileCol + inner];
      }

      for (var innerRow = 0; innerRow < ${rowPerThread}; innerRow++) {
        ${readDataFromSubASnippet(transposeA)}
        for (var innerCol = 0; innerCol < ${colPerThread}; innerCol++) {
          acc[innerRow][innerCol] = acc[innerRow][innerCol] + ACached * BCached[innerCol];
        }
      }
    }

    workgroupBarrier();
  }

  for (var innerRow = 0; innerRow < ${rowPerThread}; innerRow++) {
    for (var innerCol = 0; innerCol < ${colPerThread}; innerCol++) {
      mm_write(batch, globalRow + innerRow, globalCol + innerCol,
          acc[innerRow][innerCol]);
    }
  }
  `;
        return `
    var<workgroup> mm_Asub : array<array<f32, ${tileAWidth}>, ${tileAHight}>;
    var<workgroup> mm_Bsub : array<array<f32, ${tileBOuter}>, ${tileInner}>;

    ${getMainHeaderString()} {
      let batch = ${splitK ? '0' : 'i32(globalId.z)'};
      let batchA = ${splitK || !broadcastBatch ? 'batch' : 'batch % uniforms.aShape[0]'};
      let batchB = ${splitK || !broadcastBatch ? 'batch' : 'batch % uniforms.bShape[0]'};
      let numTiles = ${splitK ? `${Math.ceil(splitedDimInner / tileInner)}` :
        `(uniforms.dimInner - 1) / ${tileInner} + 1`};
      var kStart = ${splitK ? `i32(globalId.z) * ${splitedDimInner}` : '0'};

      var acc : array<array<f32, ${colPerThread}>, ${rowPerThread}>;

      // Without this initialization strange values show up in acc.
      for (var innerRow = 0; innerRow < ${rowPerThread}; innerRow++) {
        for (var innerCol = 0; innerCol < ${colPerThread}; innerCol++) {
          acc[innerRow][innerCol] = 0.0;
        }
      }
      ${matmulSnippet}
    }
  `;
    }
    const readVectorASnippet = (transpose) => {
        return transpose ? `
      mm_readA(batchA, colA, globalRow),
      mm_readA(batchA, colA + 1, globalRow),
      mm_readA(batchA, colA + 2, globalRow),
      mm_readA(batchA, colA + 3, globalRow)
  ` :
            `
      mm_readA(batchA, globalRow, colA),
      mm_readA(batchA, globalRow, colA + 1),
      mm_readA(batchA, globalRow, colA + 2),
      mm_readA(batchA, globalRow, colA + 3)
  `;
    };
    function makeVectorMatrixProductSource(workgroupSize, transposeA = false) {
        tf.util.assert(workgroupSize[1] === 1 && workgroupSize[2] === 1, () => `A linear work group size is required. But got ${workgroupSize}.`);
        const tileSize = workgroupSize[0] * 4;
        return `
    var<workgroup> mm_Asub : array<vec4<f32>, ${workgroupSize[0]}>;

    ${getMainHeaderString()} {
      let tileCol = i32(localId.x);
      let globalCol = i32(globalId.x);
      let globalRow = i32(globalId.y);

      let numTiles = (uniforms.dimInner - 1) / ${tileSize} + 1;
      let batch = i32(globalId.z);
      let batchA = batch % uniforms.aShape[0];
      let batchB = batch % uniforms.bShape[0];
      // Without this initialization strange values show up in acc.
      var acc = 0.0;

      // Loop over shared dimension.
      for (var t = 0; t < numTiles; t++) {
        // Load one tile of A into local memory.
        let colA = t * ${tileSize} + tileCol * 4;
        mm_Asub[tileCol] = vec4<f32>(${readVectorASnippet(transposeA)});
        workgroupBarrier();

        // Compute acc values for a single thread.
        for (var k = 0; k < ${tileSize / 4}; k++) {
          let rowB = t * ${tileSize} + k * 4;
          let BCached = vec4<f32>(mm_readB(batchB, rowB, globalCol),
                              mm_readB(batchB, rowB + 1, globalCol),
                              mm_readB(batchB, rowB + 2, globalCol),
                              mm_readB(batchB, rowB + 3, globalCol));

          let ACached = mm_Asub[k];
          acc = acc + dot(ACached, BCached);
        }

        workgroupBarrier();
      }

      mm_write(batch, globalRow, globalCol, acc);
    }
  `;
    }
    class MatMulPackedProgram {
        constructor(aShape, outputShape, transposeA = false, transposeB = false, bias = null, activation = null, preluActivationWeights = null, sequentialAccessByThreads = false) {
            this.variableNames = ['A', 'B'];
            this.uniforms = `dimAOuter : i32, dimBOuter : i32, dimInner : i32,`;
            this.outputShape = outputShape;
            this.dispatchLayout = { x: [2], y: [1], z: [0] };
            const dimInner = transposeA ? aShape[1] : aShape[2];
            this.isVec4 = ((dimInner % 4 === 0 && !transposeA) ||
                (outputShape[1] % 4 === 0 && transposeA)) &&
                outputShape[2] % 4 === 0 && !transposeB;
            this.isVectorA = outputShape[1] === 1 && !transposeA;
            if (!this.isVec4 && this.isVectorA) {
                // For makeVectorMatrixProductSource
                this.elementsPerThread = [1, 1, 1];
                this.workgroupSize = [32, 1, 1];
            }
            else {
                const workgroupInfo = computeWorkgroupInfoForMatMul(outputShape[1], dimInner, outputShape[2], transposeA);
                this.workgroupSize = workgroupInfo.workgroupSize;
                this.elementsPerThread = workgroupInfo.elementsPerThread;
            }
            this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize, this.elementsPerThread);
            const addBias = bias != null;
            const hasPreluActivationWeights = preluActivationWeights != null;
            if (addBias) {
                this.variableNames.push('bias');
            }
            if (hasPreluActivationWeights) {
                this.variableNames.push('preluActivationWeights');
            }
            this.sequentialAccessByThreads = sequentialAccessByThreads;
            this.transposeA = transposeA;
            this.transposeB = transposeB;
            this.addBias = addBias;
            this.activation = activation;
            this.hasPreluActivationWeights = hasPreluActivationWeights;
            [this.fitAOuter, this.fitBOuter, this.fitInner] =
                this.getShapeFit(outputShape[1], outputShape[2], dimInner);
            this.shaderKey = `matMulPacked_${this.elementsPerThread}_${transposeA}_${transposeB}_${this.activation}_${this.fitAOuter}_${this.fitBOuter}_${this.fitInner}_${this.isVec4}_${this.isVectorA}_${this.sequentialAccessByThreads}`;
        }
        getShapeFit(dimAOuter, dimBOuter, dimInner) {
            const tileAOuter = this.workgroupSize[1] * this.elementsPerThread[1];
            const tileBOuter = this.workgroupSize[0] * this.elementsPerThread[0];
            if (!this.isVec4 && this.isVectorA) {
                // For makeVectorMatrixProductSource
                this.tileInner = this.workgroupSize[0] * 4;
            }
            else {
                this.tileInner = tileBOuter;
            }
            const fitAOuter = dimAOuter % tileAOuter === 0;
            const fitBOuter = dimBOuter % tileBOuter === 0;
            const fitInner = dimInner % this.tileInner === 0;
            return [fitAOuter, fitBOuter, fitInner];
        }
        getUserCode() {
            const userCode = `
      ${activationFnSnippet(this.activation, this.hasPreluActivationWeights, this.isVec4)}
      ${matMulReadWriteFnSource(this.addBias, this.activation, false /* transposeA is implemented in makeMatMulPackedSource */, this.transposeB, this.fitAOuter, this.fitBOuter, this.fitInner, this.isVec4 ? 4 : 1)}
      ${this.isVec4 ?
            makeMatMulPackedVec4Source(this.elementsPerThread, this.workgroupSize, this.transposeA, this.tileInner, false, null, this.isVectorA, true) :
            (this.isVectorA ? makeVectorMatrixProductSource(this.workgroupSize, this.transposeA) :
                makeMatMulPackedSource(this.elementsPerThread, this.workgroupSize, this.transposeA, this.tileInner, false, null, this.sequentialAccessByThreads, true))}
    `;
            return userCode;
        }
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function makeMatMulReduceSource(workgroupSizeX) {
        return `
    var<workgroup> sumValues : array<f32, ${workgroupSizeX}>;
    ${getMainHeaderString()} {
      let coords = getOutputCoords();
      let batch = coords[0];
      let batchA = batch % uniforms.aShape[0];
      let batchB = batch % uniforms.bShape[0];
      let row = coords[1];
      let col = coords[2];
      var sum = 0.0;
      let Length = uniforms.dimInner;
      for (var k = i32(localId.x); k < Length; k = k + ${workgroupSizeX}) {
        let dataA = mm_readA(batchA, row, k);
        let dataB = mm_readB(batchB, k, col);
        sum = sum + dataA * dataB;
      }
      sumValues[localId.x] = sum;
      workgroupBarrier();

      for(var currentSize = ${workgroupSizeX / 2}u; currentSize > 1u;
          currentSize = currentSize / 2u) {
        if (localId.x < currentSize)
        {
          sumValues[localId.x] = sumValues[localId.x] + sumValues[localId.x + currentSize];
        }
        workgroupBarrier();
      }

      if (localId.x == 0u) {
        sum = sumValues[0] + sumValues[1];
        mm_write(batch, row, col, sum);
      }
    }
  `;
    }
    class MatMulReduceProgram {
        constructor(outputShape, transposeA = false, transposeB = false, bias = null, activation = null, preluActivationWeights = null) {
            this.variableNames = ['A', 'B'];
            this.uniforms = `dimAOuter : i32, dimBOuter : i32, dimInner : i32,`;
            this.workgroupSize = [256, 1, 1];
            this.outputShape = outputShape;
            this.dispatchLayout = { x: [], y: [1, 2], z: [0] };
            this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
            const addBias = bias != null;
            const hasPreluActivationWeights = preluActivationWeights != null;
            if (addBias) {
                this.variableNames.push('bias');
            }
            if (hasPreluActivationWeights) {
                this.variableNames.push('preluActivationWeights');
            }
            this.transposeA = transposeA;
            this.transposeB = transposeB;
            this.addBias = addBias;
            this.activation = activation;
            this.hasPreluActivationWeights = hasPreluActivationWeights;
            this.shaderKey =
                `matMulReduce_${this.activation}_${transposeA}_${transposeB}`;
        }
        getUserCode() {
            const userCode = `
      ${activationFnSnippet(this.activation, this.hasPreluActivationWeights)}
      ${matMulReadWriteFnSource(this.addBias, this.activation, this.transposeA, this.transposeB)}
      ${makeMatMulReduceSource(this.workgroupSize[0])}
    `;
            return userCode;
        }
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function makeMatMulSmallOutputSizeSource(workgroupSize) {
        const tileAOuter = workgroupSize[1];
        const tileBOuter = workgroupSize[0];
        const tileInner = tileAOuter > tileBOuter ? tileAOuter : tileBOuter;
        return `
  var<workgroup> mm_Asub : array<array<f32, ${tileInner}>, ${tileAOuter}>;
  var<workgroup> mm_Bsub : array<array<f32, ${tileBOuter}>, ${tileInner}>;

  // If the output size is small for matrix multiplication, avoid to use vec4
  // and handle some elements per thread to optimally utilize the ALU.
  // Read data from global memory to registers firstly, then store them into
  // shared memory, so it is instruction-Level parallelism for arithmetic
  // operations and others handle IO operations between barrier api, makes ALU
  // and load/store units work simultaneously, could improves the performance.
  ${getMainHeaderString()} {
    let tileRow = i32(localId.y);
    let tileCol = i32(localId.x);
    let globalRow = i32(globalId.y);
    let globalCol = i32(globalId.x);
    let batch = i32(globalId.z);
    let batchA = batch % uniforms.aShape[0];
    let batchB = batch % uniforms.bShape[0];

    // uniforms.dimInner should be greater than 0.
    let numTiles = (uniforms.dimInner - 1) / ${tileInner} + 1;
    var acc = 0.0;

    var globalColA = tileCol;
    var globalRowB = 0;
    var regA = mm_readA(batchA, globalRow, globalColA);
    var regB0 = mm_readB(batchB, globalRowB + 2 * tileRow, globalCol);
    var regB1 = mm_readB(batchB, globalRowB + 2 * tileRow + 1, globalCol);
    globalColA = globalColA + ${tileInner};
    globalRowB = globalRowB + ${tileInner};

    for (var t = 0; t < numTiles; t = t + 1) {
      mm_Asub[tileRow][tileCol] = regA;
      mm_Bsub[2 * tileRow][tileCol] = regB0;
      mm_Bsub[2 * tileRow + 1][tileCol] = regB1;

      workgroupBarrier();

      regA = mm_readA(batchA, globalRow, globalColA);
      regB0 = mm_readB(batchB, globalRowB + 2 * tileRow, globalCol);
      regB1 = mm_readB(batchB, globalRowB + 2 * tileRow + 1, globalCol);
      globalColA = globalColA + ${tileInner};
      globalRowB = globalRowB + ${tileInner};

      for (var k = 0; k < ${tileInner}; k = k + 1) {
        acc = acc + mm_Asub[tileRow][k] * mm_Bsub[k][tileCol];
      }
      workgroupBarrier();
    }

    mm_write(batch, globalRow, globalCol, acc);
  }
  `;
    }
    class MatMulSmallOutputSizeProgram {
        constructor(aShape, bShape, outputShape, transposeA = false, transposeB = false, bias = null, activation = null, preluActivationWeights = null) {
            this.variableNames = ['A', 'B'];
            this.uniforms = `dimAOuter : i32, dimBOuter : i32, dimInner : i32,`;
            this.workgroupSize = [16, 8, 1];
            this.outputShape = outputShape;
            this.dispatchLayout = { x: [2], y: [1], z: [0] };
            this.dispatch = [
                Math.ceil(outputShape[2] / this.workgroupSize[0]),
                Math.ceil(outputShape[1] / this.workgroupSize[1]), outputShape[0]
            ];
            const addBias = bias != null;
            if (addBias) {
                this.variableNames.push('bias');
            }
            const hasPreluActivationWeights = preluActivationWeights != null;
            if (hasPreluActivationWeights) {
                this.variableNames.push('preluActivationWeights');
            }
            this.transposeA = transposeA;
            this.transposeB = transposeB;
            this.addBias = addBias;
            this.activation = activation;
            this.hasPreluActivationWeights = hasPreluActivationWeights;
            this.shaderKey =
                `matMulSmallOutputSize_${this.activation}_${transposeA}_${transposeB}`;
        }
        getUserCode() {
            const userCode = `
      ${activationFnSnippet(this.activation, this.hasPreluActivationWeights)}
      ${matMulReadWriteFnSource(this.addBias, this.activation, this.transposeA, this.transposeB)}
      ${makeMatMulSmallOutputSizeSource(this.workgroupSize)}
    `;
            return userCode;
        }
    }

    /**
     * @license
     * Copyright 2022 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    class MatMulSplitKProgram {
        constructor(outputShape, dimInner, transposeA = false, transposeB = false) {
            this.variableNames = ['A', 'B'];
            this.uniforms = `dimAOuter : i32, dimBOuter : i32, dimInner : i32,`;
            this.workgroupSize = [8, 8, 1];
            this.atomic = true;
            this.isVec4 = false;
            this.splitedDimInner = 128;
            tf.util.assert(outputShape[0] === 1, () => 'MatMulSplitKProgram only supports batch = 1.');
            this.outputShape = outputShape;
            this.dispatchLayout = { x: [2], y: [1], z: [0, 3] };
            this.isVec4 = (transposeA && this.outputShape[1] % 4 === 0 ||
                !transposeA && dimInner % 4 === 0) &&
                this.outputShape[2] % 4 === 0;
            this.elementsPerThread = [4, 4, this.splitedDimInner];
            if (!this.isVec4) {
                if (this.outputShape[1] < 16) {
                    this.elementsPerThread[1] = 1;
                }
                if (this.outputShape[2] < 16) {
                    this.elementsPerThread[0] = 1;
                }
            }
            this.dispatch = computeDispatch(this.dispatchLayout, [
                this.outputShape[0], this.outputShape[1], this.outputShape[2],
                dimInner
            ], this.workgroupSize, this.elementsPerThread);
            this.transposeA = transposeA;
            this.transposeB = transposeB;
            this.shaderKey = `matMulSplitK_${transposeA}_${transposeB}_${this.elementsPerThread}_${this.isVec4}`;
        }
        getUserCode() {
            const component = this.isVec4 ? 4 : 1;
            const userCode = `
      ${matMulReadFnSource(false, this.transposeB, false, false, false, component)}
      fn mm_write(batch: i32, row : i32, colIn : i32, value : ${typeSnippet(component)}) {
        let col = colIn * ${component};
        if (row < uniforms.dimAOuter && col < uniforms.dimBOuter) {
          let coords = vec3<i32>(batch, row, col);
          let flatIndex = getOutputIndexFromCoords(coords);
          // The problem is that we should initialize output to zero before using.
          // Otherwise, the original value will be added to the result.
          for (var i = 0; i < ${component}; i = i + 1) {
            ${atomicAddSnippet('&result[flatIndex + i]', `${component > 1 ? 'value[i]' : 'value'}`, 'float32')}
          }
        }
      }
      ${this.isVec4 ? makeMatMulPackedVec4Source(this.elementsPerThread, this.workgroupSize, this.transposeA, 32, true, this.splitedDimInner) :
            makeMatMulPackedSource(this.elementsPerThread, this.workgroupSize, this.transposeA, 32, true, this.splitedDimInner)}
    `;
            return userCode;
        }
    }
    class BiasActivationProgram {
        constructor(outputShape, bias = null, activation = null, preluActivationWeights = null) {
            this.uniforms = '';
            this.variableNames = ['x'];
            this.workgroupSize = [64, 1, 1];
            this.size = true;
            this.outputShape = outputShape;
            this.dispatchLayout = flatDispatchLayout(this.outputShape);
            this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
            this.addBias = bias != null;
            this.hasPreluActivationWeights = preluActivationWeights != null;
            this.activation = activation;
            if (this.addBias) {
                this.variableNames.push('bias');
            }
            if (this.hasPreluActivationWeights) {
                this.variableNames.push('preluActivationWeights');
            }
            this.shaderKey = `biasActivation_${activation}`;
        }
        getUserCode() {
            return `
    ${activationFnSnippet(this.activation, this.hasPreluActivationWeights)}
    ${getMainHeaderString('index')} {
      if (index < uniforms.size) {
        let coords = getCoordsFromIndex(index);
        var value = getXByOutputIndex(index);
        ${biasActivationSnippet(this.addBias, this.activation)}
        setOutputAtIndex(index, value);
      }
    }
    `;
        }
    }

    /**
     * @license
     * Copyright 2019 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    class FillProgram {
        constructor(shape) {
            this.variableNames = [];
            this.outputShape = [];
            this.uniforms = 'value : f32,';
            this.workgroupSize = [64, 1, 1];
            this.size = true;
            this.outputShape = shape;
            this.dispatchLayout = flatDispatchLayout(this.outputShape);
            this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
            this.shaderKey = 'fill';
        }
        getUserCode() {
            const userCode = `
    ${getMainHeaderString('index')} {
      if (index < uniforms.size) {
        setOutputAtIndex(index, uniforms.value);
      }
    }
  `;
            return userCode;
        }
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function fill(args) {
        const { backend, attrs } = args;
        const { shape, value } = attrs;
        let { dtype } = attrs;
        dtype = dtype || tf.util.inferDtype(value);
        if (dtype === 'string') {
            // String type should be handled in CPU memory.
            const values = tf.util.getArrayFromDType(dtype, tf.util.sizeFromShape(shape));
            values.fill(value);
            return backend.makeTensorInfo(shape, dtype, values);
        }
        else {
            const program = new FillProgram(shape);
            const uniformData = [{ type: 'float32', data: [value] }];
            return backend.runWebGPUProgram(program, [], dtype, uniformData);
        }
    }
    const fillConfig = {
        kernelName: tf.Fill,
        backendName: 'webgpu',
        kernelFunc: fill
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function reshape(args) {
        const { inputs, attrs } = args;
        const { x } = inputs;
        const { shape } = attrs;
        const xSize = tf.util.sizeFromShape(x.shape);
        const $shape = tf.util.inferFromImplicitShape(shape, xSize);
        const $xSize = tf.util.sizeFromShape($shape);
        tf.util.assert(xSize === $xSize, () => `The new shape (${$shape}) has ${$xSize} elements and the old ` +
            `shape (${x.shape}) has ${xSize} elements. The new shape and old ` +
            `shape must have the same number of elements.`);
        // Backend needs to track refCount for the dataId for reshape op
        args.backend.incRef(x.dataId);
        return { dataId: x.dataId, shape: $shape, dtype: x.dtype };
    }
    const reshapeConfig = {
        kernelName: tf.Reshape,
        backendName: 'webgpu',
        kernelFunc: reshape
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function batchMatMulImpl({ a, b, transposeA, transposeB, backend, bias = null, preluActivationWeights = null, leakyreluAlpha = 0, activation = null }) {
        const aRank = a.shape.length;
        const bRank = b.shape.length;
        const innerShapeA = transposeA ? a.shape[aRank - 2] : a.shape[aRank - 1];
        const innerShapeB = transposeB ? b.shape[bRank - 1] : b.shape[bRank - 2];
        const outerShapeA = transposeA ? a.shape[aRank - 1] : a.shape[aRank - 2];
        const outerShapeB = transposeB ? b.shape[bRank - 2] : b.shape[bRank - 1];
        const outerDimsA = a.shape.slice(0, -2);
        const outerDimsB = b.shape.slice(0, -2);
        const batchDimA = tf.util.sizeFromShape(outerDimsA);
        const batchDimB = tf.util.sizeFromShape(outerDimsB);
        const outShapeOuterDims = tf.broadcast_util.assertAndGetBroadcastShape(a.shape.slice(0, -2), b.shape.slice(0, -2));
        const outShape = outShapeOuterDims.concat([outerShapeA, outerShapeB]);
        tf.util.assert(innerShapeA === innerShapeB, () => `Error in matMul: inner shapes (${innerShapeA}) and (` +
            `${innerShapeB}) of Tensors with shapes ${a.shape} and ` +
            `${b.shape} and transposeA=${transposeA}` +
            ` and transposeB=${transposeB} must match.`);
        const a3dShape = transposeA ?
            [batchDimA, innerShapeA, outerShapeA] :
            [batchDimA, outerShapeA, innerShapeA];
        const b3dShape = transposeB ?
            [batchDimB, outerShapeB, innerShapeB] :
            [batchDimB, innerShapeB, outerShapeB];
        // The rest of the implementation is designed to operate on rank-3 tensors
        const a3d = reshape({ inputs: { x: a }, backend, attrs: { shape: a3dShape } });
        const b3d = reshape({ inputs: { x: b }, backend, attrs: { shape: b3dShape } });
        const intermediates = [a3d, b3d];
        const batchDim = Math.max(batchDimA, batchDimB);
        const inputs = [a3d, b3d];
        const dimensions = [
            { type: 'int32', data: [outerShapeA] }, { type: 'int32', data: [outerShapeB] },
            { type: 'int32', data: [innerShapeA] }
        ];
        let program;
        let out;
        const outputShape = [batchDim, outerShapeA, outerShapeB];
        let matmulProgramType = tf.env().get('WEBGPU_MATMUL_PROGRAM_TYPE');
        if (matmulProgramType < 0) {
            // Usually increasing workgroups is a good way to gain more performance for
            // few workgroups by tiling 32x32 (default matmul algorithm). Currently,
            // there are three ways to increase workgroups. 1) MatMulReduceProgram,
            // which is used only when the output size is very small (128 for now). 2)
            // MatMulSplitKProgram, increasing workgroups by spliting K. 3)
            // MatMulSmallOutputSizeProgram, increasing workgroups by small tile size.
            // For different devices, the minimum optimal workgroups may be different.
            // So here we set a |thresholdToIncreaseWorkgroups| to indicate whether we
            // need to increase workgroups. And the literal number is an empirical
            // value.
            const thresholdFlagValue = tf.env().getNumber('WEBGPU_THRESHOLD_TO_INCREASE_WORKGROUPS_FOR_MATMUL');
            const thresholdToIncreaseWorkgroups = thresholdFlagValue > 0 ?
                thresholdFlagValue :
                backend.thresholdToIncreaseWorkgroups;
            const workgroupsBy32x32 = batchDim * Math.ceil(outerShapeA / 32) * Math.ceil(outerShapeB / 32);
            const hasFewWorkgroups = workgroupsBy32x32 <= thresholdToIncreaseWorkgroups ||
                (outerShapeA <= 8 &&
                    workgroupsBy32x32 <= thresholdToIncreaseWorkgroups * 2);
            if (hasFewWorkgroups) {
                if (batchDim * outerShapeA * outerShapeB <= 128) {
                    matmulProgramType = MatMulProgramType.MatMulReduceProgram;
                }
                else if (batchDim === 1 && innerShapeB >= 2000) {
                    matmulProgramType = MatMulProgramType.MatMulSplitKProgram;
                }
                else {
                    matmulProgramType = MatMulProgramType.MatMulSmallOutputSizeProgram;
                }
            }
            else {
                matmulProgramType = MatMulProgramType.MatMulPackedProgram;
            }
        }
        switch (matmulProgramType) {
            case MatMulProgramType.MatMulReduceProgram:
                program = new MatMulReduceProgram(outputShape, transposeA, transposeB, bias, activation, preluActivationWeights);
                break;
            case MatMulProgramType.MatMulSplitKProgram: {
                // The output buffer must be initailzed to zero before using since we
                // use atomicAdd in MatMulSplitKProgram.
                out = fill({ backend, attrs: { shape: outputShape, value: 0, dtype: a.dtype } });
                program = new MatMulSplitKProgram(outputShape, innerShapeB, transposeA, transposeB);
                if (bias || activation) {
                    out =
                        backend.runWebGPUProgram(program, inputs, a.dtype, dimensions, out);
                    const biasActivationProgram = new BiasActivationProgram(out.shape, bias, activation, preluActivationWeights);
                    let uniformData = null;
                    const activationInputs = [out];
                    if (bias) {
                        activationInputs.push(bias);
                    }
                    if (preluActivationWeights) {
                        activationInputs.push(preluActivationWeights);
                    }
                    if (activation === 'leakyrelu') {
                        uniformData = [{ type: 'float32', data: [leakyreluAlpha] }];
                        biasActivationProgram.uniforms += ' alpha : f32,';
                    }
                    const outActivated = backend.runWebGPUProgram(biasActivationProgram, activationInputs, out.dtype, uniformData);
                    intermediates.push(out);
                    const outReshaped = reshape({ inputs: { x: outActivated }, backend, attrs: { shape: outShape } });
                    intermediates.push(outActivated);
                    for (const i of intermediates) {
                        backend.disposeData(i.dataId);
                    }
                    return outReshaped;
                }
                break;
            }
            case MatMulProgramType.MatMulSmallOutputSizeProgram:
                program = new MatMulSmallOutputSizeProgram(a3dShape, b3dShape, outputShape, transposeA, transposeB, bias, activation, preluActivationWeights);
                break;
            case MatMulProgramType.MatMulPackedProgram:
                // Experiments show that sequential access is more friendly for Intel
                // GPUs.
                const sequentialAccessByThreads = backend.adapterInfo.isIntel();
                program = new MatMulPackedProgram(a3dShape, outputShape, transposeA, transposeB, bias, activation, preluActivationWeights, sequentialAccessByThreads);
                break;
            default:
                throw new Error(`Unsupported MatMulProgramType ${matmulProgramType}.`);
        }
        if (bias) {
            inputs.push(bias);
        }
        if (preluActivationWeights) {
            inputs.push(preluActivationWeights);
        }
        if (activation === 'leakyrelu') {
            dimensions.push({ type: 'float32', data: [leakyreluAlpha] });
            program.uniforms += ' alpha : f32,';
        }
        out = backend.runWebGPUProgram(program, inputs, a.dtype, dimensions, out);
        const outReshaped = reshape({ inputs: { x: out }, backend, attrs: { shape: outShape } });
        intermediates.push(out);
        for (const i of intermediates) {
            backend.disposeData(i.dataId);
        }
        return outReshaped;
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function _fusedMatMul(args) {
        const { inputs, backend, attrs } = args;
        const { a, b, bias, preluActivationWeights } = inputs;
        const { transposeA, transposeB, activation, leakyreluAlpha } = attrs;
        return batchMatMulImpl({
            a,
            b,
            transposeA,
            transposeB,
            backend,
            bias,
            preluActivationWeights,
            leakyreluAlpha,
            activation
        });
    }
    const _fusedMatMulConfig = {
        kernelName: tf._FusedMatMul,
        backendName: 'webgpu',
        kernelFunc: _fusedMatMul,
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    class BinaryOpComplexProgram {
        constructor(op, aShape, bShape) {
            this.variableNames = ['AReal', 'AImag', 'BReal', 'BImag'];
            this.workgroupSize = [128, 1, 1];
            this.size = true;
            this.outputShape = tf.backend_util.assertAndGetBroadcastShape(aShape, bShape);
            this.dispatchLayout = flatDispatchLayout(this.outputShape);
            this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
            this.shaderKey = `binaryOpComplex_${op}`;
            this.op = op;
        }
        getUserCode() {
            const opStr = getBinaryOpString(this.op, false);
            const userCode = `
      fn binaryOpComplex(
          areal : f32, aimag : f32, breal : f32, bimag : f32) -> f32 {
        ${opStr}
      }

      ${getMainHeaderString('index')} {
        if(index < uniforms.size) {
          let areal = getARealByOutputIndex(index);
          let aimag = getAImagByOutputIndex(index);
          let breal = getBRealByOutputIndex(index);
          let bimag = getBImagByOutputIndex(index);
          setOutputAtIndex(index, binaryOpComplex(areal, aimag, breal, bimag));
        }
      }
    `;
            return userCode;
        }
    }

    /**
     * @license
     * Copyright 2019 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    class BinaryOpProgram {
        constructor(op, aShape, bShape) {
            this.size = true;
            this.variableNames = ['A', 'B'];
            this.outputShape = tf.backend_util.assertAndGetBroadcastShape(aShape, bShape);
            this.dispatchLayout = flatDispatchLayout(this.outputShape);
            this.op = op;
            this.useSharedMemoryWithA =
                aShape.length <= 1 && bShape.length > 1 && aShape[0] < 128;
            this.useSharedMemoryWithB =
                bShape.length <= 1 && aShape.length > 1 && bShape[0] < 128;
            if (this.useSharedMemoryWithA || this.useSharedMemoryWithB) {
                this.isVec4 = false;
                // lastDimensionSize is used as sharedBuf array size, so can not be
                // used as uniform.
                this.lastDimensionSize =
                    this.useSharedMemoryWithB ? bShape[0] : aShape[0];
                this.shaderKey = `binary_${this.type}_${op}_${this.lastDimensionSize}_${this.useSharedMemoryWithB}`;
                this.type = 'shared';
                // This is an experimental value when using shared memory.
                // Note that the maximum of workgroup X dimension is 256.
                this.workgroupSize = [256, 1, 1];
                this.workPerThread = 1;
            }
            else {
                if (tf.util.arraysEqual(aShape, bShape) &&
                    tf.util.sizeFromShape(aShape) % 4 === 0) {
                    this.isVec4 = true;
                    this.type = 'vec4';
                    this.workPerThread = 4;
                }
                else {
                    this.isVec4 = false;
                    this.type = 'plain';
                    this.workPerThread = 1;
                }
                this.shaderKey = `binary_${this.type}_${op}`;
                // TODO(jiajia.qin@intel.com): Heuristically select a good work group
                // size.
                this.workgroupSize = [128, 1, 1];
            }
            this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize, [this.workPerThread, 1, 1]);
        }
        getUserCode() {
            let userCode;
            const dType = this.isVec4 ? 'vec4<f32>' : 'f32';
            const opFnStr = `
    fn binaryOperation(a : ${dType}, b : ${dType}) -> ${dType} {
      let isNaN = false;
      {
        ${getBinaryOpString(this.op, this.isVec4)}
      }
    };
    `;
            if (this.type === 'shared') {
                const sharedIndexSnippet = this.lastDimensionSize > 1 ?
                    `coords[${this.outputShape.length - 1}]` :
                    '0';
                const accessDataSnippet = this.useSharedMemoryWithB ?
                    `let a = getAByOutputIndex(index);
          let b = sharedBuf[${sharedIndexSnippet}];` :
                    `let a = sharedBuf[${sharedIndexSnippet}];
          let b = getBByOutputIndex(index);`;
                userCode = `
        ${opFnStr}
        var<workgroup> sharedBuf : array<f32, ${this.lastDimensionSize}>;
        ${getMainHeaderString('index')} {
          // Fill in the shared memory buffer.
          let localIndex = i32(localId.x);
          if(localIndex < ${this.lastDimensionSize}) {
            sharedBuf[localIndex] = f32(${this.useSharedMemoryWithB ? 'B' : 'A'}[localIndex]);
          }
          workgroupBarrier();

          if(index < uniforms.size) {
            let coords = getCoordsFromIndex(index);
            ${accessDataSnippet}
            setOutputAtIndex(index, binaryOperation(a, b));
          }
        }
        `;
            }
            else {
                userCode = `
       ${opFnStr}
       ${getMainHeaderString('index')} {
         if (index < uniforms.size) {
           let a = getAByOutputIndex(index);
           let b = getBByOutputIndex(index);
           setOutputAtIndex(index, binaryOperation(a, b));
         }
       }
       `;
            }
            return userCode;
        }
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function identity(args) {
        const { inputs } = args;
        const { x } = inputs;
        args.backend.incRef(x.dataId);
        return { dataId: x.dataId, shape: x.shape, dtype: x.dtype };
    }
    const identityConfig = {
        kernelName: tf.Identity,
        backendName: 'webgpu',
        kernelFunc: identity
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    /**
     * Complex tensors share data with their real and imaginary components. Complex
     * tensors' reference to the components is tracked by refCount on the individual
     * component. The refCounts are increased by the identity call.
     *
     * When a complex tensor is disposed, it will reduce the refCount on the
     * components by calling disposeData on each.
     */
    function complex(args) {
        const { inputs, backend } = args;
        const { real, imag } = inputs;
        const complexInfo = backend.makeTensorInfo(real.shape, 'complex64');
        const complex = backend.tensorMap.get(complexInfo.dataId);
        const realTensorInfo = identity({ inputs: { x: real }, backend });
        const imagTensorInfo = identity({ inputs: { x: imag }, backend });
        complex.complexTensorInfos = { real: realTensorInfo, imag: imagTensorInfo };
        return complexInfo;
    }
    const complexConfig = {
        kernelName: tf.Complex,
        backendName: 'webgpu',
        kernelFunc: complex
    };

    /**
     * @license
     * Copyright 2019 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    class UnaryOpProgram {
        constructor(outputShape, op, uniforms = '') {
            this.variableNames = ['A'];
            this.size = true;
            // TODO(jiajia.qin@intel.com): Heuristically select a good work group size.
            const workgroupSizeX = 128;
            this.workgroupSize = [workgroupSizeX, 1, 1];
            this.outputShape = outputShape;
            this.dispatchLayout = flatDispatchLayout(this.outputShape);
            this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
            this.op = op;
            if (uniforms !== '') {
                this.uniforms = uniforms;
            }
            this.shaderKey = `unary_${op}`;
        }
        getUserCode() {
            return `
      fn unaryOperation(a : f32) -> f32 {
        ${getUnaryOpString(this.op, false)}
      }
      ${getMainHeaderString('index')} {
        if (index < uniforms.size) {
          let a = getAByOutputIndex(index);
          setOutputAtIndex(index, unaryOperation(a));
        }
      }
      `;
        }
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    /**
     * Template that creates a `KernelFunc` for unary ops.
     * @param opType Op type to create `UnaryOpProgram`.
     * @param cpuKernelImpl Optional. Shared functionality from tfjs-backend-cpu, it
     *     will be involved when necessary.
     * @param dtype Optional. If set, the result has this dtype. Otherwise, the
     *     result has the same dtype as the first input. This is mainly used in
     *     comparison kernels, such as Equal, Less, Greater, etc.
     */
    function unaryKernelFunc({ opType, cpuKernelImpl, dtype }) {
        return ({ inputs, backend }) => {
            const { x } = inputs;
            const webgpuBackend = backend;
            const $dtype = dtype || x.dtype;
            if (webgpuBackend.shouldExecuteOnCPU([x]) && cpuKernelImpl != null) {
                const xData = webgpuBackend.tensorMap.get(x.dataId);
                const outValues = cpuKernelImpl(xData.values, $dtype);
                return webgpuBackend.makeTensorInfo(x.shape, $dtype, outValues);
            }
            const program = new UnaryOpProgram(x.shape, opType);
            return webgpuBackend.runWebGPUProgram(program, [x], $dtype);
        };
    }
    /**
     * Template that creates a `KernelFunc` for binary ops.
     * @param opType Op type to create `BinaryOpProgram`.
     * @param cpuKernelImpl Optional. Shared functionality from tfjs-backend-cpu, it
     *     will be involved when necessary.
     * @param dtype Optional. If set, the result has this dtype. Otherwise, the
     *     result has the same dtype as the first input. This is mainly used in
     *     comparison kernels, such as Equal, Less, Greater, etc.
     */
    function binaryKernelFunc({ opType, cpuKernelImpl, supportsComplex = false, dtype }) {
        return ({ inputs, backend }) => {
            const { a, b } = inputs;
            const webgpuBackend = backend;
            if (supportsComplex && a.dtype === 'complex64') {
                const aData = webgpuBackend.tensorMap.get(a.dataId);
                const bData = webgpuBackend.tensorMap.get(b.dataId);
                let real, imag;
                if (opType !== BinaryOpType.MUL) {
                    [real, imag] = [
                        [aData.complexTensorInfos.real, bData.complexTensorInfos.real],
                        [aData.complexTensorInfos.imag, bData.complexTensorInfos.imag]
                    ].map(complexParts => {
                        const [aPart, bPart] = complexParts;
                        const aHandle = {
                            dataId: aPart.dataId,
                            dtype: aPart.dtype,
                            shape: a.shape
                        };
                        const bHandle = {
                            dataId: bPart.dataId,
                            dtype: bPart.dtype,
                            shape: b.shape
                        };
                        const program = new BinaryOpProgram(opType, a.shape, b.shape);
                        return webgpuBackend.runWebGPUProgram(program, [aHandle, bHandle], tf.upcastType(aPart.dtype, bPart.dtype));
                    });
                }
                else {
                    const realProgram = new BinaryOpComplexProgram(BinaryOpType.COMPLEX_MULTIPLY_REAL, a.shape, b.shape);
                    const imagProgram = new BinaryOpComplexProgram(BinaryOpType.COMPLEX_MULTIPLY_IMAG, a.shape, b.shape);
                    const inputs = [
                        {
                            dataId: aData.complexTensorInfos.real.dataId,
                            dtype: aData.complexTensorInfos.real.dtype,
                            shape: a.shape
                        },
                        {
                            dataId: aData.complexTensorInfos.imag.dataId,
                            dtype: aData.complexTensorInfos.imag.dtype,
                            shape: a.shape
                        },
                        {
                            dataId: bData.complexTensorInfos.real.dataId,
                            dtype: bData.complexTensorInfos.real.dtype,
                            shape: b.shape
                        },
                        {
                            dataId: bData.complexTensorInfos.imag.dataId,
                            dtype: bData.complexTensorInfos.imag.dtype,
                            shape: b.shape
                        }
                    ];
                    real = webgpuBackend.runWebGPUProgram(realProgram, inputs, 'float32');
                    imag = webgpuBackend.runWebGPUProgram(imagProgram, inputs, 'float32');
                }
                const complexOutput = complex({ inputs: { real, imag }, backend: webgpuBackend });
                webgpuBackend.disposeData(real.dataId);
                webgpuBackend.disposeData(imag.dataId);
                // TODO: Implement CPU forwarding for complex inputs.
                return complexOutput;
            }
            const $dtype = dtype || tf.upcastType(a.dtype, b.dtype);
            if ((a.dtype === 'string' || b.dtype === 'string' ||
                webgpuBackend.shouldExecuteOnCPU([a, b])) &&
                cpuKernelImpl != null) {
                const aData = webgpuBackend.tensorMap.get(a.dataId).values;
                const bData = webgpuBackend.tensorMap.get(b.dataId).values;
                const decodedAVals = a.dtype === 'string' ?
                    // tslint:disable-next-line: no-any
                    tf.backend_util.fromUint8ToStringArray(aData) :
                    aData;
                const decodedBVals = a.dtype === 'string' ?
                    // tslint:disable-next-line: no-any
                    tf.backend_util.fromUint8ToStringArray(bData) :
                    bData;
                const [outValues, outShape] = cpuKernelImpl(a.shape, b.shape, decodedAVals, decodedBVals, $dtype);
                return webgpuBackend.makeTensorInfo(outShape, $dtype, outValues);
            }
            const program = new BinaryOpProgram(opType, a.shape, b.shape);
            return webgpuBackend.runWebGPUProgram(program, [a, b], $dtype);
        };
    }

    /**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the License);
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an AS IS BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function simpleAbsImpl(vals) {
        const resultValues = new Float32Array(vals.length);
        for (let i = 0; i < vals.length; ++i) {
            resultValues[i] = Math.abs(vals[i]);
        }
        return resultValues;
    }

    /**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    /**
     * Template that creates implementation for binary ops. Supports broadcast.
     */
    function createSimpleBinaryKernelImpl(op) {
        return (aShape, bShape, aVals, bVals, dtype) => {
            const newShape = tf.backend_util.assertAndGetBroadcastShape(aShape, bShape);
            const resultRank = newShape.length;
            const resultStrides = tf.util.computeStrides(newShape);
            const resultSize = tf.util.sizeFromShape(newShape);
            const result = tf.util.getTypedArrayFromDType(dtype, resultSize);
            const aRank = aShape.length;
            const bRank = bShape.length;
            const aStrides = tf.util.computeStrides(aShape);
            const bStrides = tf.util.computeStrides(bShape);
            const aBroadcastDims = tf.backend_util.getBroadcastDims(aShape, newShape);
            const bBroadcastDims = tf.backend_util.getBroadcastDims(bShape, newShape);
            if (aBroadcastDims.length + bBroadcastDims.length === 0) {
                for (let i = 0; i < result.length; ++i) {
                    result[i] = op(aVals[i % aVals.length], bVals[i % bVals.length]);
                }
            }
            else {
                for (let i = 0; i < result.length; ++i) {
                    const loc = tf.util.indexToLoc(i, resultRank, resultStrides);
                    const aLoc = loc.slice(-aRank);
                    aBroadcastDims.forEach(d => aLoc[d] = 0);
                    const aIndex = tf.util.locToIndex(aLoc, aRank, aStrides);
                    const bLoc = loc.slice(-bRank);
                    bBroadcastDims.forEach(d => bLoc[d] = 0);
                    const bIndex = tf.util.locToIndex(bLoc, bRank, bStrides);
                    result[i] = op(aVals[aIndex], bVals[bIndex]);
                }
            }
            return [result, newShape];
        };
    }

    /**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function castImpl(values, shape, inputType, dtype) {
        if (dtype === 'int32') {
            const resultValues = Int32Array.from(values);
            return [shape, 'int32', resultValues];
        }
        if (dtype === 'bool') {
            // This is essentially the result of notEqual(x, 0). We avoid using
            // kernel notEqual to avoid circular dependency, i.e. binary_utils ->
            // cast -> notEqual -> binary_utils.
            const zero = tf.util.toTypedArray([0], inputType);
            const [resultData, resultShape] = createSimpleBinaryKernelImpl((a, b) => (a !== b) ? 1 : 0)(shape, [], values, zero, 'bool');
            return [resultShape, 'bool', resultData];
        }
        throw new Error(`Error in Cast: failed to cast ${inputType} to ${dtype}`);
    }

    /**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const addImpl = createSimpleBinaryKernelImpl(((a, b) => a + b));

    /**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function bincountImpl(xVals, weightsVals, weightsDtype, weightsShape, size) {
        const weightsSize = tf.util.sizeFromShape(weightsShape);
        const outVals = tf.util.makeZerosTypedArray(size, weightsDtype);
        for (let i = 0; i < xVals.length; i++) {
            const value = xVals[i];
            if (value < 0) {
                throw new Error('Input x must be non-negative!');
            }
            if (value >= size) {
                continue;
            }
            if (weightsSize > 0) {
                outVals[value] += weightsVals[i];
            }
            else {
                outVals[value] += 1;
            }
        }
        return outVals;
    }
    function bincountReduceImpl(xBuf, weightsBuf, size, binaryOutput = false) {
        const numRows = xBuf.shape[0];
        const numCols = xBuf.shape[1];
        const outBuf = tf.buffer([numRows, size], weightsBuf.dtype);
        for (let i = 0; i < numRows; i++) {
            for (let j = 0; j < numCols; j++) {
                const value = xBuf.get(i, j);
                if (value < 0) {
                    throw new Error('Input x must be non-negative!');
                }
                if (value >= size) {
                    continue;
                }
                if (binaryOutput) {
                    outBuf.set(1, i, value);
                }
                else {
                    if (weightsBuf.size > 0) {
                        outBuf.set(outBuf.get(i, value) + weightsBuf.get(i, j), i, value);
                    }
                    else {
                        outBuf.set(outBuf.get(i, value) + 1, i, value);
                    }
                }
            }
        }
        return outBuf;
    }

    /**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    /**
     * Template that creates implementation for unary op.
     */
    function createSimpleUnaryImpl(op) {
        return (values, dtype, attrs) => {
            const newValues = tf.util.getTypedArrayFromDType(dtype, values.length);
            for (let i = 0; i < values.length; ++i) {
                newValues[i] = op(values[i], attrs);
            }
            return newValues;
        };
    }

    /**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the License);
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an AS IS BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const ceilImpl = createSimpleUnaryImpl((xi) => Math.ceil(xi));

    /**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function concatImpl(inputs, outShape, dtype, simplyConcat) {
        const outVals = tf.util.getArrayFromDType(dtype, tf.util.sizeFromShape(outShape));
        if (simplyConcat && dtype !== 'string') {
            // Use built-in TypedArray.set() method for speed.
            let offset = 0;
            inputs.forEach(input => {
                const size = tf.util.sizeFromShape(input.shape);
                outVals.set(input.vals, offset);
                offset += size;
            });
        }
        else {
            let colOffset = 0;
            inputs.forEach(input => {
                const decodedData = dtype === 'string' ?
                    tf.backend_util.fromUint8ToStringArray(input.vals) :
                    input.vals;
                let tIdx = 0;
                for (let row = 0; row < input.shape[0]; ++row) {
                    const resIdx = row * outShape[1] + colOffset;
                    for (let col = 0; col < input.shape[1]; ++col) {
                        outVals[resIdx + col] = decodedData[tIdx++];
                    }
                }
                colOffset += input.shape[1];
            });
        }
        return outVals;
    }

    /**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const equalImpl = createSimpleBinaryKernelImpl((a, b) => (a === b) ? 1 : 0);

    /**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the License);
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an AS IS BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const expImpl = createSimpleUnaryImpl((xi) => Math.exp(xi));

    /**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the License);
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an AS IS BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const expm1Impl = createSimpleUnaryImpl((xi) => Math.expm1(xi));

    /**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the License);
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an AS IS BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const floorImpl = createSimpleUnaryImpl((xi) => Math.floor(xi));

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function gatherNdImpl(indicesData, paramsBuf, dtype, numSlices, sliceRank, sliceSize, strides, paramsShape, paramsSize) {
        const outBuf = tf.buffer([numSlices, sliceSize], dtype);
        for (let i = 0; i < numSlices; i++) {
            const index = [];
            let flattenIndex = 0;
            for (let j = 0; j < sliceRank; j++) {
                const dim = indicesData[i * sliceRank + j];
                flattenIndex += dim * strides[j];
                index.push(dim);
            }
            if (flattenIndex < 0 || flattenIndex >= paramsSize / sliceSize) {
                throw new Error(`Invalid indices: ${index} does not index into ${paramsShape}`);
            }
            for (let k = 0; k < sliceSize; k++) {
                outBuf.values[i * sliceSize + k] =
                    paramsBuf.get(...paramsBuf.indexToLoc(flattenIndex * sliceSize + k));
            }
        }
        return outBuf;
    }

    /**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function gatherV2Impl(xBuf, indicesBuf, flattenOutputShape) {
        const outBuf = tf.buffer(flattenOutputShape, xBuf.dtype);
        for (let i = 0; i < outBuf.size; ++i) {
            const newLoc = outBuf.indexToLoc(i);
            const originalLoc = newLoc.slice();
            const batchIdx = originalLoc[0];
            const indicesIdx = originalLoc[2];
            const indicesIndex = indicesBuf.locToIndex([batchIdx, indicesIdx]);
            originalLoc[2] = indicesBuf.values[indicesIndex];
            const originalIndex = xBuf.locToIndex(originalLoc);
            if (0 <= originalIndex && originalIndex < xBuf.values.length) {
                outBuf.values[i] = xBuf.values[originalIndex];
            } // Else, index is out of bounds, so leave the default zero val in outBuf.
        }
        return outBuf;
    }

    /**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const greaterImpl = createSimpleBinaryKernelImpl((a, b) => (a > b) ? 1 : 0);

    /**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const greaterEqualImpl = createSimpleBinaryKernelImpl((a, b) => (a >= b) ? 1 : 0);

    /**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const lessImpl = createSimpleBinaryKernelImpl((a, b) => (a < b) ? 1 : 0);

    /**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const lessEqualImpl = createSimpleBinaryKernelImpl((a, b) => (a <= b) ? 1 : 0);

    /**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function linSpaceImpl(start, stop, num) {
        const step = (stop - start) / (num - 1);
        const values = tf.util.makeZerosTypedArray(num, 'float32');
        values[0] = start;
        for (let i = 1; i < values.length; i++) {
            values[i] = values[i - 1] + step;
        }
        return values;
    }

    /**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the License);
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an AS IS BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const logImpl = createSimpleUnaryImpl((xi) => Math.log(xi));

    /**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function maxImpl(aVals, reduceSize, outShape, dtype) {
        const vals = tf.util.getTypedArrayFromDType(dtype, tf.util.sizeFromShape(outShape));
        for (let i = 0; i < vals.length; ++i) {
            const offset = i * reduceSize;
            let max = aVals[offset];
            for (let j = 0; j < reduceSize; ++j) {
                const value = aVals[offset + j];
                if (Number.isNaN(value) ||
                    value > max) { // comparison with NaN always return false
                    max = value;
                }
            }
            vals[i] = max;
        }
        return vals;
    }

    /**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const maximumImpl = createSimpleBinaryKernelImpl(((aValue, bValue) => Math.max(aValue, bValue)));

    /**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const minimumImpl = createSimpleBinaryKernelImpl(((aValue, bValue) => Math.min(aValue, bValue)));

    /**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const multiplyImpl = createSimpleBinaryKernelImpl(((aValue, bValue) => aValue * bValue));

    /**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function negImpl(xVals, xShape, xDtype) {
        const minusOne = tf.util.createScalarValue(-1, xDtype);
        return multiplyImpl([], xShape, minusOne, xVals, xDtype);
    }

    /**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const notEqualImpl = createSimpleBinaryKernelImpl(((a, b) => (a !== b) ? 1 : 0));

    /**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function transposeImpl(xVals, xShape, dtype, perm, newShape) {
        const xRank = xShape.length;
        const xSize = tf.util.sizeFromShape(xShape);
        const xStrides = tf.util.computeStrides(xShape);
        const newStrides = tf.util.computeStrides(newShape);
        const result = tf.util.getTypedArrayFromDType(dtype, tf.util.sizeFromShape(newShape));
        for (let i = 0; i < xSize; ++i) {
            const loc = tf.util.indexToLoc(i, xRank, xStrides);
            // Permute location.
            const newLoc = new Array(loc.length);
            for (let i = 0; i < newLoc.length; i++) {
                newLoc[i] = loc[perm[i]];
            }
            const newIndex = tf.util.locToIndex(newLoc, xRank, newStrides);
            result[newIndex] = xVals[i];
        }
        return result;
    }

    /**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function prodImpl(xShape, xDtype, xVals, reductionAxes) {
        const [outShape, reduceShape] = tf.backend_util.computeOutAndReduceShapes(xShape, reductionAxes);
        const outDtype = tf.upcastType(xDtype, 'int32');
        const outVals = tf.util.makeZerosTypedArray(tf.util.sizeFromShape(outShape), outDtype);
        const reduceSize = tf.util.sizeFromShape(reduceShape);
        for (let i = 0; i < outVals.length; ++i) {
            const offset = i * reduceSize;
            let prod = 1;
            for (let j = 0; j < reduceSize; ++j) {
                prod *= xVals[offset + j];
            }
            outVals[i] = prod;
        }
        return { outVals, outShape, outDtype };
    }

    /**
     * @license
     * Copyright 2022 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function validateIndices(indices, indicesShape, numParams) {
        indices.forEach((index, i) => {
            if (index < 0 || index >= numParams) {
                const locString = tf.util.indexToLoc(i, indicesShape.length, tf.util.computeStrides(indicesShape))
                    .join(',');
                throw new Error(`indices[${locString}] = ${index} is not in [0, ${numParams})`);
            }
        });
    }
    function validateSplits(paramsNestedSplits, numParamsDenseValues) {
        // Validate
        for (let dim = 0; dim < paramsNestedSplits.length; ++dim) {
            const splits = paramsNestedSplits[dim];
            const lastSplit = (dim === paramsNestedSplits.length - 1) ?
                numParamsDenseValues :
                paramsNestedSplits[dim + 1].length;
            if (splits.length === 0) {
                throw new Error('Ragged splits may not be empty');
            }
            if (splits[0] < 0) {
                throw new Error('Ragged splits must be non-negative');
            }
            if (splits[splits.length - 1] > lastSplit) {
                throw new Error('Ragged splits must not point past values');
            }
            for (let i = 1; i < splits.length; ++i) {
                if (splits[i - 1] > splits[i]) {
                    throw new Error('Ragged splits must be sorted in ascending order');
                }
            }
        }
    }
    // Construct the `splits` output tensors, encoded using a nested vector.
    // Also find the slices of values that need to be copied, and store them
    // in `valueSlices`.  The total number of values that will be copied (which
    // we need for allocating the output values tensor) is stored in `numValues`.
    function makeSplits(indices, indicesShape, paramsNestedSplits, numParamsDenseValues) {
        const valueSlices = [];
        let numValues = 0;
        const numSplits = indicesShape.length - 1 + paramsNestedSplits.length;
        const outSplits = new Array(numSplits).fill(null).map(() => [0]);
        validateSplits(paramsNestedSplits, numParamsDenseValues);
        // Add `splits` that come from all but the last dimension of the dense
        // Tensor `indices`.  In particular, for each dimension D, we add a
        // splits tensor whose values are:
        //   range(reduceProd(splits.shape[:D]) + 1) * splits.shape[D+1]
        // E.g., if indices.shape=[2, 3, 4] then we will add splits tensors:
        //   [0, 3, 6]                    # length=2+1, stride=3
        //   [0, 4, 8, 12, 16, 20, 24]    # length=2*3+1, stride=4
        let nrows = 1;
        for (let dim = 0; dim < indicesShape.length - 1; ++dim) {
            nrows *= indicesShape[dim];
            const rowLength = indicesShape[dim + 1];
            for (let i = 1; i < nrows + 1; ++i) {
                outSplits[dim].push(i * rowLength);
            }
        }
        // Add `splits` that come from `paramsNestedSplits`.  Starting with the
        // outermost ragged dimension (i.e., the first `splits` tensor), we work
        // our way in, finding the range of values that should be copied.  As we
        // go, we update the output `splits` for each dimension with the appropriate
        // values.  In particular, the *lengths* of the slices from `param_splits`
        // should be copied to generate corresponding slice lengths in the output
        // splits.  E.g., if we are copying a ragged row with length 4, then we
        // should add a new split point to outSplits that is 4 greater than the
        // previous split point in outSplits.
        for (let i = 0; i < indices.length; ++i) {
            let start = indices[i];
            let limit = indices[i] + 1;
            // Copy splits.
            for (let dim = 0; dim < paramsNestedSplits.length; ++dim) {
                const splits = paramsNestedSplits[dim];
                const outDim = dim + indicesShape.length - 1;
                if (outDim >= 0) {
                    const outSplitsOutDim = outSplits[outDim];
                    const delta = outSplitsOutDim[outSplitsOutDim.length - 1] - splits[start];
                    for (let j = start; j < limit; ++j) {
                        outSplits[outDim].push(splits[j + 1] + delta);
                    }
                }
                start = splits[start];
                limit = splits[limit];
            }
            if (limit !== start) {
                valueSlices.push([start, limit]);
                numValues += limit - start;
            }
        }
        return { outSplits, valueSlices, numValues };
    }
    function getSplits(outSplits) {
        const splitsOut = [];
        for (let i = 0; i < outSplits.length; ++i) {
            const numSplits = outSplits[i].length;
            const splits = tf.util.getArrayFromDType('int32', numSplits);
            splitsOut.push(splits);
            outSplits[i].forEach((value, j) => splits[j] = value);
        }
        return splitsOut;
    }
    function computeFlatOuterDims(orig, numOutDims) {
        const outDims = orig.slice(0, numOutDims);
        while (outDims.length < numOutDims) {
            outDims.push(1);
        }
        for (let inDim = numOutDims; inDim < orig.length; inDim++) {
            outDims[numOutDims - 1] *= orig[inDim];
        }
        return outDims;
    }
    // For each slice in `(start, limit)` in `valueSlices`, append
    // `paramsDenseValues[start,...,limit] to `values`.  `valueSize` indicates
    // the number of scalars contained in each value paramsDenseValues[i].
    function writeValueSlices(paramsDenseValues, paramsDenseValuesShape, valueSlices, valueSize, values, valuesShape) {
        const denseM = computeFlatOuterDims(paramsDenseValuesShape, 2)[1];
        const valuesM = computeFlatOuterDims(valuesShape, 2)[1];
        let outPos = 0;
        for (const slice of valueSlices) {
            for (let i = slice[0]; i < slice[1]; ++i) {
                for (let j = 0; j < valueSize; ++j) {
                    values[outPos * valuesM + j] = paramsDenseValues[i * denseM + j];
                }
                ++outPos;
            }
        }
    }
    function getValues(paramsDenseValues, paramsDenseValuesShape, paramsDenseValuesDType, valueSlices, numValues) {
        const valuesShape = paramsDenseValuesShape.slice();
        valuesShape[0] = numValues;
        const valuesOut = tf.util.getArrayFromDType(paramsDenseValuesDType, tf.util.sizeFromShape(valuesShape));
        const numElements = paramsDenseValues.length;
        const valueSize = numElements === 0 ? 0 : (numElements / paramsDenseValuesShape[0]);
        writeValueSlices(paramsDenseValues, paramsDenseValuesShape, valueSlices, valueSize, valuesOut, valuesShape);
        return [valuesOut, valuesShape];
    }
    function raggedGatherImpl(paramsNestedSplits, paramsNestedSplitsShapes, paramsDenseValues, paramsDenseValuesShape, paramsDenseValuesDType, indices, indicesShape, outputRaggedRank) {
        if (paramsNestedSplits.length === 0) {
            throw new Error('paramsNestedSplits must be non empty');
        }
        if (paramsNestedSplitsShapes[0].length === 0) {
            throw new Error('Split tensors must not be scalars');
        }
        const numParams = paramsNestedSplitsShapes[0][0] - 1;
        validateIndices(indices, indicesShape, numParams);
        if (paramsDenseValuesShape.length === 0) {
            throw new Error('params.rank must be nonzero');
        }
        const numParamsDenseValues = paramsDenseValuesShape[0];
        // Calculate the `splits`, and store the value slices that we need to
        // copy in `valueSlices`.
        const { outSplits, valueSlices, numValues } = makeSplits(indices, indicesShape, paramsNestedSplits, numParamsDenseValues);
        // Write the output tensors.
        const outputNestedSplits = getSplits(outSplits);
        const outputDenseValues = getValues(paramsDenseValues, paramsDenseValuesShape, paramsDenseValuesDType, valueSlices, numValues);
        return [outputNestedSplits, outputDenseValues[0], outputDenseValues[1]];
    }

    /**
     * @license
     * Copyright 2022 Google LLC.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const INT32_MAX = 2147483647;
    function raggedRangeImpl(starts, startsShape, startsDType, limits, limitsShape, deltas, deltasShape) {
        // Check input tensor shapes.
        if (startsShape.length > 1) {
            throw new Error('starts must be a scalar or vector');
        }
        if (limitsShape.length > 1) {
            throw new Error('limits must be a scalar or vector');
        }
        if (deltasShape.length > 1) {
            throw new Error('deltas must be a scalar or vector');
        }
        // Determine which tensors we need to broadcast.
        const broadcastStarts = startsShape.length === 0;
        const broadcastLimits = limitsShape.length === 0;
        const broadcastDeltas = deltasShape.length === 0;
        // nRows (number of output rows) is the size of the non-broadcast inputs,
        // or 1 if all inputs are scalars.
        const inSizes = [];
        if (!broadcastStarts) {
            inSizes.push(startsShape[0]);
        }
        if (!broadcastLimits) {
            inSizes.push(limitsShape[0]);
        }
        if (!broadcastDeltas) {
            inSizes.push(deltasShape[0]);
        }
        for (let i = 1; i < inSizes.length; ++i) {
            if (inSizes[i] !== inSizes[i - 1]) {
                throw new Error('starts, limits, and deltas must have the same shape');
            }
        }
        const nRows = inSizes.length === 0 ? 1 : inSizes[0];
        // Construct the rtNestedSplits tensor.
        const rtNestedSplits = tf.util.getArrayFromDType('int32', nRows + 1);
        rtNestedSplits[0] = 0;
        for (let row = 0; row < nRows; ++row) {
            const start = broadcastStarts ? starts[0] : starts[row];
            const limit = broadcastLimits ? limits[0] : limits[row];
            const delta = broadcastDeltas ? deltas[0] : deltas[row];
            if (delta === 0) {
                throw new Error('Requires delta != 0');
            }
            let size; // The number of elements in the specified range.
            if (((delta > 0) && (limit < start)) || ((delta < 0) && (limit > start))) {
                size = 0;
            }
            else {
                size = Math.ceil(Math.abs((limit - start) / delta));
                if (size > INT32_MAX) {
                    throw new Error(`Requires ((limit - start) / delta) <= ${INT32_MAX}`);
                }
            }
            rtNestedSplits[row + 1] = rtNestedSplits[row] + size;
        }
        const nVals = rtNestedSplits[nRows];
        // Construct the rtDenseValues tensor.
        const rtDenseValues = tf.util.getArrayFromDType(startsDType, nVals);
        let valueIndex = 0;
        for (let row = 0; row < nRows; ++row) {
            const rowSize = rtNestedSplits[row + 1] - rtNestedSplits[row];
            let value = broadcastStarts ? starts[0] : starts[row];
            const delta = broadcastDeltas ? deltas[0] : deltas[row];
            for (let i = 0; i < rowSize; ++i) {
                rtDenseValues[valueIndex++] = value;
                value += delta;
            }
        }
        return [rtNestedSplits, rtDenseValues];
    }

    /**
     * @license
     * Copyright 2022 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    var RowPartitionType = tf.backend_util.RowPartitionType;
    // Based on
    // https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/ragged_tensor_to_tensor_op.cc
    class RaggedTensorToTensorOp {
        constructor(shape, shapeShape, values, valuesShape, valuesDType, defaultValue, defaultValueShape, rowPartitionValues, rowPartitionValuesShapes, rowPartitionTypeStrings) {
            this.shape = shape;
            this.shapeShape = shapeShape;
            this.values = values;
            this.valuesShape = valuesShape;
            this.valuesDType = valuesDType;
            this.defaultValue = defaultValue;
            this.defaultValueShape = defaultValueShape;
            this.rowPartitionValues = rowPartitionValues;
            this.rowPartitionValuesShapes = rowPartitionValuesShapes;
            this.rowPartitionTypes =
                tf.backend_util.getRowPartitionTypesHelper(rowPartitionTypeStrings);
            this.raggedRank = tf.backend_util.getRaggedRank(this.rowPartitionTypes);
        }
        getRowPartitionTypeByDimension(dimension) {
            if (this.rowPartitionTypes[0] === RowPartitionType.FIRST_DIM_SIZE) {
                return this.rowPartitionTypes[dimension + 1];
            }
            else {
                return this.rowPartitionTypes[dimension];
            }
        }
        // Returns the relationship between dimension and dimension + 1.
        getRowPartitionTensor(dimension) {
            if (this.rowPartitionTypes[0] === RowPartitionType.FIRST_DIM_SIZE) {
                return this.rowPartitionValues[dimension + 1];
            }
            else {
                return this.rowPartitionValues[dimension];
            }
        }
        getMaxWidth(dimension) {
            const rowPartitionTensor = this.getRowPartitionTensor(dimension - 1);
            switch (this.getRowPartitionTypeByDimension(dimension - 1)) {
                case RowPartitionType.VALUE_ROWIDS:
                    return RaggedTensorToTensorOp.getMaxWidthValueRowID(rowPartitionTensor);
                case RowPartitionType.ROW_SPLITS:
                    return RaggedTensorToTensorOp.getMaxWidthRowSplit(rowPartitionTensor);
                default:
                    throw new Error(`Cannot handle partition type ${RowPartitionType[this.getRowPartitionTypeByDimension(dimension - 1)]}`);
            }
        }
        static getMaxWidthRowSplit(rowSplit) {
            const tensorLength = rowSplit.length;
            if (tensorLength === 0 || tensorLength === 1) {
                return 0;
            }
            let maxWidth = 0;
            for (let i = 0; i < tensorLength - 1; ++i) {
                const currentWidth = rowSplit[i + 1] - rowSplit[i];
                if (currentWidth > maxWidth) {
                    maxWidth = currentWidth;
                }
            }
            return maxWidth;
        }
        static getMaxWidthValueRowID(valueRowIds) {
            const indexLength = valueRowIds.length;
            if (indexLength === 0) {
                return 0;
            }
            let firstEqualIndex = 0;
            let firstEqualIndexValue = valueRowIds[0];
            let maxWidth = 0;
            for (let i = 1; i < indexLength; ++i) {
                const value = valueRowIds[i];
                if (value !== firstEqualIndexValue) {
                    firstEqualIndexValue = value;
                    maxWidth = Math.max(i - firstEqualIndex, maxWidth);
                    firstEqualIndex = i;
                }
            }
            return Math.max(indexLength - firstEqualIndex, maxWidth);
        }
        tensorShapeFromTensor(t, tShape, isPartial = true) {
            if (tShape.length === 0) {
                if (t[0] === -1) {
                    return [];
                }
                throw new Error(`The only valid scalar shape tensor is the fully unknown shape specified as -1.`);
            }
            // MakePartialShape/MakeShapeHelper.
            return makeShape(t, isPartial);
        }
        calculateOutputSize(firstDim) {
            const valueShape = this.valuesShape;
            const defaultValueShape = this.defaultValueShape;
            tf.backend_util.validateDefaultValueShape(defaultValueShape, valueShape);
            const shape = this.tensorShapeFromTensor(this.shape, this.shapeShape);
            const outputShape = tf.backend_util.combineRaggedTensorToTensorShapes(this.raggedRank, shape, valueShape);
            const result = outputShape;
            if (result[0] < 0) {
                result[0] = firstDim;
            }
            for (let i = 1; i <= this.raggedRank; ++i) {
                if (result[i] < 0) {
                    result[i] = this.getMaxWidth(i);
                }
            }
            return result;
        }
        /**
         * The outputIndex represents the index in the output tensor
         * where the first element of a particular dimension would be written.
         * If it is -1, it indicates that the index is out of scope.
         * Example, given firstDimension = 10, firstDimensionOutput = 6,
         * and outputIndexMultiplier = 100:
         * result = [0 100 200 300 400 500 -1 -1 -1 -1]
         * If firstDimensionOutput = 11 instead, then:
         * result = [0 100 200 300 400 500 600 700 800 900]
         */
        calculateFirstParentOutputIndex(firstDimension, outputIndexMultiplier, firstDimensionOutput) {
            const minDimension = Math.min(firstDimension, firstDimensionOutput);
            const result = [];
            let currentOutputIndex = 0;
            for (let i = 0; i < minDimension; ++i, currentOutputIndex += outputIndexMultiplier) {
                result.push(currentOutputIndex);
            }
            for (let i = minDimension; i < firstDimension; ++i) {
                result.push(-1);
            }
            tf.util.assert(result.length === firstDimension, () => 'Final length of result must be equal to firstDimension.');
            return result;
        }
        calculateOutputIndexRowSplit(rowSplit, parentOutputIndex, outputIndexMultiplier, outputSize) {
            const rowSplitSize = rowSplit.length;
            const result = [];
            for (let i = 0; i < rowSplitSize - 1; ++i) {
                const rowLength = rowSplit[i + 1] - rowSplit[i];
                let realLength = Math.min(outputSize, rowLength);
                let parentOutputIndexCurrent = parentOutputIndex[i];
                if (parentOutputIndexCurrent === -1) {
                    realLength = 0;
                }
                for (let j = 0; j < realLength; ++j) {
                    result.push(parentOutputIndexCurrent);
                    parentOutputIndexCurrent += outputIndexMultiplier;
                }
                for (let j = 0; j < rowLength - realLength; ++j) {
                    result.push(-1);
                }
            }
            if (rowSplitSize > 0 && result.length !== rowSplit[rowSplitSize - 1]) {
                throw new Error('Invalid row split size.');
            }
            return result;
        }
        // Calculate the output index of the first element of a list.
        // The parentOutputIndex is the same computation for the previous list.
        // -1 indicates an element or list that is out of range.
        // The outputIndexMultiplier is the number of output indices one moves
        // forward for each column.
        // E.g., given:
        // valueRowIds:[0 1 2 2 2 3 5 5 6]
        // parentOutputIndex:[1000 1100 2000 2100 -1 3000 4000]
        // outputIndexMultiplier: 10
        // outputSize: 2
        // You get:
        // result = [1000 1100 2000 2010 -1 2100 -1 -1 3000]
        // result[0] = parentOutputIndex[valueRowIds[0]]
        // result[1] = parentOutputIndex[valueRowIds[1]]
        // result[2] = parentOutputIndex[valueRowIds[2]]
        // result[3] = parentOutputIndex[valueRowIds[2] + 10]
        // result[4] = -1 because it is the third element the size is 2.
        // result[5] = parentOutputIndex[valueRowIds[3]]
        // result[6] = -1 because parentOutputIndex[valueRowIds[6]] == -1
        // result[7] = -1 because parentOutputIndex[valueRowIds[6]] == -1
        // result[8] = parentOutputIndex[valueRowIds[7]]
        calculateOutputIndexValueRowID(valueRowIds, parentOutputIndex, outputIndexMultiplier, outputSize) {
            const indexSize = valueRowIds.length;
            const result = [];
            if (indexSize === 0) {
                return [];
            }
            let currentOutputColumn = 0;
            let currentValueRowId = valueRowIds[0];
            if (currentValueRowId >= parentOutputIndex.length) {
                throw new Error(`Got currentValueRowId=${currentValueRowId}, which is not less than ${parentOutputIndex.length}`);
            }
            let currentOutputIndex = parentOutputIndex[currentValueRowId];
            result.push(currentOutputIndex);
            for (let i = 1; i < indexSize; ++i) {
                const nextValueRowId = valueRowIds[i];
                if (nextValueRowId === currentValueRowId) {
                    if (currentOutputIndex >= 0) {
                        ++currentOutputColumn;
                        if (currentOutputColumn < outputSize) {
                            currentOutputIndex += outputIndexMultiplier;
                        }
                        else {
                            currentOutputIndex = -1;
                        }
                    }
                }
                else {
                    currentOutputColumn = 0;
                    currentValueRowId = nextValueRowId;
                    if (nextValueRowId >= parentOutputIndex.length) {
                        throw new Error(`Got nextValueRowId=${nextValueRowId} which is not less than ${parentOutputIndex.length}`);
                    }
                    currentOutputIndex = parentOutputIndex[nextValueRowId];
                }
                result.push(currentOutputIndex);
            }
            if (result.length !== valueRowIds.length) {
                throw new Error('Invalid row ids.');
            }
            return result;
        }
        calculateOutputIndex(dimension, parentOutputIndex, outputIndexMultiplier, outputSize) {
            const rowPartitionTensor = this.getRowPartitionTensor(dimension);
            const partitionType = this.getRowPartitionTypeByDimension(dimension);
            switch (partitionType) {
                case RowPartitionType.VALUE_ROWIDS:
                    return this.calculateOutputIndexValueRowID(rowPartitionTensor, parentOutputIndex, outputIndexMultiplier, outputSize);
                case RowPartitionType.ROW_SPLITS:
                    if (rowPartitionTensor.length - 1 > parentOutputIndex.length) {
                        throw new Error(`Row partition size is greater than output size: ${rowPartitionTensor.length - 1} > ${parentOutputIndex.length}`);
                    }
                    return this.calculateOutputIndexRowSplit(rowPartitionTensor, parentOutputIndex, outputIndexMultiplier, outputSize);
                default:
                    throw new Error(`Unsupported partition type: ${RowPartitionType[partitionType]}`);
            }
        }
        getFirstDimensionSize() {
            const firstPartitionTensor = this.rowPartitionValues[0];
            if (this.rowPartitionTypes.length === 0) {
                throw new Error('No row_partition_types given.');
            }
            const firstPartitionType = this.rowPartitionTypes[0];
            switch (firstPartitionType) {
                case RowPartitionType.FIRST_DIM_SIZE:
                    return firstPartitionTensor[0];
                case RowPartitionType.VALUE_ROWIDS:
                    throw new Error('Cannot handle VALUE_ROWIDS in first dimension.');
                case RowPartitionType.ROW_SPLITS:
                    return this.rowPartitionValuesShapes[0][0] - 1;
                default:
                    throw new Error(`Cannot handle type ${RowPartitionType[firstPartitionType]}`);
            }
        }
        compute() {
            const firstPartitionTensor = this.rowPartitionValues[0];
            if (firstPartitionTensor.length <= 0) {
                throw new Error('Invalid first partition input. ' +
                    'Tensor requires at least one element.');
            }
            const firstDimension = this.getFirstDimensionSize();
            const outputSize = this.calculateOutputSize(firstDimension);
            const multiplier = new Array(this.raggedRank + 1);
            multiplier[multiplier.length - 1] = 1;
            for (let i = multiplier.length - 2; i >= 0; --i) {
                multiplier[i] = multiplier[i + 1] * outputSize[i + 1];
            }
            // Full size of the tensor.
            const outputShape = makeShape(outputSize, false);
            const outputTensor = tf.util.getArrayFromDType(this.valuesDType, tf.util.sizeFromShape(outputShape));
            const fullSize = multiplier[0] * outputSize[0];
            if (fullSize > 0) {
                let outputIndex = this.calculateFirstParentOutputIndex(firstDimension, multiplier[0], outputSize[0]);
                for (let i = 1; i <= this.raggedRank; ++i) {
                    const newOutputIndex = this.calculateOutputIndex(i - 1, outputIndex, multiplier[i], outputSize[i]);
                    outputIndex = newOutputIndex;
                }
                this.setOutput(this.raggedRank, outputIndex, outputTensor, outputShape);
            }
            return [outputShape, outputTensor];
        }
        setOutput(raggedRank, outputIndex, outputTensor, outputShape) {
            if (outputTensor.length === 0) {
                return;
            }
            const valuesBase = this.values;
            const outputBase = outputTensor;
            let elementShape = outputShape.slice();
            elementShape = elementShape.slice(raggedRank + 1);
            const valueElementSize = tf.util.sizeFromShape(elementShape);
            const outputIndexSize = outputIndex.length;
            // Broadcast the default value to value_element_size.  (We can skip this
            // if defaultValueTensor.size == 1, since we use fill when that's true.)
            let defaultValue = this.defaultValue;
            if (defaultValue.length !== valueElementSize && defaultValue.length !== 1) {
                const srcShape = this.defaultValueShape;
                tf.tidy(() => {
                    const defaultValueTensor = tf.reshape(defaultValue, srcShape);
                    const bCastDefault = tf.broadcastTo(defaultValueTensor, elementShape);
                    defaultValue = bCastDefault.dataSync();
                });
            }
            // Loop through the outputIndex array, finding contiguous regions that
            // should be copied.  Once we find the end of a contiguous region, copy it
            // and add any necessary padding (with defaultValue).
            let srcStart = 0; // Start of contiguous region (in values)
            let dstStart = 0; // Destination for contiguous region (in output)
            let dstEnd = 0; // Destination for contiguous region (in output)
            for (let srcI = 0; srcI <= outputIndexSize; ++srcI) {
                // dstI is the destination where the value at srcI should be copied.
                let dstI = srcI < outputIndexSize ? outputIndex[srcI] : -1;
                // If we're still in a contiguous region, then update dstEnd go to the
                // next srcI.
                if (dstI === dstEnd) {
                    ++dstEnd;
                    continue;
                }
                // We found the end of contiguous region.  This can be because we found
                // a gap (dstI > dstEnd), or a source value that shouldn't be copied
                // because it's out-of-bounds (dstI == -1), or the end of the tensor
                // (dstI === -1).
                if (dstStart < dstEnd) {
                    // Copy the contiguous region.
                    const src = valuesBase.subarray(srcStart * valueElementSize);
                    const dst = outputBase.subarray(dstStart * valueElementSize);
                    const nVals = (dstEnd - dstStart) * valueElementSize;
                    copyArray(dst, src, nVals);
                }
                // Add any necessary padding (w/ defaultValue).
                if (srcI >= outputIndexSize) {
                    // We reached the end of values: pad to the end of output.
                    const outputSize = outputTensor.length;
                    dstI = Math.floor(outputSize / valueElementSize);
                }
                if (dstI > dstEnd) {
                    if (this.defaultValue.length === 1) {
                        outputBase
                            .subarray(dstEnd * valueElementSize, dstI * valueElementSize)
                            .fill(this.defaultValue[0]);
                        dstEnd = dstI;
                    }
                    else {
                        while (dstI > dstEnd) {
                            const dst = outputBase.slice(dstEnd * valueElementSize);
                            copyArray(dst, defaultValue, valueElementSize);
                            ++dstEnd;
                        }
                    }
                }
                // Update indices.
                if (dstI < 0) {
                    // srcI should be skipped -- leave it out of the contiguous region.
                    srcStart = srcI + 1;
                    dstStart = dstEnd;
                }
                else {
                    // srcI should be copied -- include it in the contiguous region.
                    srcStart = srcI;
                    dstStart = dstEnd;
                    dstEnd = dstStart + 1;
                }
            }
        }
    }
    function copyArray(dst, src, size) {
        for (let i = 0; i < size; i++) {
            dst[i] = src[i];
        }
    }
    function makeShape(shape, isPartial) {
        const out = [];
        for (let dim of shape) {
            if (dim < 0) {
                if (!isPartial) {
                    throw new Error(`Dimension ${dim} must be >= 0`);
                }
                if (dim < -1) {
                    throw new Error(`Dimension ${dim} must be >= -1`);
                }
                dim = -1;
            }
            out.push(dim);
        }
        return out;
    }
    function raggedTensorToTensorImpl(shape, shapesShape, values, valuesShape, valuesDType, defaultValue, defaultValueShape, rowPartitionValues, rowPartitionValuesShapes, rowPartitionTypes) {
        return new RaggedTensorToTensorOp(shape, shapesShape, values, valuesShape, valuesDType, defaultValue, defaultValueShape, rowPartitionValues, rowPartitionValuesShapes, rowPartitionTypes)
            .compute();
    }

    /**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function rangeImpl(start, stop, step, dtype) {
        const sameStartStop = start === stop;
        const increasingRangeNegativeStep = start < stop && step < 0;
        const decreasingRangePositiveStep = stop < start && step > 1;
        if (sameStartStop || increasingRangeNegativeStep ||
            decreasingRangePositiveStep) {
            return tf.util.makeZerosTypedArray(0, dtype);
        }
        const numElements = Math.abs(Math.ceil((stop - start) / step));
        const values = tf.util.makeZerosTypedArray(numElements, dtype);
        if (stop < start && step === 1) {
            // Auto adjust the step's sign if it hasn't been set
            // (or was set to 1)
            step = -1;
        }
        values[0] = start;
        for (let i = 1; i < values.length; i++) {
            values[i] = values[i - 1] + step;
        }
        return values;
    }

    /**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the License);
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an AS IS BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const rsqrtImpl = createSimpleUnaryImpl((xi) => 1 / Math.sqrt(xi));

    /**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function scatterImpl(indices, updates, shape, outputSize, sliceSize, numUpdates, sliceRank, strides, defaultValue, sumDupeIndices) {
        const flattenShape = [outputSize / sliceSize, sliceSize];
        const indicesData = indices.values;
        const updatesData = updates.values;
        if (outputSize === 0) {
            return tf.buffer(shape, updates.dtype);
        }
        const outBuf = tf.buffer(flattenShape, updates.dtype);
        if (typeof defaultValue === 'string') {
            outBuf.values.fill(defaultValue);
        }
        else if (typeof defaultValue === 'number') {
            outBuf.values.fill(defaultValue);
        }
        else if (typeof defaultValue === 'boolean') {
            outBuf.values.fill(+defaultValue);
        }
        for (let i = 0; i < numUpdates; i++) {
            const index = [];
            let flattenIndex = 0;
            for (let j = 0; j < sliceRank; j++) {
                const dim = indicesData[i * sliceRank + j];
                index.push(dim);
                flattenIndex += dim * strides[j];
            }
            if (flattenIndex < 0 || flattenIndex >= outputSize / sliceSize) {
                throw new Error(`Invalid indices: ${index} does not index into ${shape}`);
            }
            for (let k = 0; k < sliceSize; k++) {
                if (sumDupeIndices) {
                    outBuf.values[flattenIndex * sliceSize + k] +=
                        updatesData[i * sliceSize + k];
                }
                else {
                    outBuf.values[flattenIndex * sliceSize + k] = updates.rank === 0 ?
                        updatesData[0] :
                        updatesData[i * sliceSize + k];
                }
            }
        }
        return outBuf;
    }

    /**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the License);
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an AS IS BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const sigmoidImpl = createSimpleUnaryImpl((xi) => 1 / (1 + Math.exp(-xi)));

    /**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function sliceImpl(vals, begin, size, shape, dtype) {
        const isContinous = tf.slice_util.isSliceContinous(shape, begin, size);
        const length = tf.util.sizeFromShape(size);
        const xStrides = tf.util.computeStrides(shape);
        if (isContinous) {
            const flatOffset = tf.slice_util.computeFlatOffset(begin, xStrides);
            if (dtype === 'string') {
                return vals.slice(flatOffset, flatOffset + length);
            }
            return vals.subarray(flatOffset, flatOffset + length);
        }
        const decodedData = dtype === 'string' ?
            tf.backend_util.fromUint8ToStringArray(vals) :
            vals;
        const inBuf = tf.buffer(shape, dtype, decodedData);
        const outBuf = tf.buffer(size, dtype);
        for (let i = 0; i < outBuf.size; ++i) {
            const outLoc = outBuf.indexToLoc(i);
            const inLoc = outLoc.map((idx, j) => idx + begin[j]);
            outBuf.set(inBuf.get(...inLoc), ...outLoc);
        }
        if (dtype === 'string') {
            return tf.backend_util.fromStringArrayToUint8(outBuf.values);
        }
        return outBuf.values;
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function sparseFillEmptyRowsImpl(indices, indicesShape, indicesDType, values, valuesDType, denseShape, defaultValue) {
        const indicesCount = indicesShape[0];
        const denseRows = denseShape[0];
        const emptyRowIndicator = new Array(denseRows);
        const reverseIndexMap = new Array(indicesCount);
        const rank = indicesShape[1];
        if (denseRows === 0) {
            if (indicesCount !== 0) {
                throw new Error(tf.backend_util.getSparseFillEmptyRowsIndicesDenseShapeMismatch(indicesCount));
            }
            const outputIndices = tf.util.getArrayFromDType(indicesDType, 0);
            const outputValues = tf.util.getArrayFromDType(valuesDType, 0);
            return [
                outputIndices, [0, rank], outputValues, emptyRowIndicator, reverseIndexMap
            ];
        }
        let rowsAreOrdered = true;
        let lastIndicesRow = 0;
        const csrOffset = new Array(denseRows).fill(0);
        for (let i = 0; i < indicesCount; ++i) {
            // indices is a 2d tensor with shape of [N, rank]
            const row = indices[i * rank];
            if (row < 0) {
                throw new Error(tf.backend_util.getSparseFillEmptyRowsNegativeIndexErrorMessage(i, row));
            }
            if (row >= denseRows) {
                throw new Error(tf.backend_util.getSparseFillEmptyRowsOutOfRangeIndexErrorMessage(i, row, denseRows));
            }
            ++csrOffset[row];
            rowsAreOrdered = rowsAreOrdered && (row >= lastIndicesRow);
            lastIndicesRow = row;
        }
        let allRowsFull = true;
        for (let row = 0; row < denseRows; ++row) {
            // csrOffset here describes the number of elements in this dense row
            const rowEmpty = (csrOffset[row] === 0);
            emptyRowIndicator[row] = rowEmpty;
            allRowsFull = allRowsFull && !rowEmpty;
            // In filled version, each row has at least one element.
            csrOffset[row] = Math.max(csrOffset[row], 1);
            // Update csrOffset to represent the number of elements up to and
            // including denseRows + 1:
            //  csrOffset[0] == #{elements of row 0}
            //  csrOffset[1] == #{elements of row 1} + #{elements of row 0}
            //  ..
            //  csrOffset[i] == starting index for elements in row i + 1.
            if (row > 0) {
                csrOffset[row] += csrOffset[row - 1];
            }
        }
        if (allRowsFull && rowsAreOrdered) {
            const outputIndices = indices;
            const outputValues = values;
            for (let i = 0; i < indicesCount; ++i) {
                reverseIndexMap[i] = i;
            }
            return [
                outputIndices, [indicesCount, rank], outputValues, emptyRowIndicator,
                reverseIndexMap
            ];
        }
        else {
            const fullIndicesCount = csrOffset[denseRows - 1];
            const outputIndices = tf.util.getArrayFromDType(indicesDType, fullIndicesCount * rank);
            const outputValues = tf.util.getArrayFromDType(valuesDType, fullIndicesCount);
            const filledCount = new Array(denseRows).fill(0);
            // Fill in values for rows that are not missing
            for (let i = 0; i < indicesCount; ++i) {
                // indices is a 2d tensor with shape of [N, rank]
                const row = indices[i * rank];
                const offset = filledCount[row];
                const outputI = ((row === 0) ? 0 : csrOffset[row - 1]) + offset;
                filledCount[row]++; // Increment the filled count for this row.
                for (let j = 0; j < rank; ++j) {
                    // indices and outputIndices are 2d tensors with shape of [N, rank]
                    outputIndices[outputI * rank + j] = indices[i * rank + j];
                }
                outputValues[outputI] = values[i];
                // We'll need this reverse index map to backprop correctly.
                reverseIndexMap[i] = outputI;
            }
            // Fill in values for rows that are missing
            for (let row = 0; row < denseRows; ++row) {
                const rowCount = filledCount[row];
                if (rowCount === 0) { // We haven't filled this row
                    const startingIndex = (row === 0) ? 0 : csrOffset[row - 1];
                    // Remaining index values were set to zero already.
                    // Just need to set the row index in the right location.
                    // outputIndices is a 2d tensor with shape of [N, rank]
                    outputIndices[startingIndex * rank + 0] = row;
                    for (let col = 1; col < rank; ++col) {
                        outputIndices[startingIndex * rank + col] = 0;
                    }
                    outputValues[startingIndex] = defaultValue;
                }
            }
            return [
                outputIndices, [fullIndicesCount, rank], outputValues, emptyRowIndicator,
                reverseIndexMap
            ];
        }
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function sparseReshapeImpl(inputIndices, inputIndicesShape, inputDType, inputShape, targetShape) {
        const denseSize = tf.util.sizeFromShape(inputShape);
        const nnz = inputIndicesShape[0];
        const outputRank = targetShape.length;
        // Compute the output shape. Determine product of specified dimensions, and
        // find the index of the unspecified one.
        const outputShape = [];
        let product = 1;
        let unknownIndex = -1;
        for (let d = 0; d < outputRank; ++d) {
            const size = targetShape[d];
            if (size === -1) {
                if (unknownIndex !== -1) {
                    throw new Error(tf.backend_util
                        .getSparseReshapeMultipleNegativeOneOutputDimErrorMessage(unknownIndex, d));
                }
                unknownIndex = d;
                outputShape.push(1);
            }
            else {
                if (size < 0) {
                    throw new Error(tf.backend_util.getSparseReshapeNegativeOutputDimErrorMessage(d, size));
                }
                product *= size;
                outputShape.push(size);
            }
        }
        if (unknownIndex !== -1) {
            if (product <= 0) {
                throw new Error(tf.backend_util.getSparseReshapeEmptyTensorZeroOutputDimErrorMessage());
            }
            const missing = Math.trunc(denseSize / product);
            if (product * missing !== denseSize) {
                throw new Error(tf.backend_util.getSparseReshapeInputOutputMultipleErrorMessage(inputShape, outputShape));
            }
            outputShape[unknownIndex] = missing;
        }
        const outputSize = tf.util.sizeFromShape(outputShape);
        if (outputSize !== denseSize) {
            throw new Error(tf.backend_util.getSparseReshapeInputOutputMismatchErrorMessage(inputShape, outputShape));
        }
        const inputRank = inputShape.length;
        const inputStrides = [];
        if (inputRank > 0) {
            inputStrides[inputRank - 1] = 1;
            for (let d = inputRank - 2; d >= 0; --d) {
                inputStrides[d] = inputStrides[d + 1] * inputShape[d + 1];
            }
        }
        const outputStrides = [];
        if (outputRank > 0) {
            outputStrides[outputRank - 1] = 1;
            for (let d = outputRank - 2; d >= 0; --d) {
                outputStrides[d] = outputStrides[d + 1] * outputShape[d + 1];
            }
        }
        const newIndices = tf.util.getArrayFromDType(inputDType, nnz * outputRank);
        for (let i = 0; i < nnz; ++i) {
            let id = 0;
            for (let j = 0; j < inputRank; ++j) {
                // inputIndices is a 2d tensor with shape of [nnz, inputRank]
                id += inputIndices[i * inputRank + j] * inputStrides[j];
            }
            for (let j = 0; j < outputRank; ++j) {
                // newIndices is a 2d tensor with shape of [nnz, outputRank]
                newIndices[i * outputRank + j] = Math.trunc(id / outputStrides[j]);
                id %= outputStrides[j];
            }
        }
        return [newIndices, [nnz, outputRank], outputShape];
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function sparseSegmentReductionImpl(input, inputShape, inputDType, indices, segmentIds, isMean = false, defaultValue = 0) {
        const numIndices = indices.length;
        // Flatten the array to two dimensions
        const inputFlat = [inputShape[0], input.length / inputShape[0]];
        const numCol = inputFlat[1];
        // Note that the current implementation assumes that segmentIds values are
        // sorted.
        const lastSegmentIdPlusOne = numIndices > 0 ? segmentIds[numIndices - 1] + 1 : 0;
        const outputRows = lastSegmentIdPlusOne;
        if (outputRows < 0) {
            throw new Error(tf.backend_util.getSparseSegmentReductionNegativeSegmentIdsErrorMessage());
        }
        const outputShape = inputShape.slice();
        outputShape[0] = outputRows;
        const outputLength = outputShape.reduce((product, value) => product * value, 1);
        // Output array is initialized with the value 0 by default.
        const output = tf.util.getArrayFromDType(inputDType, outputLength);
        // Note that we do not initialize the output buffer with a default value, so
        // we need to explicitly set missing indices to the default value.
        if (numIndices === 0) {
            if (outputRows > 0) {
                output.fill(defaultValue);
            }
            return [output, outputShape];
        }
        if (outputRows <= 0) {
            throw new Error(tf.backend_util.getSparseSegmentReductionNegativeSegmentIdsErrorMessage());
        }
        let start = 0, end = 1;
        // Index from which the output is not initialized.
        let uninitializedIndex = 0;
        let outIndex = segmentIds[start];
        while (true) {
            // We initialize nextIndex to 0 to avoid may be uninitialized warning
            let nextIndex = 0;
            if (end < numIndices) {
                nextIndex = segmentIds[end];
                if (outIndex === nextIndex) {
                    ++end;
                    continue;
                }
                // We have a new segment here.  Verify that the segment ids are growing.
                if (outIndex >= nextIndex) {
                    throw new Error(tf.backend_util
                        .getSparseSegmentReductionNonIncreasingSegmentIdsErrorMessage());
                }
            }
            if (outIndex < 0 || outIndex >= outputRows) {
                throw new Error(tf.backend_util.getSparseSegmentReductionSegmentIdOutOfRangeErrorMessage(outIndex, outputRows));
            }
            // If there is a gap between two indices, we need to set that gap to the
            // default value.
            if (outIndex > uninitializedIndex) {
                output.fill(defaultValue, uninitializedIndex * numCol, outIndex * numCol);
            }
            for (let i = start; i < end; ++i) {
                const index = indices[i];
                if (index < 0 || index >= inputFlat[0]) {
                    throw new Error(tf.backend_util.getSparseSegmentReductionIndicesOutOfRangeErrorMessage(i, indices[i], inputFlat[0]));
                }
                for (let j = 0; j < numCol; j++) {
                    output[outIndex * numCol + j] += input[index * numCol + j];
                }
            }
            if (isMean) {
                for (let j = 0; j < numCol; j++) {
                    output[outIndex * numCol + j] /= end - start;
                }
            }
            start = end;
            ++end;
            uninitializedIndex = outIndex + 1;
            outIndex = nextIndex;
            if (end > numIndices) {
                break;
            }
        }
        // Fill the gap at the end with the default value.
        if (uninitializedIndex < outputRows) {
            output.fill(defaultValue, uninitializedIndex * numCol, outputRows * numCol);
        }
        return [output, outputShape];
    }

    /**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the License);
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an AS IS BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const sqrtImpl = createSimpleUnaryImpl((xi) => Math.sqrt(xi));

    /**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const squaredDifferenceImpl = createSimpleBinaryKernelImpl(((a, b) => {
        const diff = a - b;
        return diff * diff;
    }));

    /**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function stridedSliceImpl(outShape, xBuf, strides, begin) {
        const outBuf = tf.buffer(outShape, xBuf.dtype);
        for (let i = 0; i < outBuf.size; i++) {
            const loc = outBuf.indexToLoc(i);
            const newLoc = new Array(loc.length);
            for (let j = 0; j < newLoc.length; j++) {
                newLoc[j] = loc[j] * strides[j] + begin[j];
            }
            outBuf.set(xBuf.get(...newLoc), ...loc);
        }
        return outBuf;
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    /**
     * The StringNGramsOp class creates ngrams from ragged string data.
     * The constructor contains all attributes related to the operation such as
     * padding widths and strings, and the compute function can be used to
     * compute the ngrams for different ragged tensor inputs.
     */
    class StringNGramsOp {
        constructor(separator, nGramWidths, leftPad, rightPad, padWidth, preserveShortSequences) {
            this.separator = tf.util.encodeString(separator);
            this.nGramWidths = nGramWidths;
            this.leftPad = tf.util.encodeString(leftPad);
            this.rightPad = tf.util.encodeString(rightPad);
            this.padWidth = padWidth;
            this.preserveShort = preserveShortSequences;
        }
        getPadWidth(nGramWidth) {
            // Ngrams can be padded with either a fixed pad width or a dynamic pad
            // width depending on the 'padWidth' arg, but in no case should the padding
            // ever be wider than 'nGramWidth' - 1.
            return Math.min(this.padWidth < 0 ? nGramWidth - 1 : this.padWidth, nGramWidth - 1);
        }
        getNumNGrams(length, nGramWidth) {
            const padWidth = this.getPadWidth(nGramWidth);
            return Math.max(0, ((length + 2 * padWidth) - nGramWidth) + 1);
        }
        createNGrams(data, splitIndex, output, outputStartIndex, numNGrams, nGramWidth) {
            for (let nGramIndex = 0; nGramIndex < numNGrams; ++nGramIndex) {
                const padWidth = this.getPadWidth(nGramWidth);
                const leftPadding = Math.max(0, padWidth - nGramIndex);
                const rightPadding = Math.max(0, padWidth - (numNGrams - (nGramIndex + 1)));
                const numTokens = nGramWidth - (leftPadding + rightPadding);
                const dataStartIndex = splitIndex + (leftPadding > 0 ? 0 : nGramIndex - padWidth);
                // Calculate the total expected size of the nGram so we can reserve the
                // correct amount of space in the string.
                let nGramSize = 0;
                // Size of the left padding.
                nGramSize += leftPadding * this.leftPad.length;
                // Size of the tokens.
                for (let n = 0; n < numTokens; ++n) {
                    nGramSize += data[dataStartIndex + n].length;
                }
                // Size of the right padding.
                nGramSize += rightPadding * this.rightPad.length;
                // Size of the separators.
                const numSeparators = leftPadding + rightPadding + numTokens - 1;
                nGramSize += numSeparators * this.separator.length;
                // Build the nGram.
                output[outputStartIndex + nGramIndex] = new Uint8Array(nGramSize);
                const nGram = output[outputStartIndex + nGramIndex];
                let nextNGramIndex = 0;
                const appendToNGram = (str) => str.forEach((value) => nGram[nextNGramIndex++] = value);
                for (let n = 0; n < leftPadding; ++n) {
                    appendToNGram(this.leftPad);
                    appendToNGram(this.separator);
                }
                // Only output first numTokens - 1 pairs of data and separator
                for (let n = 0; n < numTokens - 1; ++n) {
                    appendToNGram(data[dataStartIndex + n]);
                    appendToNGram(this.separator);
                }
                // Handle case when there are no tokens or no right padding as these
                // can result in consecutive separators.
                if (numTokens > 0) {
                    // If we have tokens, then output last and then pair each separator
                    // with the right padding that follows, to ensure nGram ends either with
                    // the token or with the right pad.
                    appendToNGram(data[dataStartIndex + numTokens - 1]);
                    for (let n = 0; n < rightPadding; ++n) {
                        appendToNGram(this.separator);
                        appendToNGram(this.rightPad);
                    }
                }
                else {
                    // If we don't have tokens, then the last item inserted into the nGram
                    // has been the separator from the left padding loop above. Hence,
                    // output right pad and separator and make sure to finish with a
                    // padding, not a separator.
                    for (let n = 0; n < rightPadding - 1; ++n) {
                        appendToNGram(this.rightPad);
                        appendToNGram(this.separator);
                    }
                    appendToNGram(this.rightPad);
                }
            }
        }
        // Data and splits together form the definition of the ragged tensor,
        // where data is 1 dimensional and contains the values of the tensor
        // and splits denotes the indices at which each row starts.
        compute(data, splits) {
            // Validate that the splits are valid indices into data, only if there are
            // splits specified.
            const inputDataSize = data.length;
            const splitsSize = splits.length;
            if (splitsSize > 0) {
                let prevSplit = splits[0];
                if (prevSplit !== 0) {
                    throw new Error(`First split value must be 0, got ${prevSplit}`);
                }
                for (let i = 1; i < splitsSize; ++i) {
                    let validSplits = splits[i] >= prevSplit;
                    validSplits = validSplits && (splits[i] <= inputDataSize);
                    if (!validSplits) {
                        throw new Error(`Invalid split value ${splits[i]}, must be in [${prevSplit}, ${inputDataSize}]`);
                    }
                    prevSplit = splits[i];
                }
                if (prevSplit !== inputDataSize) {
                    throw new Error(`Last split value must be data size. Expected ${inputDataSize}, got ${prevSplit}`);
                }
            }
            const numBatchItems = splitsSize - 1;
            const nGramsSplits = tf.util.getArrayFromDType('int32', splitsSize);
            // If there is no data or size, return an empty ragged tensor.
            if (inputDataSize === 0 || splitsSize === 0) {
                const empty = new Array(inputDataSize);
                for (let i = 0; i <= numBatchItems; ++i) {
                    nGramsSplits[i] = 0;
                }
                return [empty, nGramsSplits];
            }
            nGramsSplits[0] = 0;
            for (let i = 1; i <= numBatchItems; ++i) {
                const length = splits[i] - splits[i - 1];
                let numNGrams = 0;
                this.nGramWidths.forEach((nGramWidth) => {
                    numNGrams += this.getNumNGrams(length, nGramWidth);
                });
                if (this.preserveShort && length > 0 && numNGrams === 0) {
                    numNGrams = 1;
                }
                nGramsSplits[i] = nGramsSplits[i - 1] + numNGrams;
            }
            const nGrams = new Array(nGramsSplits[numBatchItems]);
            for (let i = 0; i < numBatchItems; ++i) {
                const splitIndex = splits[i];
                let outputStartIdx = nGramsSplits[i];
                this.nGramWidths.forEach((nGramWidth) => {
                    const length = splits[i + 1] - splits[i];
                    const numNGrams = this.getNumNGrams(length, nGramWidth);
                    this.createNGrams(data, splitIndex, nGrams, outputStartIdx, numNGrams, nGramWidth);
                    outputStartIdx += numNGrams;
                });
                // If we're preserving short sequences, check to see if no sequence was
                // generated by comparing the current output start idx to the original
                // one (nGramSplitsdata). If no ngrams were generated, then they will
                // be equal (since we increment outputStartIdx by numNGrams every
                // time we create a set of ngrams.)
                if (this.preserveShort && outputStartIdx === nGramsSplits[i]) {
                    const dataLength = splits[i + 1] - splits[i];
                    // One legitimate reason to not have any ngrams when this.preserveShort
                    // is true is if the sequence itself is empty. In that case, move on.
                    if (dataLength === 0) {
                        continue;
                    }
                    // We don't have to worry about dynamic padding sizes here: if padding
                    // was dynamic, every sequence would have had sufficient padding to
                    // generate at least one nGram.
                    const nGramWidth = dataLength + 2 * this.padWidth;
                    const numNGrams = 1;
                    this.createNGrams(data, splitIndex, nGrams, outputStartIdx, numNGrams, nGramWidth);
                }
            }
            return [nGrams, nGramsSplits];
        }
    }
    function stringNGramsImpl(data, dataSplits, separator, nGramWidths, leftPad, rightPad, padWidth, preserveShortSequences) {
        return new StringNGramsOp(separator, nGramWidths, leftPad, rightPad, padWidth, preserveShortSequences)
            .compute(data, dataSplits);
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function split(str, delimiters, skipEmpty, result) {
        if (!str.length) {
            return;
        }
        // When the delimiter is empty, the input is split into individual characters.
        if (delimiters.length === 0) {
            for (let i = 0; i < str.length; ++i) {
                result.push(str.subarray(i, i + 1));
            }
            return;
        }
        // When there is one delimiter, the input is split only at that delimiter.
        if (delimiters.length === 1) {
            const delimiter = delimiters[0];
            let f = str.indexOf(delimiter);
            while (f !== -1) {
                const token = str.subarray(0, f);
                if (!skipEmpty || token.length !== 0) {
                    result.push(token);
                }
                str = str.subarray(f + 1);
                f = str.indexOf(delimiter);
            }
            if (!skipEmpty || str.length !== 0) {
                result.push(str);
            }
            return;
        }
        // When there are multiple delimiters, the input is split at every instance
        // one of the delimiters appears.
        let tokenStart = 0;
        for (let i = 0; i < str.length + 1; i++) {
            if ((i === str.length) || (delimiters.indexOf(str[i]) !== -1)) {
                const token = str.subarray(tokenStart, i);
                if (!skipEmpty || token.length !== 0) {
                    result.push(token);
                }
                tokenStart = i + 1;
            }
        }
    }
    function stringSplitImpl(input, delimiter, skipEmpty) {
        const batchSize = input.length;
        // Empty delimiter means split the input character by character.
        const tokens = [];
        let outputSize = 0;
        let maxNumEntries = 0;
        const numIndices = new Array(batchSize);
        for (let i = 0; i < batchSize; ++i) {
            const prevTokensLength = tokens.length;
            split(input[i], delimiter, skipEmpty, tokens);
            const nEntries = tokens.length - prevTokensLength;
            numIndices[i] = nEntries;
            outputSize += nEntries;
            maxNumEntries = Math.max(maxNumEntries, nEntries);
        }
        const indices = tf.util.getArrayFromDType('int32', outputSize * 2);
        const values = new Array(outputSize);
        const shape = [batchSize, maxNumEntries];
        let c = 0;
        for (let i = 0; i < batchSize; ++i) {
            for (let j = 0; j < numIndices[i]; ++j) {
                // indices is a 2d tensor with shape of [outputSize, 2]
                indices[c * 2] = i;
                indices[c * 2 + 1] = j;
                values[c] = tokens[c];
                ++c;
            }
        }
        return [indices, values, shape];
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function stringToHashBucketFastImpl(input, numBuckets) {
        const output = tf.util.getArrayFromDType('int32', input.length);
        for (let i = 0; i < input.length; ++i) {
            output[i] =
                tf.util.fingerPrint64(input[i]).modulo(numBuckets).getLowBitsUnsigned();
        }
        return output;
    }

    /**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const subImpl = createSimpleBinaryKernelImpl(((aValue, bValue) => aValue - bValue));

    /**
     * @license
     * Copyright 2019 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    /**
     * An implementation of the tile kernel shared between webgl and cpu for string
     * tensors only.
     */
    function tileImpl(xBuf, reps) {
        const newShape = new Array(xBuf.rank);
        for (let i = 0; i < newShape.length; i++) {
            newShape[i] = xBuf.shape[i] * reps[i];
        }
        const result = tf.buffer(newShape, xBuf.dtype);
        for (let i = 0; i < result.values.length; ++i) {
            const newLoc = result.indexToLoc(i);
            const originalLoc = new Array(xBuf.rank);
            for (let j = 0; j < originalLoc.length; j++) {
                originalLoc[j] = newLoc[j] % xBuf.shape[j];
            }
            const originalIndex = xBuf.locToIndex(originalLoc);
            result.values[i] = xBuf.values[originalIndex];
        }
        return result;
    }

    /**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const comparePair = (a, b) => {
        const valueDiff = b.value - a.value;
        return valueDiff === 0 ? a.index - b.index : valueDiff;
    };
    /**
     * Partitions array where all elements smaller than the (k+1) smallest element
     * are found to the left of it, and all larger to the right of it.
     * Based on the Floyd-Rivest Algorithm, ref:
     * https://en.wikipedia.org/wiki/Floyd%E2%80%93Rivest_algorithm
     * @param array: Array to partition
     * @param left: Left index for the interval
     * @param right: Right index for the interval
     * @param k: Desired index value, where array[k] is the (k+1)th smallest element
     *           when left = 0
     */
    function select(array, k, left = 0, right = array.length - 1) {
        while (right > left) {
            // Use select recursively to sample a smaller set of size s
            // the arbitrary constants 600 and 0.5 are used in the original
            // version to minimize execution time.
            if (right - left > 600) {
                const n = right - left + 1;
                const i = k - left + 1;
                const z = Math.log(n);
                const s = 0.5 * Math.exp(2 * z / 3);
                const sd = 0.5 * Math.sqrt(z * s * (n - s) / n) * Math.sign(i - n / 2);
                const newLeft = Math.max(left, Math.floor(k - i * s / n + sd));
                const newRight = Math.min(right, Math.floor(k + (n - i) * s / n + sd));
                select(array, k, newLeft, newRight);
            }
            // partition the elements between left and right around t
            const t = array[k];
            let i = left;
            let j = right;
            tf.util.swap(array, left, k);
            if (comparePair(array[right], t) > 0) {
                tf.util.swap(array, left, right);
            }
            while (i < j) {
                tf.util.swap(array, i, j);
                i++;
                j--;
                while (comparePair(array[i], t) < 0) {
                    i = i + 1;
                }
                while (comparePair(array[j], t) > 0) {
                    j = j - 1;
                }
            }
            if (comparePair(array[left], t) === 0) {
                tf.util.swap(array, left, j);
            }
            else {
                j = j + 1;
                tf.util.swap(array, j, right);
            }
            // Adjust left and right towards the boundaries of the subset
            // containing the (k - left + 1)th smallest element.
            if (j <= k) {
                left = j + 1;
            }
            if (k <= j) {
                right = j - 1;
            }
        }
    }
    function topKImpl(x, xShape, xDtype, k, sorted) {
        // Reshape into a 2d tensor [batch, lastDim] and compute topk along lastDim.
        const lastDim = xShape[xShape.length - 1];
        const [batch, size] = [x.length / lastDim, lastDim];
        const allTopKVals = tf.util.getTypedArrayFromDType(xDtype, batch * k);
        const allTopKIndices = tf.util.getTypedArrayFromDType('int32', batch * k);
        for (let b = 0; b < batch; b++) {
            const offset = b * size;
            const vals = x.subarray(offset, offset + size);
            let valAndInd = new Array(vals.length);
            vals.forEach((value, index) => valAndInd[index] = { value, index });
            if (k < valAndInd.length) {
                select(valAndInd, k);
                valAndInd = valAndInd.slice(0, k);
            }
            if (sorted) {
                valAndInd.sort(comparePair);
            }
            const outOffset = b * k;
            const topKVals = allTopKVals.subarray(outOffset, outOffset + k);
            const topKIndices = allTopKIndices.subarray(outOffset, outOffset + k);
            for (let i = 0; i < k; i++) {
                topKVals[i] = valAndInd[i].value;
                topKIndices[i] = valAndInd[i].index;
            }
        }
        // Reshape back to the original input shape, except that the last
        // dimension is k.
        const outputShape = xShape.slice();
        outputShape[outputShape.length - 1] = k;
        return [
            tf.buffer(outputShape, xDtype, allTopKVals),
            tf.buffer(outputShape, 'int32', allTopKIndices)
        ];
    }

    /**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function uniqueImpl(values, axis, shape, dtype) {
        // Normalize and validate axis.
        const $axis = tf.util.parseAxisParam(axis, shape)[0];
        // Calculate the new shape that is suitable for extracting data along the
        // given axis.
        //
        // The rank is 3.
        // The size of the 1st dimension is the size of all the axes < the given axis.
        // The size of the 2nd dimension is the same as the size of the given axis.
        // The size of the 3rd dimension is the size of all the axes > the given axis.
        //
        // For example, for a 4D tensor with shape=[2, 3, 5, 4] and axis=2, the
        // newShape would be: [2*3, 5, 4].
        //
        // Note that this is not the final output shape. This will be the shape for an
        // intermediate TensorBuffer (see inputBuffer below) to allow us to extract
        // values along the given axis. To demonstrate how it works, consider the
        // following example:
        //
        // Input: a 3D tensor, with shape [1, 2, 3]
        // [
        //   [
        //      [1,2,3],
        //      [4,5,6]
        //   ]
        // ]
        // Axis: 2 (the last axis).
        // Along axis 2, we expect to extract 3 tensors: [1,4], [2,5], [3,6].
        //
        // For this example, newShape would be: [2, 3, 1], where 2 is calculated from
        // 1*2. The re-shaped data would look like:
        //
        // [
        //   [
        //     [1], [2], [3]
        //   ],
        //   [
        //     [4], [5], [6]
        //   ]
        // ]
        //
        // Then, we can construct a 3-level nested loop by the following dimension
        // order to extract the values along the axis (dimension1):
        // i: dimension1       // 0,1,2 (newShape[1])
        //   m: dimension0     // 0,1   (newShape[0])
        //     n: dimension2   // 0     (newShape[2])
        //
        //                       m, i, n
        //                      ---------
        // Iteration 0: data at [0, 0, 0] => "1"
        // Iteration 1: data at [1, 0, 0] => "4"
        // We got [1,4].
        // Iteration 2: data at [0, 1, 0] => "2"
        // Iteration 3: data at [1, 1, 0] => "5"
        // We got [2,5].
        // Iteration 4: data at [0, 2, 0] => "3"
        // Iteration 5: data at [1, 2, 0] => "6"
        // We got [3,6].
        const newShape = [1, shape[0], 1];
        for (let i = 0; i < $axis; i++) {
            newShape[0] *= shape[i];
        }
        newShape[1] = shape[$axis];
        for (let i = $axis + 1; i < shape.length; i++) {
            newShape[2] *= shape[i];
        }
        // A map from unique elements (their string representations) to their values
        // in "indices" (below).
        const uniqueElements = {};
        // The indices of each unique element in the original tensor along the given
        // axis. It is 1D and has the same size as the given axis.
        const indices = new Int32Array(shape[$axis]);
        // Create a buffer so we can easily extract value at a given location.
        const inputBuffer = new tf.TensorBuffer(newShape, dtype, values);
        // The indices along the given axis that have unique elements. This is a
        // de-duped version of "indices" above.
        const uniqueIndices = [];
        const is1DTensor = newShape[0] === 1 && newShape[2] === 1;
        for (let i = 0; i < shape[$axis]; i++) {
            // Extract values along the axis.
            let element;
            if (is1DTensor) {
                // Fast path for 1D tensor input.
                element = values[i].toString();
            }
            else {
                const axisValues = [];
                for (let m = 0; m < newShape[0]; m++) {
                    for (let n = 0; n < newShape[2]; n++) {
                        axisValues.push(inputBuffer.get(m, i, n));
                    }
                }
                element = axisValues.join(',');
            }
            // Dedup and update various indices.
            if (uniqueElements[element] !== undefined) {
                indices[i] = uniqueElements[element];
            }
            else {
                const uniqueIndex = Object.keys(uniqueElements).length;
                uniqueElements[element] = uniqueIndex;
                indices[i] = uniqueIndex;
                uniqueIndices.push(i);
            }
        }
        // Now we know where each of the unique elements are located along the axis
        // (uniqueIndices). Extract them from input buffer and store them in the
        // output buffer.
        const outputTmpShape = newShape.slice();
        outputTmpShape[1] = Object.keys(uniqueElements).length;
        const outputBuffer = new tf.TensorBuffer(outputTmpShape, dtype);
        uniqueIndices.forEach((uniqueElementIndex, i) => {
            for (let m = 0; m < newShape[0]; m++) {
                for (let n = 0; n < newShape[2]; n++) {
                    outputBuffer.set(inputBuffer.get(m, uniqueElementIndex, n), m, i, n);
                }
            }
        });
        // The output shape can be calculated from the input shape with the size of
        // the given axis replaced by the number of unique elements along that axis.
        const outputShape = shape.slice();
        outputShape[$axis] = outputTmpShape[1];
        return {
            outputValues: outputBuffer.values,
            outputShape,
            indices,
        };
    }

    /**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */

    var shared = /*#__PURE__*/Object.freeze({
        __proto__: null,
        simpleAbsImpl: simpleAbsImpl,
        addImpl: addImpl,
        bincountImpl: bincountImpl,
        bincountReduceImpl: bincountReduceImpl,
        castImpl: castImpl,
        ceilImpl: ceilImpl,
        concatImpl: concatImpl,
        equalImpl: equalImpl,
        expImpl: expImpl,
        expm1Impl: expm1Impl,
        floorImpl: floorImpl,
        gatherNdImpl: gatherNdImpl,
        gatherV2Impl: gatherV2Impl,
        greaterImpl: greaterImpl,
        greaterEqualImpl: greaterEqualImpl,
        lessImpl: lessImpl,
        lessEqualImpl: lessEqualImpl,
        linSpaceImpl: linSpaceImpl,
        logImpl: logImpl,
        maxImpl: maxImpl,
        maximumImpl: maximumImpl,
        minimumImpl: minimumImpl,
        multiplyImpl: multiplyImpl,
        negImpl: negImpl,
        notEqualImpl: notEqualImpl,
        prodImpl: prodImpl,
        raggedGatherImpl: raggedGatherImpl,
        raggedRangeImpl: raggedRangeImpl,
        raggedTensorToTensorImpl: raggedTensorToTensorImpl,
        rangeImpl: rangeImpl,
        rsqrtImpl: rsqrtImpl,
        scatterImpl: scatterImpl,
        sigmoidImpl: sigmoidImpl,
        sliceImpl: sliceImpl,
        sparseFillEmptyRowsImpl: sparseFillEmptyRowsImpl,
        sparseReshapeImpl: sparseReshapeImpl,
        sparseSegmentReductionImpl: sparseSegmentReductionImpl,
        sqrtImpl: sqrtImpl,
        squaredDifferenceImpl: squaredDifferenceImpl,
        stridedSliceImpl: stridedSliceImpl,
        stringNGramsImpl: stringNGramsImpl,
        stringSplitImpl: stringSplitImpl,
        stringToHashBucketFastImpl: stringToHashBucketFastImpl,
        subImpl: subImpl,
        tileImpl: tileImpl,
        topKImpl: topKImpl,
        transposeImpl: transposeImpl,
        uniqueImpl: uniqueImpl
    });

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const { addImpl: addImplCPU, castImpl: castImplCPU, ceilImpl: ceilImplCPU, concatImpl: concatImplCPU, equalImpl: equalImplCPU, expImpl: expImplCPU, expm1Impl: expm1ImplCPU, floorImpl: floorImplCPU, gatherNdImpl: gatherNdImplCPU, gatherV2Impl: gatherV2ImplCPU, greaterEqualImpl: greaterEqualImplCPU, greaterImpl: greaterImplCPU, lessEqualImpl: lessEqualImplCPU, lessImpl: lessImplCPU, logImpl: logImplCPU, maxImpl: maxImplCPU, maximumImpl: maximumImplCPU, minimumImpl: minimumImplCPU, multiplyImpl: multiplyImplCPU, negImpl: negImplCPU, notEqualImpl: notEqualImplCPU, prodImpl: prodImplCPU, rangeImpl: rangeImplCPU, rsqrtImpl: rsqrtImplCPU, scatterImpl: scatterImplCPU, simpleAbsImpl: simpleAbsImplCPU, sliceImpl: sliceImplCPU, stridedSliceImpl: stridedSliceImplCPU, stringNGramsImpl: stringNGramsImplCPU, subImpl: subImplCPU, tileImpl: tileImplCPU, topKImpl: topKImplCPU, transposeImpl: transposeImplCPU, uniqueImpl: uniqueImplCPU, } = shared;

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const abs = unaryKernelFunc({ opType: UnaryOpType.ABS, cpuKernelImpl: simpleAbsImplCPU });
    const absConfig = {
        kernelName: tf.Abs,
        backendName: 'webgpu',
        kernelFunc: abs
    };

    /**
     * @license
     * Copyright 2022 Google LLC.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const acos = unaryKernelFunc({ opType: UnaryOpType.ACOS });
    const acosConfig = {
        kernelName: tf.Acos,
        backendName: 'webgpu',
        kernelFunc: acos
    };

    /**
     * @license
     * Copyright 2022 Google LLC.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const acosh = unaryKernelFunc({ opType: UnaryOpType.ACOSH });
    const acoshConfig = {
        kernelName: tf.Acosh,
        backendName: 'webgpu',
        kernelFunc: acosh
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const addKernelFunc = binaryKernelFunc({ opType: BinaryOpType.ADD, cpuKernelImpl: addImplCPU, supportsComplex: true });
    const addConfig = {
        kernelName: tf.Add,
        backendName: 'webgpu',
        kernelFunc: addKernelFunc
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    class AddNPackedProgram {
        constructor(shapes) {
            this.workPerThread = 1;
            this.workgroupSize = [64, 1, 1];
            this.size = true;
            this.outputShape = shapes[0];
            this.variableNames = shapes.map((_, i) => `T${i}`);
            this.dispatchLayout = flatDispatchLayout(this.outputShape);
            this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize, [this.workPerThread, 1, 1]);
            this.shaderKey = 'addN';
        }
        getUserCode() {
            const snippets = [];
            // Get target elements from every input tensor.
            this.variableNames.forEach(variable => {
                snippets.push(`let v${variable} = get${variable}ByOutputCoords(coords);`);
            });
            // Calculate the sum of all elements.
            const operation = this.variableNames
                .map(variable => {
                return `v${variable}`;
            })
                .join(' + ');
            const userCode = `
      ${getMainHeaderString('index')} {
        for (var i = 0; i < ${this.workPerThread}; i = i + 1) {
          let flatIndex = index * ${this.workPerThread} + i;
          if (flatIndex < uniforms.size) {
            let coords = getCoordsFromIndex(flatIndex);
            ${snippets.join('\n        ')}
            setOutputAtIndex(flatIndex, ${operation});
          }
        }
      }
    `;
            return userCode;
        }
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function addN(args) {
        const { inputs, backend } = args;
        const tensors = inputs;
        if (tensors.length === 1) {
            return identity({ inputs: { x: tensors[0] }, backend });
        }
        const dtype = tensors.map(t => t.dtype).reduce((d1, d2) => tf.upcastType(d1, d2));
        const shapes = tensors.map(t => t.shape);
        const program = new AddNPackedProgram(shapes);
        return backend.runWebGPUProgram(program, tensors, dtype);
    }
    const addNConfig = {
        kernelName: tf.AddN,
        backendName: 'webgpu',
        kernelFunc: addN
    };

    /**
     * @license
     * Copyright 2019 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    class TransposeSharedProgram {
        constructor(aShape, newDim) {
            this.variableNames = ['A'];
            // Note that the maximum number of workgroup invocations by webgpu is 256.
            this.workgroupSize = [16, 16, 1];
            const outputShape = new Array(aShape.length);
            for (let i = 0; i < outputShape.length; i++) {
                outputShape[i] = aShape[newDim[i]];
            }
            this.outputShape = outputShape;
            this.dispatchLayout = { x: [0], y: [1] };
            this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize, [1, 1, 1]);
            this.shaderKey = 'transposeShared';
        }
        getUserCode() {
            tf.util.assert(this.workgroupSize[0] === this.workgroupSize[1], () => `Must be a square tile, current tile shape is ${this.workgroupSize[0]} x ${this.workgroupSize[1]}`);
            const tileSize = this.workgroupSize[0];
            const userCode = `
      var<workgroup> tile : array<array<f32, ${this.workgroupSize[0] + 1}>, ${this.workgroupSize[0]}>;
      ${getMainHeaderString()} {
        var x = i32(workgroupId.x) * ${tileSize} + i32(localId.x);
        var y = i32(workgroupId.y) * ${tileSize} + i32(localId.y);
        let width = uniforms.outShape[0];
        let height = uniforms.outShape[1];
        if (x < width && y < height) {
          tile[localId.y][localId.x] = f32(A[y * width + x]);
        }
        workgroupBarrier();

        x = i32(workgroupId.y) * ${tileSize} + i32(localId.x);
        y = i32(workgroupId.x) * ${tileSize} + i32(localId.y);
        if (x < height && y < width) {
          setOutputAtIndex((y * height + x), tile[localId.x]
            [localId.y]);
        }
      }
    `;
            return userCode;
        }
    }

    /**
     * @license
     * Copyright 2019 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    class TransposeProgram {
        constructor(aShape, newDim) {
            this.variableNames = ['A'];
            this.workPerThread = 1;
            this.workgroupSize = [64, 1, 1];
            this.size = true;
            const outputShape = new Array(aShape.length);
            for (let i = 0; i < outputShape.length; i++) {
                outputShape[i] = aShape[newDim[i]];
            }
            this.outputShape = outputShape;
            this.dispatchLayout = flatDispatchLayout(this.outputShape);
            this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize, [this.workPerThread, 1, 1]);
            this.newDim = newDim;
            this.shaderKey = `transpose_${newDim}`;
        }
        getUserCode() {
            const dtype = getCoordsDataType(this.outputShape.length);
            const switched = getSwitchedCoords(this.newDim);
            const userCode = `
      ${getMainHeaderString('index')} {
        for(var i = 0; i < ${this.workPerThread}; i = i + 1) {
          let flatIndex = index * ${this.workPerThread} + i;
          if(flatIndex < uniforms.size) {
            let resRC = getCoordsFromIndex(flatIndex);
            setOutputAtIndex(flatIndex, A[getIndexFromCoords${this.outputShape.length}D(
              ${dtype}(${switched}), uniforms.aShape)]);
          }
        }
      }
    `;
            return userCode;
        }
    }
    function getSwitchedCoords(newDim) {
        const rank = newDim.length;
        if (rank > 6) {
            throw Error(`Transpose for rank ${rank} is not yet supported`);
        }
        const switchedCoords = new Array(rank);
        for (let i = 0; i < newDim.length; i++) {
            switchedCoords[newDim[i]] = `resRC.${getCoordsXYZ(i)}`;
        }
        return switchedCoords.join();
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function transpose(args) {
        const { inputs, backend, attrs } = args;
        const { x } = inputs;
        const { perm } = attrs;
        const webgpuBackend = backend;
        const xRank = x.shape.length;
        const newShape = new Array(xRank);
        for (let i = 0; i < newShape.length; i++) {
            newShape[i] = x.shape[perm[i]];
        }
        if (backend.shouldExecuteOnCPU([x])) {
            const xData = webgpuBackend.tensorMap.get(x.dataId);
            const values = xData.values;
            const outValues = transposeImplCPU(values, x.shape, x.dtype, perm, newShape);
            return backend.makeTensorInfo(newShape, x.dtype, outValues);
        }
        if (x.shape.length === 2 && tf.util.arraysEqual(perm, [1, 0])) {
            const program = new TransposeSharedProgram(x.shape, perm);
            return webgpuBackend.runWebGPUProgram(program, [x], x.dtype);
        }
        const program = new TransposeProgram(x.shape, perm);
        return webgpuBackend.runWebGPUProgram(program, [x], x.dtype);
    }
    const transposeConfig = {
        kernelName: tf.Transpose,
        backendName: 'webgpu',
        kernelFunc: transpose
    };

    /**
     * @license
     * Copyright 2019 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    class ReduceProgram {
        constructor(reduceInfo, reduceType) {
            this.workgroupSize = [64, 1, 1];
            this.variableNames = ['x'];
            this.uniforms = 'reduceSize : i32,';
            this.size = true;
            this.inputShape = [reduceInfo.batchSize, reduceInfo.inSize];
            const [outputShape,] = tf.backend_util.computeOutAndReduceShapes(this.inputShape, [1]);
            this.outputShape = outputShape.length === 0 ? [1] : outputShape;
            this.dispatchLayout = flatDispatchLayout(this.outputShape);
            // A work group only outputs a data, so we transfer [1, 1, 1] to compute
            // dispatch size.
            this.dispatch =
                computeDispatch(this.dispatchLayout, this.outputShape, [1, 1, 1]);
            this.reduceType = reduceType;
            this.shaderKey = `reduce_${reduceType}`;
        }
        getUserCode() {
            let reduceOp = ``;
            let initValue = '0.0';
            const workgroupSizeX = this.workgroupSize[0];
            if (this.reduceType === 'min' || this.reduceType === 'max') {
                reduceOp = `
         if (isnan(candidate)) {
          bestValue = uniforms.NAN;
         } else if (!isnan(bestValue) && candidate ${this.reduceType === 'min' ? '<' : '>'} bestValue)
           {  bestValue = candidate; }`;
                initValue = 'f32(x[offset])';
            }
            else if (this.reduceType === 'sum' || this.reduceType === 'mean') {
                reduceOp = ' bestValue = bestValue + candidate; ';
            }
            else if (this.reduceType === 'prod') {
                reduceOp = ' bestValue = bestValue * candidate; ';
                initValue = '1.0';
            }
            else if (this.reduceType === 'all') {
                reduceOp = ' bestValue = f32(bestValue >= 1.0 && candidate >= 1.0); ';
                initValue = '1.0';
            }
            else if (this.reduceType === 'any') {
                reduceOp = ' bestValue = f32(bestValue >= 1.0 || candidate >= 1.0); ';
                initValue = '0.0';
            }
            const outputSnippet = this.reduceType === 'mean' ?
                // tslint:disable-next-line:max-line-length
                `setOutputAtIndex(outputIndex, bestValue / f32(uniforms.reduceSize));` :
                `setOutputAtIndex(outputIndex, bestValue);`;
            const sharedMemorySnippet = `
         var<workgroup> xBestValues : array<f32, ${workgroupSizeX}>;
       `;
            const userCode = `
       fn DIV_CEIL(a : u32, b : u32) -> u32 {
        return ((a - 1u) / b + 1u);
       }

       ${sharedMemorySnippet}
       fn getOffset(outputIndex : i32) -> i32 {
         let outputCoords = getCoordsFromIndex(outputIndex);
         let offset = ${this.outputShape.length === 1 ?
            'outputCoords' :
            'outputCoords[0]'} * uniforms.reduceSize;
          return offset;
       }
       ${getMainHeaderString('index')} {
         let outputIndex = index / ${workgroupSizeX};
         let offset = getOffset(outputIndex);
         var bestValue = ${initValue};
         let Length = uniforms.reduceSize;
         let WorkPerThread = DIV_CEIL(u32(Length), ${workgroupSizeX}u);
         for (var k = i32(localId.x); k < Length && outputIndex < uniforms.size;
             k = k + ${workgroupSizeX}) {
           let candidate = f32(x[offset + k]);
           ${reduceOp}
         }
         xBestValues[localId.x] = bestValue;
         workgroupBarrier();

         var reduceSize = min(u32(Length), ${workgroupSizeX}u);
         for (var currentSize = reduceSize / 2u; reduceSize > 1u;
             currentSize = reduceSize / 2u) {
           let interval = DIV_CEIL(reduceSize, 2u);
           if (localId.x < currentSize) {
            let candidate = xBestValues[localId.x + interval];
            ${reduceOp}
            xBestValues[localId.x] = bestValue;
           }
           reduceSize = interval;
           workgroupBarrier();
         }

         if (localId.x == 0u && outputIndex < uniforms.size) {
          ${outputSnippet}
        }
       }
     `;
            return userCode;
        }
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function reduce(x, axis, keepDims, reduceType, backend) {
        const xRank = x.shape.length;
        const toDispose = [];
        const origAxes = tf.util.parseAxisParam(axis, x.shape);
        let axes = origAxes;
        const permutedAxes = tf.backend_util.getAxesPermutation(axes, xRank);
        let input = x;
        if (permutedAxes != null) {
            input = transpose({ inputs: { x }, attrs: { perm: permutedAxes }, backend });
            axes = tf.backend_util.getInnerMostAxes(axes.length, xRank);
            toDispose.push(input);
        }
        tf.backend_util.assertAxesAreInnerMostDims(reduceType, axes, xRank);
        const [reduceOutShape, reduceShape] = tf.backend_util.computeOutAndReduceShapes(input.shape, axes);
        let resOutShape = reduceOutShape;
        if (keepDims) {
            // rather than reshape at the end, set the target shape here.
            resOutShape = tf.backend_util.expandShapeToKeepDim(reduceOutShape, origAxes);
        }
        let res;
        if ((reduceType === 'max' || reduceType === 'prod') &&
            backend.shouldExecuteOnCPU([input])) {
            const xVals = backend.tensorMap.get(input.dataId).values;
            switch (reduceType) {
                case 'max':
                    const outValues = maxImplCPU(xVals, tf.util.sizeFromShape(reduceShape), resOutShape, x.dtype);
                    res = backend.makeTensorInfo(resOutShape, x.dtype, outValues);
                    break;
                case 'prod':
                    const { outVals, outShape, outDtype } = prodImplCPU(input.shape, input.dtype, xVals, axes);
                    res = backend.makeTensorInfo(outShape, outDtype, outVals);
                    break;
                default:
                    throw new Error(`${reduceType} CPU implementation is not yet supported.`);
            }
        }
        else {
            const inSize = tf.util.sizeFromShape(reduceShape);
            const xSize = tf.util.sizeFromShape(input.shape);
            const batchSize = xSize / inSize;
            const reduceInfo = { windowSize: inSize, inSize, batchSize, outSize: 1 };
            const dtype = reduceType === 'mean' ? 'float32' : tf.sumOutType(x.dtype);
            const uniformData = [
                { type: 'int32', data: [inSize] },
            ];
            const program = new ReduceProgram(reduceInfo, reduceType);
            const reduced = backend.runWebGPUProgram(program, [input], dtype, uniformData);
            toDispose.push(reduced);
            res = reshape({ inputs: { x: reduced }, attrs: { shape: resOutShape }, backend });
        }
        toDispose.forEach(t => backend.disposeData(t.dataId));
        return res;
    }

    /**
     * @license
     * Copyright 2022 Google LLC.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function all(args) {
        const { inputs, backend, attrs } = args;
        const { x } = inputs;
        const { keepDims, axis } = attrs;
        return reduce(x, axis, keepDims, 'all', backend);
    }
    const allConfig = {
        kernelName: tf.All,
        backendName: 'webgpu',
        kernelFunc: all
    };

    /**
     * @license
     * Copyright 2022 Google LLC.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function any(args) {
        const { inputs, backend, attrs } = args;
        const { x } = inputs;
        const { keepDims, axis } = attrs;
        return reduce(x, axis, keepDims, 'any', backend);
    }
    const anyConfig = {
        kernelName: tf.Any,
        backendName: 'webgpu',
        kernelFunc: any
    };

    /**
     * @license
     * Copyright 2019 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    class ArgMinMaxProgram {
        constructor(inputShape, axis, reduceType) {
            this.workgroupSize = [64, 1, 1];
            this.variableNames = ['x'];
            this.uniforms = 'infinityValue : f32,';
            this.size = true;
            const axes = [axis];
            this.op = reduceType === 'min' ? '<' : '>';
            // |outShape| is the shape with the removed axis
            const [outputShape, reduceShape] = tf.backend_util.computeOutAndReduceShapes(inputShape, axes);
            this.outputShape = outputShape.length === 0 ? [1] : outputShape;
            this.dispatchLayout = flatDispatchLayout(this.outputShape);
            // The shared algorithm is mainly used for large reduce size. It fully
            // utilizes the threads in one workgroup to do the reduction. However,
            // when the reduce size is very small or the output shape is too large. It's
            // better to use the plain algorithm to reduce the number of workgroups to
            // speedup. The threthold can be further tuned.
            if (tf.util.sizeFromShape(reduceShape) < 32 ||
                tf.util.sizeFromShape(outputShape) > 1000) {
                this.type = 'plain';
                this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
            }
            else {
                this.type = 'shared';
                // A work group only outputs a data, so we transfer [1, 1, 1] to compute
                // dispatch size.
                this.dispatch =
                    computeDispatch(this.dispatchLayout, this.outputShape, [1, 1, 1]);
            }
            this.inputShape = inputShape;
            this.shaderKey = `argMinMax_${this.op}_${this.type}`;
        }
        getUserCode() {
            const workgroupSizeX = this.workgroupSize[0];
            const getInputShapeLastDim = () => {
                if (this.inputShape.length === 1) {
                    return 'uniforms.xShape';
                }
                else {
                    return `uniforms.xShape.${getCoordsXYZ(this.inputShape.length - 1)}`;
                }
            };
            const splitOutputCoords = () => {
                let snippet = '';
                if (this.outputShape.length === 1) {
                    if (this.inputShape.length !== 1) {
                        snippet += 'outputCoords,';
                    }
                }
                else {
                    for (let i = 0; i < this.outputShape.length; i++) {
                        snippet += `outputCoords.${getCoordsXYZ(i)},`;
                    }
                }
                return snippet;
            };
            if (this.type === 'shared') {
                const sharedMemorySnippet = `
      var<workgroup> xBestIndices : array<i32, ${workgroupSizeX}>;
      var<workgroup> xBestValues : array<f32, ${workgroupSizeX}>;
    `;
                const userCode = `
      fn DIV_CEIL(a : u32, b : u32) -> u32 {
        return ((a - 1u) / b + 1u);
      }

      ${sharedMemorySnippet}

      ${getMainHeaderString('index')} {
        let outputIndex = index / ${workgroupSizeX};
        let reduceLength = ${getInputShapeLastDim()};

        var bestIndex = i32(localId.x);
        var bestValue = uniforms.infinityValue;
        let outputCoords = getCoordsFromIndex(outputIndex);
        for (var k = i32(localId.x); k < reduceLength && outputIndex < uniforms.size;
            k = k + ${workgroupSizeX}) {
          let candidate = getX(${splitOutputCoords()} k);
          if (!isnan(candidate) && candidate ${this.op} bestValue) {
            bestValue = candidate;
            bestIndex = k;
          }
        }
        xBestValues[localId.x] = bestValue;
        xBestIndices[localId.x] = bestIndex;
        workgroupBarrier();

        var reduceSize = min(u32(reduceLength), ${workgroupSizeX}u);
        for (var currentSize = reduceSize / 2u; reduceSize > 1u;
            currentSize = reduceSize / 2u) {
          let interval = DIV_CEIL(reduceSize, 2u);
          if (localId.x < currentSize) {
            let candidate = xBestValues[localId.x + interval];
            if (candidate ${this.op} bestValue) {
              bestValue = candidate;
              xBestValues[localId.x] = bestValue;
              xBestIndices[localId.x] = xBestIndices[localId.x + interval];
            }
          }
          reduceSize = interval;
          workgroupBarrier();
        }

        if (localId.x == 0u && outputIndex < uniforms.size) {
          setOutputAtIndexI32(outputIndex, xBestIndices[localId.x]);
        }
      }
    `;
                return userCode;
            }
            else {
                const userCode = `
      ${getMainHeaderString('index')} {
        if (index < uniforms.size) {
          let outputCoords = getCoordsFromIndex(index);
          var bestIndex = 0;
          var bestValue = getX(${splitOutputCoords()} 0);
          let reduceLength = ${getInputShapeLastDim()};
          for (var i = 1; i < reduceLength; i++) {
            let candidate = getX(${splitOutputCoords()} i);
            if (candidate ${this.op} bestValue) {
              bestValue = candidate;
              bestIndex = i;
            }
          }
          setOutputAtIndexI32(index, bestIndex);
        }
      }
      `;
                return userCode;
            }
        }
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function argMax(args) {
        const { inputs, backend, attrs } = args;
        const { x } = inputs;
        const { axis } = attrs;
        let axes = tf.util.parseAxisParam(axis, x.shape);
        const permutedAxes = tf.backend_util.getAxesPermutation(axes, x.shape.length);
        let $x = x;
        const intermediateTensorInfos = [];
        if (permutedAxes != null) {
            $x = transpose({ inputs: { x }, backend, attrs: { perm: permutedAxes } });
            intermediateTensorInfos.push($x);
            axes = tf.backend_util.getInnerMostAxes(axes.length, $x.shape.length);
        }
        tf.backend_util.assertAxesAreInnerMostDims('argMax', [axes[0]], $x.shape.length);
        const program = new ArgMinMaxProgram($x.shape, axes[0], 'max');
        const uniformData = [{ type: 'float32', data: [Number.NEGATIVE_INFINITY] }];
        const out = backend.runWebGPUProgram(program, [$x], 'int32', uniformData);
        intermediateTensorInfos.forEach(t => backend.disposeData(t.dataId));
        return out;
    }
    const argMaxConfig = {
        kernelName: tf.ArgMax,
        backendName: 'webgpu',
        kernelFunc: argMax
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function argMin(args) {
        const { inputs, backend, attrs } = args;
        const { x } = inputs;
        const { axis } = attrs;
        let axes = tf.util.parseAxisParam(axis, x.shape);
        const permutedAxes = tf.backend_util.getAxesPermutation(axes, x.shape.length);
        let $x = x;
        const intermediateTensorInfos = [];
        if (permutedAxes != null) {
            $x = transpose({ inputs: { x }, backend, attrs: { perm: permutedAxes } });
            intermediateTensorInfos.push($x);
            axes = tf.backend_util.getInnerMostAxes(axes.length, $x.shape.length);
        }
        tf.backend_util.assertAxesAreInnerMostDims('argMin', [axes[0]], $x.shape.length);
        const program = new ArgMinMaxProgram($x.shape, axes[0], 'min');
        const uniformData = [{ type: 'float32', data: [Number.POSITIVE_INFINITY] }];
        const out = backend.runWebGPUProgram(program, [$x], 'int32', uniformData);
        intermediateTensorInfos.forEach(t => backend.disposeData(t.dataId));
        return out;
    }
    const argMinConfig = {
        kernelName: tf.ArgMin,
        backendName: 'webgpu',
        kernelFunc: argMin
    };

    /**
     * @license
     * Copyright 2022 Google LLC.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const asin = unaryKernelFunc({ opType: UnaryOpType.ASIN });
    const asinConfig = {
        kernelName: tf.Asin,
        backendName: 'webgpu',
        kernelFunc: asin
    };

    /**
     * @license
     * Copyright 2022 Google LLC.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const asinh = unaryKernelFunc({ opType: UnaryOpType.ASINH });
    const asinhConfig = {
        kernelName: tf.Asinh,
        backendName: 'webgpu',
        kernelFunc: asinh
    };

    /**
     * @license
     * Copyright 2022 Google LLC.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const atan = unaryKernelFunc({ opType: UnaryOpType.ATAN });
    const atanConfig = {
        kernelName: tf.Atan,
        backendName: 'webgpu',
        kernelFunc: atan
    };

    /**
     * @license
     * Copyright 2022 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const atan2 = binaryKernelFunc({ opType: BinaryOpType.ATAN2 });
    const atan2Config = {
        kernelName: tf.Atan2,
        backendName: 'webgpu',
        kernelFunc: atan2
    };

    /**
     * @license
     * Copyright 2022 Google LLC.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const atanh = unaryKernelFunc({ opType: UnaryOpType.ATANH });
    const atanhConfig = {
        kernelName: tf.Atanh,
        backendName: 'webgpu',
        kernelFunc: atanh
    };

    /**
     * @license
     * Copyright 2019 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    class Pool2DProgram {
        constructor(convInfo, poolType) {
            this.variableNames = ['x'];
            this.uniforms = `stride : vec2<i32>, pad : vec2<i32>, dilation : vec2<i32>, convDims : vec2<i32>, filterDims : vec2<i32>,`;
            // TODO(jiajia.qin@intel.com): Dynamically choose different workgroupSize for
            // different output shapes.
            this.workgroupSize = [128, 1, 1];
            this.size = true;
            this.outputShape = convInfo.outShape;
            this.dispatchLayout = flatDispatchLayout(this.outputShape);
            this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
            this.shaderKey = `pool2D_${poolType}`;
            this.poolType = poolType;
        }
        getUserCode() {
            let updateSnippet = `resultValue = max(value, resultValue);`;
            if (this.poolType === 'avg') {
                updateSnippet = `resultValue = resultValue + value; count = count + 1.0;`;
            }
            let returnValue = `resultValue`;
            if (this.poolType === 'avg') {
                returnValue = `resultValue / max(count, 1.0)`;
            }
            const userCode = `
      ${getMainHeaderString('index')} {
      if (index < uniforms.size) {
        let coords = getCoordsFromIndex(index);
          let batch = coords[0];
          let xRCCorner = vec2<i32>(coords.yz) * uniforms.stride - uniforms.pad;
          let xRCorner = xRCCorner.x;
          let xCCorner = xRCCorner.y;

          var resultValue = ${this.poolType === 'avg' ? '0.0' : '-1.0 / pow(10.0, -20.0)'};
          var count = 0.0;

          for (var wR = 0; wR < uniforms.filterDims.x; wR = wR + uniforms.dilation.x) {
            let xR = xRCorner + wR;

            if (xR < 0 || xR >= uniforms.convDims.x) {
              continue;
            }

            for (var wC = 0; wC < uniforms.filterDims.y; wC = wC + uniforms.dilation.y) {
              let xC = xCCorner + wC;
              if (xC < 0 || xC >= uniforms.convDims.y) {
                continue;
              }

              let value = getX(batch, xR, xC, coords[3]);
              ${updateSnippet}
            }
          }

          setOutputAtIndex(index, ${returnValue});
        }
      }
    `;
            return userCode;
        }
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    class PoolWithFilterSizeEqualsOneProgram {
        constructor(convInfo) {
            this.variableNames = ['x'];
            this.uniforms = `stride : vec2<i32>,`;
            this.workgroupSize = [256, 1, 1];
            this.size = true;
            this.outputShape = convInfo.outShape;
            this.dispatchLayout = flatDispatchLayout(this.outputShape);
            this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
            this.shaderKey = 'poolWithFilterSizeEqualsOne';
        }
        getUserCode() {
            const userCode = `
      ${getMainHeaderString('index')} {
        if (index < uniforms.size) {
          let coords = getCoordsFromIndex(index);
          let batch = coords[0];
          let d = coords[3];

          let xRCCorner = coords.yz * uniforms.stride;
          let xRCorner = xRCCorner.x;
          let xCCorner = xRCCorner.y;

          let value = getX(batch, xRCorner, xCCorner, d);
          setOutputAtIndex(index, value);
        }
      }
    `;
            return userCode;
        }
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function max(args) {
        const { inputs, backend, attrs } = args;
        const { x } = inputs;
        const { reductionIndices, keepDims } = attrs;
        return reduce(x, reductionIndices, keepDims, 'max', backend);
    }
    const maxConfig = {
        kernelName: tf.Max,
        backendName: 'webgpu',
        kernelFunc: max
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function mean(args) {
        const { inputs, backend, attrs } = args;
        const { x } = inputs;
        const { keepDims, axis } = attrs;
        return reduce(x, axis, keepDims, 'mean', backend);
    }
    const meanConfig = {
        kernelName: tf.Mean,
        backendName: 'webgpu',
        kernelFunc: mean
    };

    /**
     * @license
     * Copyright 2022 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function poolImpl(x, convInfo, poolType, backend) {
        if (convInfo.filterWidth === 1 && convInfo.filterHeight === 1 &&
            tf.util.arraysEqual(convInfo.inShape, convInfo.outShape)) {
            return identity({ inputs: { x }, backend });
        }
        if (convInfo.filterWidth === convInfo.inWidth &&
            convInfo.filterHeight === convInfo.inHeight && convInfo.batchSize === 1 &&
            convInfo.padInfo.type === 'VALID') {
            const length = x.shape.length;
            const reshapeX = reshape({
                inputs: { x },
                backend,
                attrs: {
                    shape: [
                        x.shape[length - 3] * x.shape[length - 2] /* height * width */,
                        x.shape[length - 1] /* channel */
                    ]
                }
            });
            let reduceX;
            if (poolType === 'avg') {
                reduceX = mean({ inputs: { x: reshapeX }, backend, attrs: { axis: 0, keepDims: false } });
            }
            else {
                tf.util.assert(poolType === 'max', () => `Invalid pool type ${poolType}`);
                reduceX = max({
                    inputs: { x: reshapeX },
                    backend,
                    attrs: { reductionIndices: 0, keepDims: false }
                });
            }
            const result = reshape({ inputs: { x: reduceX }, backend, attrs: { shape: convInfo.outShape } });
            backend.disposeData(reshapeX.dataId);
            backend.disposeData(reduceX.dataId);
            return result;
        }
        let program;
        const dimensions = [{ type: 'int32', data: [convInfo.strideHeight, convInfo.strideWidth] }];
        if (convInfo.filterHeight === 1 && convInfo.filterWidth === 1) {
            program = new PoolWithFilterSizeEqualsOneProgram(convInfo);
        }
        else {
            if (poolType === 'avg') {
                program = new Pool2DProgram(convInfo, 'avg');
            }
            else {
                tf.util.assert(poolType === 'max', () => `Invalid pool type ${poolType}`);
                program = new Pool2DProgram(convInfo, 'max');
            }
            dimensions.push({ type: 'int32', data: [convInfo.padInfo.top, convInfo.padInfo.left] }, {
                type: 'int32',
                data: [convInfo.dilationHeight, convInfo.dilationWidth]
            }, { type: 'int32', data: [convInfo.inHeight, convInfo.inWidth] }, {
                type: 'int32',
                data: [convInfo.effectiveFilterHeight, convInfo.effectiveFilterWidth]
            });
        }
        return backend.runWebGPUProgram(program, [x], x.dtype, dimensions);
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function avgPool(args) {
        const { inputs, backend, attrs } = args;
        const { x } = inputs;
        const { filterSize, strides, pad, dimRoundingMode } = attrs;
        const dilations = 1;
        const convInfo = tf.backend_util.computePool2DInfo(x.shape, filterSize, strides, dilations, pad, dimRoundingMode);
        return poolImpl(x, convInfo, 'avg', backend);
    }
    const avgPoolConfig = {
        kernelName: tf.AvgPool,
        backendName: 'webgpu',
        kernelFunc: avgPool
    };

    /**
     * @license
     * Copyright 2022 Google LLC.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    class AvgPool2DBackpropProgram {
        constructor(convInfo) {
            this.variableNames = ['dy'];
            this.uniforms = `stride : vec2<i32>, pads : vec2<i32>, dilation : vec2<i32>, filterDims : vec2<i32>,
       outHeight : i32, outWidth : i32, avgMultiplier : f32,`;
            this.workgroupSize = [64, 1, 1];
            this.size = true;
            this.outputShape = convInfo.inShape;
            this.dispatchLayout = flatDispatchLayout(this.outputShape);
            this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
            this.shaderKey = `avg_pool2d_backprop`;
        }
        getUserCode() {
            const userCode = `
      ${getMainHeaderString('index')} {
      if (index < uniforms.size) {
        let coords = getCoordsFromIndex(index);
        let batch = coords[0];
        let d = coords[3];

        let dyRCCorner = vec2<i32>(coords.yz) - uniforms.pads;
        let dyRCorner = dyRCCorner.x;
        let dyCCorner = dyRCCorner.y;

        // Convolve dy(?, ?, d) with pos mask(:, :, d) to get dx(xR, xC, d).
        // ? = to be determined. : = across all values in that axis.
        var dotProd = 0.0;
        for (var wR = 0; wR < uniforms.filterDims[0]; wR = wR + uniforms.dilation[0]) {
          let dyR = f32(dyRCorner + wR) / f32(uniforms.stride[0]);

          if (dyR < 0.0 || dyR >= f32(uniforms.outHeight) || fract(dyR) > 0.0) {
            continue;
          }
          let idyR = i32(dyR);

          for (var wC = 0; wC < uniforms.filterDims[1]; wC = wC + uniforms.dilation[1]) {
            let dyC = f32(dyCCorner + wC) / f32(uniforms.stride[1]);

            if (dyC < 0.0 || dyC >= f32(uniforms.outWidth) || fract(dyC) > 0.0) {
              continue;
            }
            let idyC = i32(dyC);

            let dyValue = getDy(batch, idyR, idyC, d);

            dotProd = dotProd + dyValue * uniforms.avgMultiplier;
          }
        }
        setOutputAtIndex(index, dotProd);
      }
    }
    `;
            return userCode;
        }
    }

    /**
     * @license
     * Copyright 2022 Google LLC.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function avgPoolGrad(args) {
        const { inputs, backend, attrs } = args;
        const { dy, input } = inputs;
        const x = input;
        assertNotComplex([dy, input], 'avgPoolGrad');
        const { filterSize, strides, pad } = attrs;
        const convInfo = tf.backend_util.computePool2DInfo(x.shape, filterSize, strides, 1 /* dilations */, pad);
        const program = new AvgPool2DBackpropProgram(convInfo);
        const avgMultiplier = 1 / (convInfo.filterHeight * convInfo.filterWidth);
        const uniformData = [
            { type: 'int32', data: [convInfo.strideHeight, convInfo.strideWidth] }, {
                type: 'int32',
                data: [
                    convInfo.effectiveFilterHeight - 1 - convInfo.padInfo.top,
                    convInfo.effectiveFilterWidth - 1 - convInfo.padInfo.left
                ]
            },
            { type: 'int32', data: [convInfo.dilationHeight, convInfo.dilationWidth] }, {
                type: 'int32',
                data: [convInfo.effectiveFilterHeight, convInfo.effectiveFilterWidth]
            },
            { type: 'int32', data: [convInfo.outHeight] },
            { type: 'int32', data: [convInfo.outWidth] },
            { type: 'float32', data: [avgMultiplier] }
        ];
        return backend.runWebGPUProgram(program, [dy], x.dtype, uniformData);
    }
    const avgPoolGradConfig = {
        kernelName: tf.AvgPoolGrad,
        backendName: 'webgpu',
        kernelFunc: avgPoolGrad
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function batchMatMul(args) {
        const { inputs, backend, attrs } = args;
        const { a, b } = inputs;
        const { transposeA, transposeB } = attrs;
        return batchMatMulImpl({ a, b, transposeA, transposeB, backend });
    }
    const batchMatMulConfig = {
        kernelName: tf.BatchMatMul,
        backendName: 'webgpu',
        kernelFunc: batchMatMul,
    };

    /**
     * @license
     * Copyright 2019 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    class SliceProgram {
        constructor(start, destSize) {
            this.variableNames = ['source'];
            this.workPerThread = 1;
            this.workgroupSize = [64, 1, 1];
            this.size = true;
            this.outputShape = destSize;
            this.rank = destSize.length;
            this.dispatchLayout = flatDispatchLayout(this.outputShape);
            this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize, [this.workPerThread, 1, 1]);
            this.start = start;
            this.uniforms = `start : ${getCoordsDataType(start.length)}, `;
            this.shaderKey = 'slice';
        }
        getUserCode() {
            const dtype = getCoordsDataType(this.rank);
            const sourceCoords = getCoords(this.rank);
            let coordSum;
            if (this.start.length === 1) {
                coordSum = this.outputShape.map((_, i) => {
                    return `sourceLoc = uniforms.start + coords;`;
                });
            }
            else {
                coordSum = this.outputShape.map((_, i) => {
                    return `sourceLoc.${coords[i]} = uniforms.start.${getCoordsXYZ(i)} + coords.${coords[i]};`;
                });
            }
            const userCode = `
      ${getMainHeaderString('index')} {
        if (index < uniforms.size) {
          var sourceLoc : ${dtype};
          let coords = getCoordsFromIndex(index);
          ${coordSum.join('\n')}
          setOutputAtIndex(index, getSource(${sourceCoords}));
        }
      }
    `;
            return userCode;
        }
    }
    const coords = ['x', 'y', 'z', 'w', 'u', 'v'];
    function getCoords(rank) {
        if (rank === 1) {
            return 'sourceLoc';
        }
        else if (rank <= 6) {
            return coords.slice(0, rank).map(coord => `sourceLoc.${coord}`).join(',');
        }
        else {
            throw Error(`Slicing for rank ${rank} is not yet supported`);
        }
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function slice(args) {
        const { inputs, backend, attrs } = args;
        const { x } = inputs;
        const { begin, size } = attrs;
        const [$begin, $size] = tf.slice_util.parseSliceParams(x, begin, size);
        tf.slice_util.assertParamsValid(x, $begin, $size);
        if (backend.shouldExecuteOnCPU([x]) || x.dtype === 'string') {
            const xBufferInfo = backend.tensorMap.get(x.dataId);
            const outValues = sliceImplCPU(xBufferInfo.values, $begin, $size, x.shape, x.dtype);
            return backend.makeTensorInfo($size, x.dtype, outValues);
        }
        if (tf.util.sizeFromShape($size) === 0) {
            return backend.makeTensorInfo($size, x.dtype, []);
        }
        // TODO(xing.xu): Add shadow slice support.
        const program = new SliceProgram($begin, $size);
        const uniformData = [{ type: 'int32', data: $begin }];
        return backend.runWebGPUProgram(program, [x], x.dtype, uniformData);
    }
    const sliceConfig = {
        kernelName: tf.Slice,
        backendName: 'webgpu',
        kernelFunc: slice
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const batchToSpaceND = (args) => {
        const { inputs, backend, attrs } = args;
        const { x } = inputs;
        const { blockShape, crops } = attrs;
        tf.util.assert(x.shape.length <= 4, () => 'batchToSpaceND for rank > 4 with a WebGPU backend not ' +
            'implemented yet');
        const prod = blockShape.reduce((a, b) => a * b);
        const reshaped = tf.backend_util.getReshaped(x.shape, blockShape, prod);
        const permuted = tf.backend_util.getPermuted(reshaped.length, blockShape.length);
        const reshapedPermuted = tf.backend_util.getReshapedPermuted(x.shape, blockShape, prod);
        const sliceBeginCoords = tf.backend_util.getSliceBeginCoords(crops, blockShape.length);
        const sliceSize = tf.backend_util.getSliceSize(reshapedPermuted, crops, blockShape.length);
        const toDispose = [];
        const reshapedIntermediate = reshape({ inputs: { x }, backend, attrs: { shape: reshaped } });
        const transposedIntermediate = transpose({ inputs: { x: reshapedIntermediate }, backend, attrs: { perm: permuted } });
        const reshapedIntermediate2 = reshape({
            inputs: { x: transposedIntermediate },
            backend,
            attrs: { shape: reshapedPermuted }
        });
        const sliced = slice({
            inputs: { x: reshapedIntermediate2 },
            backend,
            attrs: { begin: sliceBeginCoords, size: sliceSize }
        });
        toDispose.push(reshapedIntermediate);
        toDispose.push(transposedIntermediate);
        toDispose.push(reshapedIntermediate2);
        toDispose.forEach(t => backend.disposeData(t.dataId));
        return sliced;
    };
    const batchToSpaceNDConfig = {
        kernelName: tf.BatchToSpaceND,
        backendName: 'webgpu',
        kernelFunc: batchToSpaceND
    };

    /**
     * @license
     * Copyright 2022 Google LLC.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const writeSnippet = `
  fn bincount_write(index: i32, value: f32) {
    ${atomicAddSnippet('&result[index]', 'value', 'float32')}
  }
`;
    const binaryWriteSnippet = `
  fn bincount_write(index: i32, value: f32) {
    atomicStore(&result[index], bitcast<i32>(value));
  }
`;
    class BincountProgram {
        constructor(shape, hasWeights, binaryOutput = false) {
            this.outputShape = [];
            this.variableNames = ['x'];
            this.uniforms = 'binCountSize : i32,';
            this.workgroupSize = [64, 1, 1];
            this.atomic = true;
            this.hasWeights = true;
            this.binaryOutput = false;
            this.outputShape = shape;
            this.rank = shape.length;
            this.dispatchLayout = flatDispatchLayout(this.outputShape);
            this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
            this.binaryOutput = binaryOutput;
            if (binaryOutput) {
                this.atomic = false;
            }
            this.hasWeights = hasWeights;
            if (this.hasWeights) {
                this.variableNames.push('w');
            }
            this.shaderKey =
                `bincount_${this.hasWeights}_${this.binaryOutput}_${this.rank}`;
        }
        getUserCode() {
            const userCode = `
    ${this.binaryOutput ? binaryWriteSnippet : writeSnippet}
  ${getMainHeaderString('index')} {
    ${this.rank === 1 ?
            `if (index < uniforms.xShape) {
      let indexVal = i32(getX(index));
      if (indexVal < uniforms.binCountSize) {
        let value = ${this.binaryOutput ? 1. :
                (this.hasWeights ? 'getW(index)' : '1.')};
        bincount_write(indexVal, value);
      }
    }` :
            `let coord = getCoordsFromIndex(index);
    if (coordsInBounds2D(coord, uniforms.xShape)) {
      let indexVal = i32(getX(coord[0], coord[1]));
      if (indexVal < uniforms.binCountSize) {
        let value = ${this.binaryOutput ?
                1. :
                (this.hasWeights ? 'getW(coord[0], coord[1])' : '1.')};
        bincount_write(coord.x * uniforms.binCountSize + indexVal, value);
      }
    }`}
  }
  `;
            return userCode;
        }
    }

    /**
     * @license
     * Copyright 2022 Google LLC.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function bincount(args) {
        const { inputs, backend, attrs } = args;
        const { x, weights } = inputs;
        const { size } = attrs;
        const xSize = tf.util.sizeFromShape(x.shape);
        const weightsSize = tf.util.sizeFromShape(weights.shape);
        const hasWeights = weightsSize > 0;
        const outputSize = [size];
        const dtype = weights.dtype;
        const output = fill({ backend, attrs: { shape: outputSize, value: 0, dtype } });
        const program = new BincountProgram([xSize], hasWeights);
        const uniformData = [{ type: 'int32', data: [size] }];
        const bincountInputs = hasWeights ? [x, weights] : [x];
        const res = backend.runWebGPUProgram(program, bincountInputs, dtype, uniformData, output);
        return res;
    }
    const bincountConfig = {
        kernelName: tf.Bincount,
        backendName: 'webgpu',
        kernelFunc: bincount
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const notEqual = binaryKernelFunc({
        opType: BinaryOpType.NOT_EQUAL,
        dtype: 'bool',
        cpuKernelImpl: notEqualImplCPU
    });
    const notEqualConfig = {
        kernelName: tf.NotEqual,
        backendName: 'webgpu',
        kernelFunc: notEqual
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function real(args) {
        const { inputs, backend } = args;
        const { input } = inputs;
        const inputData = backend.tensorMap.get(input.dataId);
        return identity({ inputs: { x: inputData.complexTensorInfos.real }, backend });
    }
    const realConfig = {
        kernelName: tf.Real,
        backendName: 'webgpu',
        kernelFunc: real
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function int(input, backend) {
        const program = new UnaryOpProgram(input.shape, UnaryOpType.TO_INT);
        const output = backend.runWebGPUProgram(program, [input], 'int32');
        return { dataId: output.dataId, shape: output.shape, dtype: output.dtype };
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function cast(args) {
        const { inputs, backend, attrs } = args;
        const { x } = inputs;
        const { dtype } = attrs;
        // Casting to complex64.
        if (dtype === 'complex64') {
            if (x.dtype === 'complex64') {
                return identity({ inputs: { x }, backend });
            }
            // TODO: Import kernel function once zeros is modularized.
            const zerosTensor = tf.zeros(x.shape);
            const floatX = cast({ inputs: { x }, backend, attrs: { dtype: 'float32' } });
            const result = complex({ inputs: { real: floatX, imag: zerosTensor }, backend });
            zerosTensor.dispose();
            backend.disposeData(floatX.dataId);
            return result;
        }
        // Casting from complex64
        if (x.dtype === 'complex64') {
            const realPart = real({ inputs: { input: x }, backend });
            const result = cast({ inputs: { x: realPart }, backend, attrs: { dtype } });
            backend.disposeData(realPart.dataId);
            return result;
        }
        if (!tf.util.hasEncodingLoss(x.dtype, dtype)) {
            // We don't change the underlying data, since we cast to higher
            // precision.
            const result = identity({ inputs: { x }, backend });
            return { dataId: result.dataId, shape: result.shape, dtype };
        }
        if (backend.shouldExecuteOnCPU([x])) {
            const values = backend.tensorMap.get(x.dataId).values;
            const [resultShape, resultType, resultData] = castImplCPU(values, x.shape, x.dtype, dtype);
            return backend.makeTensorInfo(resultShape, resultType, resultData);
        }
        if (dtype === 'int32') {
            return int(x, backend);
        }
        if (dtype === 'bool') {
            const zerosTensorInfo = backend.makeTensorInfo([], 'bool', tf.util.getTypedArrayFromDType('bool', 1));
            const binaryInputs = { a: x, b: zerosTensorInfo };
            const result = notEqual({ inputs: binaryInputs, backend });
            backend.disposeData(zerosTensorInfo.dataId);
            return result;
        }
        throw new Error(`Error in Cast: failed to cast ${x.dtype} to ${dtype}`);
    }
    const castConfig = {
        kernelName: tf.Cast,
        backendName: 'webgpu',
        kernelFunc: cast
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const ceil = unaryKernelFunc({ opType: UnaryOpType.CEIL, cpuKernelImpl: ceilImplCPU });
    const ceilConfig = {
        kernelName: tf.Ceil,
        backendName: 'webgpu',
        kernelFunc: ceil
    };

    /**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    class ClipVec4Program {
        constructor(outputShape) {
            this.variableNames = ['A'];
            this.uniforms = 'minVal : f32, maxVal : f32,';
            this.workPerThread = 4;
            this.workgroupSize = [64, 1, 1];
            this.isVec4 = true;
            this.size = true;
            this.outputShape = outputShape;
            this.dispatchLayout = flatDispatchLayout(this.outputShape);
            this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize, [this.workPerThread, 1, 1]);
            this.shaderKey = 'clipVec4';
        }
        getUserCode() {
            const userCode = `
      ${getMainHeaderString('index')} {
        if(index < uniforms.size) {
          let value = getAByOutputIndex(index);
          var clampedValue = clamp(
              value, vec4<f32>(uniforms.minVal), vec4<f32>(uniforms.maxVal));
          clampedValue = select(clampedValue, value, isnanVec4(value));
          setOutputAtIndex(index, clampedValue);
        }
      }
    `;
            return userCode;
        }
    }

    /**
     * @license
     * Copyright 2019 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    class ClipProgram {
        constructor(outputShape) {
            this.variableNames = ['A'];
            this.uniforms = 'minVal : f32, maxVal : f32,';
            this.workgroupSize = [64, 1, 1];
            this.size = true;
            this.outputShape = outputShape;
            this.dispatchLayout = flatDispatchLayout(this.outputShape);
            this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
            this.shaderKey = 'clip';
        }
        getUserCode() {
            const userCode = `
      ${getMainHeaderString('index')} {
        if(index < uniforms.size) {
          let value = getAByOutputIndex(index);
          if (isnan(value)) {
            setOutputAtIndex(index, value);
            return;
          }
          setOutputAtIndex(index, clamp(value, uniforms.minVal, uniforms.maxVal));
        }
      }
    `;
            return userCode;
        }
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function clipByValue(args) {
        const { inputs, backend, attrs } = args;
        const { x } = inputs;
        const { clipValueMin, clipValueMax } = attrs;
        let program;
        const uniformData = [
            { type: 'float32', data: [clipValueMin] },
            { type: 'float32', data: [clipValueMax] }
        ];
        if (tf.util.sizeFromShape(x.shape) % 4 === 0) {
            program = new ClipVec4Program(x.shape);
        }
        else {
            program = new ClipProgram(x.shape);
        }
        return backend.runWebGPUProgram(program, [x], x.dtype, uniformData);
    }
    const clipByValueConfig = {
        kernelName: tf.ClipByValue,
        backendName: 'webgpu',
        kernelFunc: clipByValue
    };

    /**
     * @license
     * Copyright 2019 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    class ConcatProgram {
        constructor(shapes) {
            this.uniforms = '';
            this.workPerThread = 1;
            this.workgroupSize = [64, 1, 1];
            this.size = true;
            this.outputShape =
                tf.backend_util.computeOutShape(shapes, 1 /* axis */);
            this.variableNames = shapes.map((_, i) => `T${i}`);
            this.dispatchLayout = flatDispatchLayout(this.outputShape);
            this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize, [this.workPerThread, 1, 1]);
            this.offsetLength = shapes.length - 1;
            for (let i = 0; i < this.offsetLength; i++) {
                this.uniforms += `offset${i} : i32,`;
            }
            this.shaderKey = 'concat';
        }
        getUserCode() {
            const snippets = [];
            if (this.offsetLength > 0) {
                snippets.push(`if (yC < uniforms.offset0){ setOutputAtCoords(coords.x, coords.y, getT0(yR, yC)); }`);
                for (let i = 1; i < this.offsetLength; i++) {
                    snippets.push(`else if (yC < uniforms.offset${[i]}){ ` +
                        `setOutputAtCoords(coords.x, coords.y, getT${i}(yR, yC - uniforms.offset${i - 1})); }`);
                }
                const lastIndex = this.offsetLength;
                const lastShiftIndex = this.offsetLength - 1;
                snippets.push(`else { setOutputAtCoords(coords.x, coords.y, getT${lastIndex}(yR, yC - uniforms.offset${lastShiftIndex})); }`);
            }
            else {
                snippets.push(`setOutputAtCoords(coords.x, coords.y, getT0(yR, yC));`);
            }
            const userCode = `
      ${getMainHeaderString('index')} {
        for(var i = 0; i < ${this.workPerThread}; i = i + 1) {
          let flatIndex = index * ${this.workPerThread} + i;
          if(flatIndex < uniforms.size) {
            let coords = getCoordsFromIndex(flatIndex);
            let yR = coords.x;
            let yC = coords.y;

            ${snippets.join('\n        ')}
          }
        }
      }
    `;
            return userCode;
        }
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function imag(args) {
        const { inputs, backend } = args;
        const { input } = inputs;
        const inputData = backend.tensorMap.get(input.dataId);
        return identity({ inputs: { x: inputData.complexTensorInfos.imag }, backend });
    }
    const imagConfig = {
        kernelName: tf.Imag,
        backendName: 'webgpu',
        kernelFunc: imag
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function concatImpl$1(inputs, axis, backend) {
        const dtype = inputs[0].dtype;
        if (dtype === 'complex64') {
            const reals = inputs.map((t) => real({ inputs: { input: t }, backend }));
            const imags = inputs.map((t) => imag({ inputs: { input: t }, backend }));
            const realConcated = concatImpl$1(reals, axis, backend);
            const imagConcated = concatImpl$1(imags, axis, backend);
            const result = complex({ inputs: { real: realConcated, imag: imagConcated }, backend });
            reals.forEach(r => backend.disposeData(r.dataId));
            imags.forEach(i => backend.disposeData(i.dataId));
            backend.disposeData(realConcated.dataId);
            backend.disposeData(imagConcated.dataId);
            return result;
        }
        let runOnCpu = backend.shouldExecuteOnCPU(inputs);
        // Run on cpu if dtype is string. For string, the backend represents it
        // as Uint8Array[], where each Uint8Array is a character. Given that the
        // computation is only on the outer array, uploading the whole data onto
        // gpu is wasteful. Also, currently webgpu doesn't have a design to
        // upload and retrieve Uint8Array[] between cpu and gpu. Therefore, we
        // just run the kernel on cpu if dtype is string.
        if (dtype === 'string') {
            runOnCpu = true;
        }
        if (runOnCpu) {
            // Any concat of n-dimensional tensors across any axis can be reduced to
            // a concatenation of two-dimensional tensors across the axis 1 by first
            // partitioning the axes of the original tensors into those less than the
            // axis to be concatenated and the rest. Then reshape the tensors
            // into a two-dimensional tensor by collapsing these two sets of axes and
            // concatenate the resulting matrices across the axis 1, finally reshaping
            // the result to have the proper shape.
            const tensors2D = inputs.map(t => {
                const innerSize = tf.util.sizeFromShape(t.shape.slice(axis));
                const shape = [-1, innerSize];
                return reshape({ inputs: { x: t }, backend, attrs: { shape } });
            });
            const inputsValShapes = tensors2D.map(t => {
                return { vals: backend.readSync(t.dataId), shape: t.shape };
            });
            // Concats 2d tensors along axis=1.
            const outShape = tf.backend_util.computeOutShape(tensors2D.map(t => t.shape), 1 /* axis */);
            const simplyConcat = tensors2D[0].shape[0] === 1;
            const outVals = concatImplCPU(inputsValShapes, outShape, dtype, simplyConcat);
            const finalOutShape = tf.backend_util.computeOutShape(inputs.map(t => t.shape), axis);
            const outInfo = backend.makeTensorInfo(finalOutShape, dtype, outVals);
            tensors2D.forEach(t => backend.disposeData(t.dataId));
            return outInfo;
        }
        // There is a storage buffer limitation in compute stage, one for output so
        // the maximum for input is limits.maxStorageBuffersPerShaderStage - 1
        const maxInputNum = backend.device.limits.maxStorageBuffersPerShaderStage - 1;
        if (inputs.length > maxInputNum) {
            const reducedInputs = [];
            for (let i = 0; i < inputs.length; i += maxInputNum) {
                const subArray = inputs.slice(i, i + maxInputNum);
                reducedInputs.push(concatImpl$1(subArray, axis, backend));
            }
            const result = concatImpl$1(reducedInputs, axis, backend);
            for (const i of reducedInputs) {
                backend.disposeData(i.dataId);
            }
            return result;
        }
        const { tensors2D, outShape } = computeTensors2D(inputs, axis, backend);
        const shapes = (tensors2D).map(t => t.shape);
        const program = new ConcatProgram(shapes);
        const uniformData = [];
        const offsets = new Array(shapes.length - 1);
        if (offsets.length > 0) {
            offsets[0] = shapes[0][1];
            uniformData.push({ type: 'int32', data: [offsets[0]] });
            for (let i = 1; i < offsets.length; i++) {
                offsets[i] = offsets[i - 1] + shapes[i][1];
                uniformData.push({ type: 'int32', data: [offsets[i]] });
            }
        }
        const res = backend.runWebGPUProgram(program, tensors2D, tensors2D[0].dtype, uniformData);
        tensors2D.forEach(r => backend.disposeData(r.dataId));
        const reshapedResult = reshape({ inputs: { x: res }, backend, attrs: { shape: outShape } });
        backend.disposeData(res.dataId);
        return reshapedResult;
    }
    function computeTensors2D(inputs, axis, backend) {
        const outShape = tf.backend_util.computeOutShape(inputs.map(t => t.shape), axis);
        const tensors2D = inputs.map(t => reshape({
            inputs: { x: t },
            backend,
            attrs: {
                shape: [
                    tf.util.sizeFromShape(t.shape.slice(0, axis)),
                    tf.util.sizeFromShape(t.shape.slice(axis))
                ]
            }
        }));
        return { tensors2D, outShape };
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function concat(args) {
        const { inputs, backend, attrs } = args;
        const { axis } = attrs;
        const $axis = tf.util.parseAxisParam(axis, inputs[0].shape)[0];
        const shapes = inputs.map(t => t.shape);
        tf.backend_util.assertParamsConsistent(shapes, $axis);
        const outShape = tf.backend_util.computeOutShape(inputs.map(t => t.shape), $axis);
        if (tf.util.sizeFromShape(outShape) === 0) {
            return backend.makeTensorInfo(outShape, inputs[0].dtype, []);
        }
        // Keep only non-empty tensors (ignore tensors with 0 in their shape).
        const $inputs = inputs.filter(t => tf.util.sizeFromShape(t.shape) > 0);
        if ($inputs.length === 1) {
            return identity({ inputs: { x: $inputs[0] }, backend });
        }
        return concatImpl$1($inputs, $axis, backend);
    }
    const concatConfig = {
        kernelName: tf.Concat,
        backendName: 'webgpu',
        kernelFunc: concat
    };

    /**
     * @license
     * Copyright 2019 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function conv2dCommonSnippet(isChannelsLast, fitAOuter, fitBOuter, fitInner, addBias = false, activation = null, hasPreluActivationWeights = false, innerElementSizeX = 4, innerElementSizeW = 4, innerElementSize = 4) {
        const getXSnippet = (innerElementSize) => {
            switch (innerElementSize) {
                case 1:
                    return 'resData = x[xIndex];';
                case 3:
                    return 'resData = vec3<f32>(x[xIndex], x[xIndex + 1], x[xIndex + 2]);';
                case 4:
                    return 'resData = x[xIndex / 4];';
                default:
                    throw new Error(`innerElementSize ${innerElementSize} is not supported.`);
            }
        };
        const getWSnippet = (innerElementSize) => {
            switch (innerElementSize) {
                case 1:
                    return 'return W[row * uniforms.wShape[3] + colIn];';
                case 4:
                    return 'return W[row * uniforms.wShape[3] / 4 + colIn];';
                default:
                    throw new Error(`innerElementSize ${innerElementSize} is not supported.`);
            }
        };
        const coordASnippet = isChannelsLast ? `
      let coord = vec4<i32>(batch, xRow, xCol, xCh);
      ` :
            `
      let coord = vec4<i32>(batch, xCh, xRow, xCol);
      `;
        const coordResSnippet = isChannelsLast ? `
      let coords = vec4<i32>(
        batch,
        row / outWidth,
        row % outWidth,
        col);
      ` :
            `
      let coords = vec4<i32>(
        batch,
        row,
        col / outWidth,
        col % outWidth);
      `;
        const xHight = isChannelsLast ? 'uniforms.xShape[1]' : 'uniforms.xShape[2]';
        const xWidth = isChannelsLast ? 'uniforms.xShape[2]' : 'uniforms.xShape[3]';
        const row = isChannelsLast ? 'row' : 'col';
        const col = isChannelsLast ? 'col' : 'row';
        const readXSnippet = `
      let inChannels = uniforms.wShape[2];
      let outWidth = ${isChannelsLast ? 'uniforms.outShape[2]' : 'uniforms.outShape[3]'};
      let outRow = ${row} / outWidth;
      let outCol = ${row} % outWidth;

      let WRow = ${col} / (uniforms.filterDims[1] * inChannels);
      let WCol = ${col} / inChannels % uniforms.filterDims[1];
      let xRow = outRow * uniforms.stride[0] + uniforms.dilation[0] * WRow - uniforms.pad[0];
      let xCol = outCol * uniforms.stride[1] + uniforms.dilation[1] * WCol - uniforms.pad[1];
      let xCh = ${col} % inChannels;
      var resData = ${typeSnippet(innerElementSizeX)}(0.0);
      // The bounds checking is always needed since we use it to pad zero for
      // the 'same' padding type.
      if (xRow >= 0 && xRow < ${xHight} && xCol >= 0 && xCol < ${xWidth}) {
        ${coordASnippet}
        let xIndex = getIndexFromCoords4D(coord, uniforms.xShape);
        ${getXSnippet(innerElementSizeX)}
      }
      return resData;`;
        const sampleX = isChannelsLast ? (fitAOuter && fitInner ? `
      let col = colIn * ${innerElementSizeX};
      ${readXSnippet}` :
            `
      let col = colIn * ${innerElementSizeX};
      if (row < uniforms.dimAOuter && col < uniforms.dimInner) {
        ${readXSnippet}
      }
      return ${typeSnippet(innerElementSizeX)}(0.0);`) :
            (fitInner && fitBOuter ? `
      let col = colIn * ${innerElementSizeX};
      ${readXSnippet}` :
                `
      let col = colIn * ${innerElementSizeX};
      if (row < uniforms.dimInner && col < uniforms.dimBOuter) {
        ${readXSnippet}
      }
      return ${typeSnippet(innerElementSizeX)}(0.0);`);
        const sampleW = `${getWSnippet(innerElementSizeW)}`;
        const resType = typeSnippet(innerElementSize);
        const aType = isChannelsLast ? typeSnippet(innerElementSizeX) :
            typeSnippet(innerElementSizeW);
        const bType = isChannelsLast ? typeSnippet(innerElementSizeW) :
            typeSnippet(innerElementSizeX);
        const userCode = `
      ${activationFnSnippet(activation, hasPreluActivationWeights, innerElementSize === 4, 4)}
      fn mm_readA(batch: i32, row : i32, colIn : i32) -> ${aType} {
        ${isChannelsLast ? sampleX : sampleW}
      }

      fn mm_readB(batch: i32, row : i32, colIn : i32) -> ${bType} {
        ${isChannelsLast ? sampleW : sampleX}
      }

      fn mm_write(batch: i32, row : i32, colIn : i32, valueIn : ${resType}) {
        let col = colIn * ${innerElementSize};
        if (row < uniforms.dimAOuter && col < uniforms.dimBOuter)
        {
        var value = valueIn;
        let outWidth = ${isChannelsLast ? 'uniforms.outShape[2]' : 'uniforms.outShape[3]'};
        ${coordResSnippet}
        ${biasActivationSnippet(addBias, activation)}
        setOutputAtCoords(coords[0], coords[1], coords[2], coords[3], value);
        }
      }`;
        return userCode;
    }
    class Conv2DMMProgram {
        constructor(convInfo, dimAOuter, dimBOuter, dimInner, addBias = false, activation = null, hasPreluActivationWeights = false, sequentialAccessByThreads = false) {
            this.variableNames = ['x', 'W'];
            this.uniforms = `filterDims : vec2<i32>, pad : vec2<i32>, stride : vec2<i32>, dilation : vec2<i32>, dimAOuter : i32, dimBOuter : i32, dimInner : i32,`;
            this.outputShape = convInfo.outShape;
            this.isChannelsLast = convInfo.dataFormat === 'channelsLast';
            this.isVec4 =
                (((convInfo.inChannels % 4 === 0 || convInfo.inChannels % 3 === 0) &&
                    this.isChannelsLast) ||
                    (convInfo.outWidth % 4 === 0 && !this.isChannelsLast)) &&
                    convInfo.outChannels % 4 === 0;
            this.dispatchLayout = this.isChannelsLast ? { x: [3], y: [1, 2], z: [0] } :
                { x: [2, 3], y: [1], z: [0] };
            this.workgroupSize = computeWorkgroupSizeForConv2d(this.dispatchLayout, this.outputShape, this.isVec4);
            this.elementsPerThread = computeWorkPerThreadForConv2d(this.dispatchLayout, this.outputShape, this.isVec4);
            this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize, this.elementsPerThread);
            if (this.isVec4) {
                if (this.isChannelsLast && convInfo.inChannels % 4 !== 0) {
                    this.innerElementSize = 3;
                    this.variableTypes = ['f32', 'vec4<f32>'];
                }
                else {
                    this.innerElementSize = 4;
                    this.variableTypes = ['vec4<f32>', 'vec4<f32>'];
                }
                if (addBias) {
                    this.variableNames.push('bias');
                    this.variableTypes.push('vec4<f32>');
                }
                if (hasPreluActivationWeights) {
                    this.variableNames.push('preluActivationWeights');
                    this.variableTypes.push('vec4<f32>');
                }
            }
            else {
                this.innerElementSize = this.elementsPerThread[0];
                if (addBias) {
                    this.variableNames.push('bias');
                }
                if (hasPreluActivationWeights) {
                    this.variableNames.push('preluActivationWeights');
                }
            }
            this.sequentialAccessByThreads = sequentialAccessByThreads;
            this.addBias = addBias;
            this.activation = activation;
            this.hasPreluActivationWeights = hasPreluActivationWeights;
            this.tileAOuter = this.workgroupSize[1] * this.elementsPerThread[1];
            this.tileBOuter = this.workgroupSize[0] * this.elementsPerThread[0];
            this.tileInner = Math.max(this.workgroupSize[0] * this.innerElementSize, this.workgroupSize[1]);
            this.fitAOuter = dimAOuter % this.tileAOuter === 0;
            this.fitBOuter = dimBOuter % this.tileBOuter === 0;
            this.fitInner = dimInner % this.tileInner === 0;
            this.shaderKey = `conv2DMM_${this.elementsPerThread}_${this.activation}}_${this.fitAOuter}_${this.fitBOuter}_${this.fitInner}_${this.isVec4}_${this.innerElementSize}_${this.isChannelsLast}_${this.sequentialAccessByThreads}`;
        }
        getUserCode() {
            const matMulSource = this.isVec4 ?
                makeMatMulPackedVec4Source(this.elementsPerThread, this.workgroupSize, !this.isChannelsLast, this.tileInner) :
                makeMatMulPackedSource(this.elementsPerThread, this.workgroupSize, !this.isChannelsLast, this.tileInner, false, null, this.sequentialAccessByThreads);
            const elementsSize = this.isVec4 ? [this.innerElementSize, 4, 4] : [1, 1, 1];
            const userCode = `
    ${conv2dCommonSnippet(this.isChannelsLast, this.fitAOuter, this.fitBOuter, this.fitInner, this.addBias, this.activation, this.hasPreluActivationWeights, elementsSize[0], elementsSize[1], elementsSize[2])}
    ${matMulSource}
  `;
            return userCode;
        }
    }

    /**
     * @license
     * Copyright 2022 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    class Conv2DNaiveProgram {
        constructor(convInfo, addBias = false, activation = null, hasPreluActivationWeights = false) {
            this.variableNames = ['x', 'W'];
            this.uniforms = 'filterDims: vec2<i32>, pad: vec2<i32>, stride: vec2<i32>, dilation: vec2<i32>,';
            this.workgroupSize = [4, 4, 8];
            this.outputShape = convInfo.outShape;
            this.isChannelsLast = convInfo.dataFormat === 'channelsLast';
            this.dispatchLayout = this.isChannelsLast ? { x: [2], y: [1], z: [0, 3] } :
                { x: [3], y: [2], z: [0, 1] };
            this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
            this.addBias = addBias;
            this.activation = activation;
            this.hasPreluActivationWeights = hasPreluActivationWeights;
            if (addBias) {
                this.variableNames.push('bias');
            }
            if (hasPreluActivationWeights) {
                this.variableNames.push('preluActivationWeights');
            }
            this.shaderKey = `conv2dnaive_${this.activation}_${this.isChannelsLast}`;
        }
        getUserCode() {
            const userCode = `
       ${activationFnSnippet(this.activation, this.hasPreluActivationWeights, false, 4)}
       fn readInp(batch : i32, row : i32, col : i32, chan : i32) -> f32{
         let coords = vec4<i32>(batch, row, col, chan);
         if (coordsInBounds4D(coords, uniforms.xShape)) {
           return  getX(batch, row, col, chan);
         } else {
          return 0.0;
         }
       }
       fn readFilt(row : i32, col : i32, xChannel : i32, outChannel : i32) -> f32{
         let coords = vec4<i32>(row, col, xChannel, outChannel);
         if(coordsInBounds4D(coords, uniforms.wShape)) {
           return getW(row, col, xChannel, outChannel);
          } else {
            return 0.0;
          }
       }
       fn writeResult(batch : i32, row : i32, col : i32, chan : i32, valueIn : f32) {
         let coords = ${this.isChannelsLast ? `vec4<i32>(batch, row, col, chan);` :
            `vec4<i32>(batch, chan, row, col);`}
         if (coordsInBounds4D(coords, uniforms.outShape)) {
           var value = valueIn;
           ${biasActivationSnippet(this.addBias, this.activation)}
           setOutputAtCoords(coords.x, coords.y, coords.z, coords.w, value);
         }
       }
       ${getMainHeaderString('index')} {
         let coords = getOutputCoords();
         let batch = coords[0];
         let outChannel = ${this.isChannelsLast ? `coords[3];` : `coords[1];`}
         let outRow = ${this.isChannelsLast ? `coords[1];` : `coords[2];`}
         let outCol = ${this.isChannelsLast ? `coords[2];` : `coords[3];`}
         var acc : f32 = 0.0;
         for (var row = 0; row < uniforms.filterDims[0]; row = row + 1) {
           for (var col = 0; col < uniforms.filterDims[1]; col = col + 1) {
             let xRow = outRow * uniforms.stride[0] + uniforms.dilation[0] * row - uniforms.pad[0];
             let xCol = outCol * uniforms.stride[1] + uniforms.dilation[1] * col - uniforms.pad[1];
             for (var xChannel = 0; xChannel < ${this.isChannelsLast ? `uniforms.xShape[3];` :
            `uniforms.xShape[1];`} xChannel = xChannel + 1) {
               ${this.isChannelsLast ? `let v = readInp(batch, xRow, xCol, xChannel);` :
            `let v = readInp(batch, xChannel, xRow, xCol);`}
               let f = readFilt(row, col, xChannel, outChannel);
               acc = acc + v * f;
             }
           }
         }
         writeResult(batch, outRow, outCol, outChannel, acc);
       }
     `;
            return userCode;
        }
    }

    /**
     * @license
     * Copyright 2022 Google LLC.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    class Im2ColProgram {
        constructor(outputShape, isChannelsLast) {
            this.variableNames = ['x'];
            this.uniforms = `pad : vec2<i32>, stride : vec2<i32>, dilation : vec2<i32>, outWidth : i32, itemsPerBlockRow : i32,
       inChannels : i32,`;
            this.workgroupSize = [64, 1, 1];
            this.size = true;
            this.outputShape = outputShape;
            this.dispatchLayout = flatDispatchLayout(this.outputShape);
            this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
            this.isChannelsLast = isChannelsLast;
            this.shaderKey = `im2col_${this.isChannelsLast}`;
        }
        getUserCode() {
            const rowDim = this.isChannelsLast ? 1 : 2;
            const colDim = this.isChannelsLast ? 2 : 3;
            const row = this.isChannelsLast ? 'coords[1]' : 'coords[2]';
            const col = this.isChannelsLast ? 'coords[2]' : 'coords[1]';
            const getXSnippet = this.isChannelsLast ? 'getX(batch, xRow, xCol, ch)' :
                'getX(batch, ch, xRow, xCol)';
            const userCode = `
    ${getMainHeaderString('index')} {
      let coords = getCoordsFromIndex(index);
      if(index < uniforms.size) {
        let batch = coords[0];
        let row = ${row};
        let col = ${col};
        let offsetY = (row / uniforms.outWidth) * uniforms.stride[0] - uniforms.pad[0];
        let xRow = offsetY + uniforms.dilation[0] * (col / uniforms.itemsPerBlockRow);
        var value = 0.0;
        if(xRow < uniforms.xShape[${rowDim}] && xRow >= 0) {
          let offsetX = (row % uniforms.outWidth) * uniforms.stride[1] -
              uniforms.pad[1];
          let xCol = offsetX + uniforms.dilation[1] * ((col %
              uniforms.itemsPerBlockRow) / uniforms.inChannels);
          let ch = col % uniforms.inChannels;
          if(xCol < uniforms.xShape[${colDim}] && xCol >= 0) {
            value = ${getXSnippet};
          }
        }
        setOutputAtIndex(index, value);
      }
    }
   `;
            return userCode;
        }
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    // conv2dByMatMul fuses height and width into one dimension to compute
    // batchMatMul, so bias and activation weights are also supposed to fuse the two
    // dimensions into one.
    //
    // This function computes the target shape for fusing height and width
    // dimensions. Returning null means the shape is already compatible.
    function getShapeForBatchMatMul(shape, isChannelsLast) {
        const length = shape.length;
        if (length >= 3) {
            return isChannelsLast ?
                [
                    ...shape.slice(0, -3) /* batch */,
                    shape[length - 3] * shape[length - 2] /* height * width */,
                    shape[length - 1] /* channel */
                ] :
                [
                    ...shape.slice(0, -3) /* batch */, shape[length - 3] /* channel */,
                    shape[length - 2] * shape[length - 1] /* height * width */
                ];
        }
        else if (!isChannelsLast && length === 1 && shape[0] > 1) {
            return [shape[0], 1];
        }
        else {
            return null;
        }
    }
    // For 1x1 kernels that iterate through every point in the input, convolution
    // can be expressed as matrix multiplication (without need for memory
    // remapping).
    function conv2dByMatMul({ x, filter, convInfo, backend, bias = null, preluActivationWeights = null, leakyreluAlpha = 0, activation = null }) {
        const isChannelsLast = convInfo.dataFormat === 'channelsLast';
        const transposeA = isChannelsLast ? false : true;
        const transposeB = false;
        const sameSize = isChannelsLast &&
            convInfo.filterHeight === convInfo.inHeight &&
            convInfo.filterWidth === convInfo.inWidth &&
            convInfo.padInfo.type === 'VALID';
        const intermediates = [];
        let xReshaped;
        let filterReshaped;
        if (sameSize) {
            const sharedDim = convInfo.inHeight * convInfo.inWidth * convInfo.inChannels;
            xReshaped = reshape({
                inputs: { x },
                backend,
                attrs: { shape: [1, convInfo.batchSize, sharedDim] }
            });
            filterReshaped = reshape({
                inputs: { x: filter },
                backend,
                attrs: { shape: [1, sharedDim, convInfo.outChannels] }
            });
        }
        else {
            xReshaped = reshape({
                inputs: { x },
                backend,
                attrs: {
                    shape: isChannelsLast ?
                        [
                            convInfo.batchSize, convInfo.inHeight * convInfo.inWidth,
                            convInfo.inChannels
                        ] :
                        [
                            convInfo.batchSize, convInfo.inChannels,
                            convInfo.inHeight * convInfo.inWidth
                        ]
                }
            });
            filterReshaped = reshape({
                inputs: { x: filter },
                backend,
                attrs: { shape: [1, convInfo.inChannels, convInfo.outChannels] }
            });
        }
        intermediates.push(xReshaped);
        intermediates.push(filterReshaped);
        if (preluActivationWeights != null) {
            const targetShape = getShapeForBatchMatMul(preluActivationWeights.shape, isChannelsLast);
            if (targetShape != null) {
                preluActivationWeights = reshape({
                    inputs: { x: preluActivationWeights },
                    backend,
                    attrs: { shape: targetShape }
                });
                intermediates.push(preluActivationWeights);
            }
        }
        if (bias != null) {
            const targetShape = getShapeForBatchMatMul(bias.shape, isChannelsLast);
            if (targetShape != null) {
                bias = reshape({ inputs: { x: bias }, backend, attrs: { shape: targetShape } });
                intermediates.push(bias);
            }
        }
        const result = batchMatMulImpl({
            a: isChannelsLast ? xReshaped : filterReshaped,
            b: isChannelsLast ? filterReshaped : xReshaped,
            transposeA,
            transposeB,
            backend,
            bias,
            activation,
            preluActivationWeights,
            leakyreluAlpha
        });
        const out = reshape({ inputs: { x: result }, backend, attrs: { shape: convInfo.outShape } });
        intermediates.push(result);
        for (const i of intermediates) {
            backend.disposeData(i.dataId);
        }
        return out;
    }
    // Implements the im2col algorithm as outlined in "High Performance
    // Convolutional Neural Networks for Document Processing" (Suvisoft, 2006)
    function conv2dWithIm2Col({ x, filter, convInfo, backend, bias = null, preluActivationWeights = null, leakyreluAlpha = 0, activation = null }) {
        // Rearranges conv2d input so each block to be convolved over forms the
        // row of a new matrix with shape [outHeight * outWidth,
        // filterWidth * filterHeight * inChannels]. The filter is also rearranged so
        // each output channel forms a col of a new matrix with shape [
        // filterWidth * filterHeight * inChannels, outChannels]. The convolution is
        // then computed by multiplying these matrices and reshaping the result.
        const { filterWidth, filterHeight, inChannels, strideWidth, strideHeight, padInfo, outWidth, outHeight, dilationWidth, dilationHeight, dataFormat } = convInfo;
        const isChannelsLast = dataFormat === 'channelsLast';
        const sharedDim = filterWidth * filterHeight * inChannels;
        const numCols = outHeight * outWidth;
        const x2ColShape = isChannelsLast ? [convInfo.batchSize, numCols, sharedDim] :
            [convInfo.batchSize, sharedDim, numCols];
        const im2ColProgram = new Im2ColProgram(x2ColShape, isChannelsLast);
        const dimensions = [
            { type: 'int32', data: [padInfo.top, padInfo.left] },
            { type: 'int32', data: [strideHeight, strideWidth] },
            { type: 'int32', data: [dilationHeight, dilationWidth] },
            { type: 'int32', data: [outWidth] },
            { type: 'int32', data: [inChannels * filterWidth] },
            { type: 'int32', data: [inChannels] }
        ];
        const x2Col = backend.runWebGPUProgram(im2ColProgram, [x], x.dtype, dimensions);
        const intermediates = [];
        intermediates.push(x2Col);
        const filterReshaped = reshape({ inputs: { x: filter }, backend, attrs: { shape: [1, sharedDim, -1] } });
        intermediates.push(filterReshaped);
        if (preluActivationWeights != null) {
            const targetShape = getShapeForBatchMatMul(preluActivationWeights.shape, isChannelsLast);
            if (targetShape != null) {
                preluActivationWeights = reshape({
                    inputs: { x: preluActivationWeights },
                    backend,
                    attrs: { shape: targetShape }
                });
                intermediates.push(preluActivationWeights);
            }
        }
        if (bias != null) {
            const targetShape = getShapeForBatchMatMul(bias.shape, isChannelsLast);
            if (targetShape != null) {
                bias = reshape({ inputs: { x: bias }, backend, attrs: { shape: targetShape } });
                intermediates.push(bias);
            }
        }
        const transposeA = isChannelsLast ? false : true;
        const transposeB = false;
        const result = batchMatMulImpl({
            a: isChannelsLast ? x2Col : filterReshaped,
            b: isChannelsLast ? filterReshaped : x2Col,
            transposeA,
            transposeB,
            backend,
            bias,
            activation,
            preluActivationWeights,
            leakyreluAlpha
        });
        const out = reshape({ inputs: { x: result }, backend, attrs: { shape: convInfo.outShape } });
        intermediates.push(result);
        for (const i of intermediates) {
            backend.disposeData(i.dataId);
        }
        return out;
    }
    function conv2DImpl({ x, filter, convInfo, backend, bias = null, preluActivationWeights = null, leakyreluAlpha = 0, activation = null }) {
        const hasBias = bias != null;
        const hasPreluActivationWeights = preluActivationWeights != null;
        const isChannelsLast = convInfo.dataFormat === 'channelsLast';
        const sameSize = isChannelsLast &&
            convInfo.filterHeight === convInfo.inHeight &&
            convInfo.filterWidth === convInfo.inWidth &&
            convInfo.padInfo.type === 'VALID';
        const useNaiveConv2d = tf.env().getBool('WEBGPU_USE_NAIVE_CONV2D_DEBUG');
        if (!useNaiveConv2d &&
            (sameSize ||
                (convInfo.filterHeight === 1 && convInfo.filterWidth === 1 &&
                    convInfo.dilationHeight === 1 && convInfo.dilationWidth === 1 &&
                    convInfo.strideHeight === 1 && convInfo.strideWidth === 1 &&
                    (convInfo.padInfo.type === 'SAME' ||
                        convInfo.padInfo.type === 'VALID')))) {
            return conv2dByMatMul({
                x,
                filter,
                convInfo,
                backend,
                bias,
                activation,
                preluActivationWeights,
                leakyreluAlpha
            });
        }
        const thresholdFlagValue = tf.env().getNumber('WEBGPU_THRESHOLD_TO_INCREASE_WORKGROUPS_FOR_MATMUL');
        const thresholdToIncreaseWorkgroups = thresholdFlagValue > 0 ?
            thresholdFlagValue : backend.thresholdToIncreaseWorkgroups;
        const workgroupsBy32x32 = convInfo.batchSize *
            Math.ceil((convInfo.outHeight * convInfo.outWidth) / 32) *
            Math.ceil(convInfo.outChannels / 32);
        if (tf.env().getBool('WEBGPU_CONV_SEPARATE_IM2COL_SHADER') ||
            workgroupsBy32x32 <= thresholdToIncreaseWorkgroups) {
            return conv2dWithIm2Col({
                x,
                filter,
                convInfo,
                backend,
                bias,
                preluActivationWeights,
                leakyreluAlpha,
                activation
            });
        }
        let program;
        const padInfo = [convInfo.padInfo.top, convInfo.padInfo.left];
        const dimensions = [
            { type: 'int32', data: [convInfo.filterHeight, convInfo.filterWidth] },
            { type: 'int32', data: [...padInfo] },
            { type: 'int32', data: [convInfo.strideHeight, convInfo.strideWidth] },
            { type: 'int32', data: [convInfo.dilationHeight, convInfo.dilationWidth] }
        ];
        if (useNaiveConv2d) {
            program = new Conv2DNaiveProgram(convInfo, hasBias, activation, hasPreluActivationWeights);
        }
        else {
            const dimAOuter = isChannelsLast ? convInfo.outHeight * convInfo.outWidth :
                convInfo.outChannels;
            const dimBOuter = isChannelsLast ? convInfo.outChannels :
                convInfo.outHeight * convInfo.outWidth;
            const dimInner = convInfo.filterHeight * convInfo.filterWidth * convInfo.inChannels;
            dimensions.push({ type: 'int32', data: [dimAOuter] }, { type: 'int32', data: [dimBOuter] }, { type: 'int32', data: [dimInner] });
            // Experiments show that sequential access is more friendly for Intel GPUs.
            const sequentialAccessByThreads = backend.adapterInfo.isIntel();
            program = new Conv2DMMProgram(convInfo, dimAOuter, dimBOuter, dimInner, hasBias, activation, hasPreluActivationWeights, sequentialAccessByThreads);
        }
        const intermediates = [];
        const inputVar = [x, filter];
        if (hasBias) {
            if (!isChannelsLast && bias.shape.length === 1) {
                bias = reshape({ inputs: { x: bias }, backend, attrs: { shape: [bias.shape[0], 1, 1] } });
                intermediates.push(bias);
            }
            inputVar.push(bias);
        }
        if (hasPreluActivationWeights) {
            if (!isChannelsLast && preluActivationWeights.shape.length === 1) {
                preluActivationWeights = reshape({
                    inputs: { x: preluActivationWeights },
                    backend,
                    attrs: { shape: [preluActivationWeights.shape[0], 1, 1] }
                });
                intermediates.push(preluActivationWeights);
            }
            inputVar.push(preluActivationWeights);
        }
        if (activation === 'leakyrelu') {
            dimensions.push({ type: 'float32', data: [leakyreluAlpha] });
            program.uniforms += ' alpha : f32,';
        }
        const out = backend.runWebGPUProgram(program, inputVar, x.dtype, dimensions);
        for (const i of intermediates) {
            backend.disposeData(i.dataId);
        }
        return out;
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function conv2d(args) {
        const { inputs, attrs, backend } = args;
        const { x, filter } = inputs;
        const { strides, pad, dataFormat, dilations, dimRoundingMode } = attrs;
        const $dataFormat = tf.backend_util.convertConv2DDataFormat(dataFormat);
        const convInfo = tf.backend_util.computeConv2DInfo(x.shape, filter.shape, strides, dilations, pad, dimRoundingMode, false /* depthwise */, $dataFormat);
        return conv2DImpl({ x, filter, convInfo, backend });
    }
    const conv2DConfig = {
        kernelName: tf.Conv2D,
        backendName: 'webgpu',
        kernelFunc: conv2d
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    class Conv2DDerInputProgram {
        constructor(convInfo) {
            this.variableNames = ['dy', 'W'];
            this.uniforms = 'filterDims : vec2<i32>, pads : vec2<i32>, stride : vec2<i32>, outBackprop : vec4<i32>,';
            this.workgroupSize = [64, 1, 1];
            this.size = true;
            this.outputShape = convInfo.inShape;
            this.dispatchLayout = flatDispatchLayout(this.outputShape);
            this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
            this.isChannelsLast = convInfo.dataFormat === 'channelsLast';
            this.shaderKey = `conv2DDerInput_${this.isChannelsLast}`;
        }
        getUserCode() {
            const rowDim = this.isChannelsLast ? 1 : 2;
            const colDim = this.isChannelsLast ? 2 : 3;
            const channelDim = this.isChannelsLast ? 3 : 1;
            return `
    ${getMainHeaderString('index')} {
      if(index < uniforms.size) {
        let coords = getCoordsFromIndex(index);
        let batch = coords[0];
        let d1 = coords[${channelDim}];

        let dyCorner = vec2<i32>(coords[${rowDim}], coords[${colDim}]) - uniforms.pads;
        let dyRCorner = dyCorner.x;
        let dyCCorner = dyCorner.y;

        // Convolve dy(?, ?, d2) with w(:, :, d1, d2) to compute dx(xR, xC, d1).
        // ? = to be determined. : = across all values in that axis.
        var dotProd = 0.0;
        for (var wR = 0; wR < uniforms.filterDims.x; wR = wR + 1) {
          let dyR = (f32(dyRCorner) + f32(wR)) / f32(uniforms.stride.x);
          let wRPerm = uniforms.filterDims.x - 1 - wR;
          if (dyR < 0.0 || dyR >= f32(uniforms.outBackprop[1]) || fract(dyR) > 0.0 ||
              wRPerm < 0) {
            continue;
          }
          let idyR = i32(dyR);

          for (var wC = 0; wC < uniforms.filterDims.y; wC = wC + 1) {
            let dyC = (f32(dyCCorner) + f32(wC)) / f32(uniforms.stride.y);
            let wCPerm = uniforms.filterDims.y - 1 - wC;
            if (dyC < 0.0 || dyC >= f32(uniforms.outBackprop[2]) ||
                fract(dyC) > 0.0 || wCPerm < 0) {
              continue;
            }
            let idyC = i32(dyC);

            for (var d2 = 0; d2 < uniforms.outBackprop[3]; d2 = d2 + 1) {
              if (${this.isChannelsLast}) {
                let xValue = getDy(batch, idyR, idyC, d2);
                let wValue = getW(wRPerm, wCPerm, d1, d2);
                dotProd = dotProd + xValue * wValue;
              } else {
                let xValue = getDy(batch, d2, idyR, idyC);
                let wValue = getW(wRPerm, wCPerm, d1, d2);
                dotProd = dotProd + xValue * wValue;
              }

            }
          }
        }
        setOutputAtIndex(index, dotProd);
      }
    }
  `;
        }
    }
    class Conv2DDerFilterProgram {
        constructor(convInfo) {
            this.variableNames = ['x', 'dy'];
            this.uniforms = 'pad : vec2<i32>, stride : vec2<i32>, batchSize : i32, outHeight : i32, outWidth : i32, inHeight : i32, inWidth : i32,';
            this.workgroupSize = [64, 1, 1];
            this.size = true;
            this.outputShape = convInfo.filterShape;
            this.dispatchLayout = flatDispatchLayout(this.outputShape);
            this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
            this.isChannelsLast = convInfo.dataFormat === 'channelsLast';
            this.shaderKey = `conv2DDerFilter_${this.isChannelsLast}`;
        }
        getUserCode() {
            return `
    ${getMainHeaderString('index')} {
      if(index < uniforms.size) {
        let coords = getCoordsFromIndex(index);
        let wR = coords[0];
        let wC = coords[1];
        let d1 = coords[2];
        let d2 = coords[3];

        // Convolve x(?, ?, d1) with dy(:, :, d2) to get dw(wR, wC, d1, d2).
        // ? = to be determined. : = across all values in that axis.
        var dotProd = 0.0;
        for (var b = 0; b < uniforms.batchSize; b = b + 1) {
          for (var yR = 0; yR < uniforms.outHeight; yR = yR + 1) {
            let xR = wR + yR * uniforms.stride[0] - uniforms.pad[0];
            if (xR < 0 || xR >= uniforms.inHeight) {
              continue;
            }

            for (var yC = 0; yC < uniforms.outWidth; yC = yC + 1) {
              let xC = wC + yC * uniforms.stride[1] - uniforms.pad[1];

              if (xC < 0 || xC >= uniforms.inWidth) {
                continue;
              }

              if (${this.isChannelsLast}) {
                let dyValue = getDy(b, yR, yC, d2);
                let xValue = getX(b, xR, xC, d1);
                dotProd = dotProd + xValue * dyValue;
              } else {
                let dyValue = getDy(b, d2, yR, yC);
                let xValue = getX(b, d1, xR, xC);
                dotProd = dotProd + xValue * dyValue;
              }
            }
          }
        }
        setOutputAtIndex(index, dotProd);
      }
    }
  `;
        }
    }

    /**
     * @license
     * Copyright 2022 Google LLC.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function conv2DBackpropFilter(args) {
        const { inputs, backend, attrs } = args;
        const { x, dy } = inputs;
        const { strides, pad, dataFormat, dimRoundingMode, filterShape } = attrs;
        const $dataFormat = tf.backend_util.convertConv2DDataFormat(dataFormat);
        const convInfo = tf.backend_util.computeConv2DInfo(x.shape, filterShape, strides, 1 /* dilations */, pad, dimRoundingMode, false /* depthwise */, $dataFormat);
        const program = new Conv2DDerFilterProgram(convInfo);
        const uniformData = [
            { type: 'int32', data: [convInfo.padInfo.top, convInfo.padInfo.left] },
            { type: 'int32', data: [convInfo.strideHeight, convInfo.strideWidth] },
            { type: 'int32', data: [convInfo.batchSize] },
            { type: 'int32', data: [convInfo.outHeight] },
            { type: 'int32', data: [convInfo.outWidth] },
            { type: 'int32', data: [convInfo.inHeight] },
            { type: 'int32', data: [convInfo.inWidth] }
        ];
        return backend.runWebGPUProgram(program, [x, dy], x.dtype, uniformData);
    }
    const conv2DBackpropFilterConfig = {
        kernelName: tf.Conv2DBackpropFilter,
        backendName: 'webgpu',
        kernelFunc: conv2DBackpropFilter
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function conv2dTransposeCommonSnippet(innerElementSize = 4) {
        const getWSnippet = (innerElementSize) => {
            switch (innerElementSize) {
                case 1:
                    return 'return W[getIndexFromCoords4D(coord, uniforms.wShape)];';
                case 4:
                    return `
            let coord1 = vec4<i32>(coordX, coordY, col + 1, rowInner);
            let coord2 = vec4<i32>(coordX, coordY, col + 2, rowInner);
            let coord3 = vec4<i32>(coordX, coordY, col + 3, rowInner);
            let v0 = W[getIndexFromCoords4D(coord, uniforms.wShape)];
            let v1 = W[getIndexFromCoords4D(coord1, uniforms.wShape)];
            let v2 = W[getIndexFromCoords4D(coord2, uniforms.wShape)];
            let v3 = W[getIndexFromCoords4D(coord3, uniforms.wShape)];
            return vec4<f32>(v0, v1, v2, v3);
            `;
                default:
                    throw new Error(`innerElementSize ${innerElementSize} is not supported.`);
            }
        };
        const readASnippet = `
      let outRow = row / uniforms.outShape[2];
      let outCol = row % uniforms.outShape[2];

      let WRow = col / (uniforms.filterDims[1] * uniforms.outBackprop[3]);
      let WCol = col / uniforms.outBackprop[3] % uniforms.filterDims[1];
      let xR = f32(outRow - uniforms.pads[0] + WRow) / f32(uniforms.stride[0]);
      let xC = f32(outCol - uniforms.pads[1] + WCol) / f32(uniforms.stride[1]);
      if (xR < 0.0 || xR >= f32(uniforms.outBackprop[1]) || fract(xR) > 0.0) {
        return ${typeSnippet(innerElementSize)}(0.0);
      }
      if (xC < 0.0 || xC >= f32(uniforms.outBackprop[2]) || fract(xC) > 0.0) {
        return ${typeSnippet(innerElementSize)}(0.0);
      }
      let coord = vec4<i32>(
          batch,
          i32(xR),
          i32(xC),
          col % uniforms.outBackprop[3]);
      return x[getIndexFromCoords4D(coord, uniforms.xShape)/${innerElementSize}];`;
        const sampleA = `if (row < uniforms.dimAOuter && col < uniforms.dimInner) {
        ${readASnippet}
      }
      return ${typeSnippet(innerElementSize)}(0.0);`;
        const userCode = `
  fn mm_readA(batch: i32, row : i32, colIn : i32) -> ${typeSnippet(innerElementSize)} {
    let col = colIn * ${innerElementSize};
    ${sampleA}
  }

  fn mm_readB(batch: i32, row : i32, colIn : i32) -> ${typeSnippet(innerElementSize)} {
    let col = colIn * ${innerElementSize};
    let coordX = uniforms.filterDims.x - 1 -
        row / (uniforms.filterDims[1] * uniforms.outBackprop[3]);
    let coordY = uniforms.filterDims.y - 1 -
        (row / uniforms.outBackprop[3]) % uniforms.filterDims[1];
    if (row < uniforms.dimInner && col < uniforms.dimBOuter &&
        coordX >= 0 && coordY >= 0) {
      let rowInner = row % uniforms.outBackprop[3];
      let coord = vec4<i32>(coordX, coordY, col, rowInner);
      ${getWSnippet(innerElementSize)}
    }
    return ${typeSnippet(innerElementSize)}(0.0);
  }

  fn mm_write(batch: i32, row : i32, colIn : i32, valueInput : ${typeSnippet(innerElementSize)}) {
    let col = colIn * ${innerElementSize};
    if (row < uniforms.dimAOuter && (col + ${innerElementSize - 1}) < uniforms.dimBOuter) {
      var value = valueInput;
      let outCoord = vec4<i32>(
          batch,
          row / uniforms.outShape[2],
          row % uniforms.outShape[2],
          col);
      result[getIndexFromCoords4D(outCoord, uniforms.outShape)/${innerElementSize}] = value;
    }
  }`;
        return userCode;
    }
    class Conv2DDerInputMMProgram {
        constructor(convInfo) {
            this.variableNames = ['x', 'W'];
            this.uniforms = 'filterDims : vec2<i32>, pads : vec2<i32>, stride : vec2<i32>, outBackprop : vec4<i32>, dimAOuter : i32, dimBOuter : i32, dimInner : i32,';
            this.outputShape = convInfo.inShape;
            tf.util.assert(convInfo.dataFormat === 'channelsLast', () => 'TODO: NCHW is unimplemented');
            this.isVec4 =
                convInfo.inChannels % 4 === 0 && convInfo.outChannels % 4 === 0;
            this.dispatchLayout = { x: [3], y: [1, 2], z: [0] };
            this.workgroupSize = computeWorkgroupSizeForConv2d(this.dispatchLayout, this.outputShape, this.isVec4);
            this.elementsPerThread = computeWorkPerThreadForConv2d(this.dispatchLayout, this.outputShape, this.isVec4);
            this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize, this.elementsPerThread);
            if (this.isVec4) {
                this.variableTypes = ['vec4<f32>', 'f32'];
            }
            this.shaderKey =
                `conv2DDerInputMM_${this.isVec4}_${this.elementsPerThread}`;
        }
        getUserCode() {
            const matMulSource = this.isVec4 ?
                makeMatMulPackedVec4Source(this.elementsPerThread, this.workgroupSize) :
                makeMatMulPackedSource(this.elementsPerThread, this.workgroupSize);
            const userCode = `
    ${conv2dTransposeCommonSnippet(this.isVec4 ? 4 : 1)}
    ${matMulSource}
    `;
            return userCode;
        }
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function conv2DBackpropInput(args) {
        const { inputs, backend, attrs } = args;
        const { dy, filter } = inputs;
        const { inputShape, strides, pad, dataFormat, dimRoundingMode } = attrs;
        const $dataFormat = tf.backend_util.convertConv2DDataFormat(dataFormat);
        const convInfo = tf.backend_util.computeConv2DInfo(inputShape, filter.shape, strides, 1 /* dilations */, pad, dimRoundingMode, false, $dataFormat);
        const dimensions = [
            { type: 'int32', data: [convInfo.filterHeight, convInfo.filterWidth] },
            {
                type: 'int32',
                data: [
                    convInfo.filterHeight - 1 - convInfo.padInfo.top,
                    convInfo.filterWidth - 1 - convInfo.padInfo.left
                ]
            },
            { type: 'int32', data: [convInfo.strideHeight, convInfo.strideWidth] },
            {
                type: 'int32',
                data: [
                    convInfo.batchSize, convInfo.outHeight, convInfo.outWidth,
                    convInfo.outChannels
                ]
            },
        ];
        let program;
        // When filter size is small, Conv2DDerInputProgram is much faster than
        // Conv2DDerInputMMProgram.
        if (tf.env().getBool('WEBGPU_USE_NAIVE_CONV2D_TRANSPOSE') ||
            convInfo.filterHeight <= 2 && convInfo.filterWidth <= 2 &&
                convInfo.outChannels <= 16 && convInfo.inChannels === 1) {
            program = new Conv2DDerInputProgram(convInfo);
        }
        else {
            program = new Conv2DDerInputMMProgram(convInfo);
            const dimAOuter = convInfo.inHeight * convInfo.inWidth;
            const dimBOuter = convInfo.inChannels;
            const dimInner = convInfo.filterHeight * convInfo.filterWidth * convInfo.outChannels;
            dimensions.push({ type: 'uint32', data: [dimAOuter] }, { type: 'uint32', data: [dimBOuter] }, { type: 'uint32', data: [dimInner] });
        }
        return backend.runWebGPUProgram(program, [dy, filter], 'float32', dimensions);
    }
    const conv2DBackpropInputConfig = {
        kernelName: tf.Conv2DBackpropInput,
        backendName: 'webgpu',
        kernelFunc: conv2DBackpropInput,
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const cos = unaryKernelFunc({ opType: UnaryOpType.COS });
    const cosConfig = {
        kernelName: tf.Cos,
        backendName: 'webgpu',
        kernelFunc: cos
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const cosh = unaryKernelFunc({ opType: UnaryOpType.COSH });
    const coshConfig = {
        kernelName: tf.Cosh,
        backendName: 'webgpu',
        kernelFunc: cosh
    };

    /**
     * @license
     * Copyright 2019 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    class CropAndResizeProgram {
        constructor(channnel, boxShape, cropSize, method) {
            this.variableNames = ['Image', 'Boxes', 'BoxInd'];
            this.uniforms = 'extrapolationValue : f32,';
            this.workgroupSize = [64, 1, 1];
            this.size = true;
            const [numBoxes,] = boxShape;
            this.outputShape = [numBoxes, cropSize[0], cropSize[1], channnel];
            this.dispatchLayout = flatDispatchLayout(this.outputShape);
            this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
            this.methodId = method === 'bilinear' ? 1 : 0;
            this.cropHeightBiggerThan1 = this.outputShape[1] > 1;
            this.cropWidthBiggerThan1 = this.outputShape[2] > 1;
            this.shaderKey = `cropAndResize_${this.methodId}_${this.cropHeightBiggerThan1}_${this.cropWidthBiggerThan1}`;
        }
        getUserCode() {
            const [inputHeightFloat, inputWidthFloat] = [`f32(uniforms.imageShape[1] - 1)`, `f32(uniforms.imageShape[2] - 1)`];
            const [heightRatio, heightScale, inY] = this.cropHeightBiggerThan1 ?
                [
                    `(${inputHeightFloat} / f32(uniforms.outShape[1] - 1))`,
                    '(y2-y1) * height_ratio',
                    `y1*${inputHeightFloat} + f32(y)*(height_scale)`,
                ] :
                [
                    '0.0',
                    '0.0',
                    `0.5 * (y1+y2) * ${inputHeightFloat}`,
                ];
            const [widthRatio, widthScale, inX] = this.cropWidthBiggerThan1 ?
                [
                    `(${inputWidthFloat} / f32(uniforms.outShape[2] - 1))`,
                    '(x2-x1) * width_ratio',
                    `x1*${inputWidthFloat} + f32(x)*(width_scale)`,
                ] :
                [
                    '0.0',
                    '0.0',
                    `0.5 * (x1+x2) * ${inputWidthFloat}`,
                ];
            // Reference implementation
            // tslint:disable-next-line:max-line-length
            // https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/crop_and_resize_op_gpu.cu.cc
            const userCode = `
    ${getMainHeaderString('index')} {
      if (index < uniforms.size) {
        let coords = getCoordsFromIndex(index);
        let height_ratio = f32(${heightRatio});
        let width_ratio = f32(${widthRatio});
        let b = coords[0];
        let y = coords[1];
        let x = coords[2];
        let d = coords[3];
        // get box vals
        let y1 = getBoxes(b, 0);
        let x1 = getBoxes(b, 1);
        let y2 = getBoxes(b, 2);
        let x2 = getBoxes(b, 3);
        // get image in batch index
        let bInd = i32(round(getBoxInd(b)));
        if(bInd < 0 || bInd >= uniforms.outShape[0]) {
          return;
        }
        let height_scale = ${heightScale};
        let width_scale = ${widthScale};
        let in_y = ${inY};
        if( in_y < 0.0 || in_y > ${inputHeightFloat} ) {
          setOutputAtIndex(index, uniforms.extrapolationValue);
          return;
        }
        let in_x = ${inX};
        if( in_x < 0.0 || in_x > ${inputWidthFloat} ) {
          setOutputAtIndex(index, uniforms.extrapolationValue);
          return;
        }
        let sourceFracIndexCR = vec2<f32>(in_x,in_y);
        if(${this.methodId} == 1) {
          // Compute the four integer indices.
          let sourceFloorCR = vec2<i32>(sourceFracIndexCR);
          let sourceCeilCR = vec2<i32>(ceil(sourceFracIndexCR));
          let topLeft = getImage(bInd, sourceFloorCR.y, sourceFloorCR.x, d);
          let bottomLeft = getImage(bInd, sourceCeilCR.y, sourceFloorCR.x, d);
          let topRight = getImage(bInd, sourceFloorCR.y, sourceCeilCR.x, d);
          let bottomRight = getImage(bInd, sourceCeilCR.y, sourceCeilCR.x, d);
          let fracCR = sourceFracIndexCR - vec2<f32>(sourceFloorCR);
          let top = topLeft + (topRight - topLeft) * fracCR.x;
          let bottom = bottomLeft + (bottomRight - bottomLeft) * fracCR.x;
          let newValue = top + (bottom - top) * fracCR.y;
          setOutputAtIndex(index, newValue);
        } else {
          // Compute the coordinators of nearest neighbor point.
          let sourceNearestCR = vec2<i32>(floor(
            sourceFracIndexCR + vec2<f32>(0.5,0.5)));
          let newValue = getImage(
            bInd, sourceNearestCR.y, sourceNearestCR.x, d);
          setOutputAtIndex(index, newValue);
        }
      }
    }
    `;
            return userCode;
        }
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const cropAndResize = (args) => {
        const { inputs, backend, attrs } = args;
        const { image, boxes, boxInd } = inputs;
        const { cropSize, method, extrapolationValue } = attrs;
        const program = new CropAndResizeProgram(image.shape[3], boxes.shape, cropSize, method);
        const uniformData = [{ type: 'float32', data: [extrapolationValue] }];
        return backend.runWebGPUProgram(program, [image, boxes, boxInd], 'float32', uniformData);
    };
    const cropAndResizeConfig = {
        kernelName: tf.CropAndResize,
        backendName: 'webgpu',
        kernelFunc: cropAndResize
    };

    /**
     * @license
     * Copyright 2022 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    var CumOpType;
    (function (CumOpType) {
        CumOpType["Prod"] = "*";
        CumOpType["Sum"] = "+";
    })(CumOpType || (CumOpType = {}));
    class CumProgram {
        constructor(op, shape, exclusive, reverse) {
            this.variableNames = ['x'];
            // pow(i32, i32) is not supported, use pow(f32, f32) instead.
            this.uniforms = 'index : f32,';
            this.size = true;
            this.workgroupSize = [128, 1, 1];
            this.outputShape = shape;
            this.dispatchLayout = flatDispatchLayout(this.outputShape);
            this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
            this.exclusive = exclusive;
            this.reverse = reverse;
            this.op = op;
            this.shaderKey = `cum_${this.op}_${this.exclusive}_${this.reverse}`;
        }
        getUserCode() {
            const rank = this.outputShape.length;
            const initVal = this.op === CumOpType.Prod ? '1.0' : '0.0';
            const val = this.exclusive ? initVal :
                `getX(${getCoords$1(rank, 'coords', this.op)})`;
            const length = this.outputShape[this.outputShape.length - 1];
            let condition = '';
            let idxString = '';
            // When exclusive is set, the cum op becomes roll op that copies the
            // value from the previous index based on the direction specified by the
            // reverse flag.
            if (this.exclusive) {
                condition = this.reverse ? `end != ${length - 1}` : 'end != 0';
                idxString = this.reverse ? 'end + 1' : 'end - 1';
            }
            else {
                condition = this.reverse ? `end + pow2 < ${length}` : 'end >= pow2';
                idxString = (this.reverse ? 'end + pow2' : 'end - pow2');
            }
            return `
      ${getMainHeaderString('index')} {
       if (index < uniforms.size) {
         var coords = getCoordsFromIndex(index);

         let end = ${getFinalCoord(rank, 'coords', this.op)};
         var val = ${val};
         let pow2 = i32(pow(2.0, uniforms.index));
         if (${condition}) {
           let idx = ${idxString};
           ${getFinalCoord(rank, 'coords', this.op)} = idx;
           val ${this.op}= getX(${getCoords$1(rank, 'coords', this.op)});
         }
         setOutputAtIndex(index, val);
       }
      }
    `;
        }
    }
    function getCoords$1(rank, name, op) {
        if (rank === 1) {
            return `${name}`;
        }
        else if (rank === 2) {
            return `${name}.x, ${name}.y`;
        }
        else if (rank === 3) {
            return `${name}.x, ${name}.y, ${name}.z`;
        }
        else if (rank === 4) {
            return `${name}.x, ${name}.y, ${name}.z, ${name}.w`;
        }
        else {
            throw Error(`Cumulative ${op} for rank ${rank} is not yet supported`);
        }
    }
    function getFinalCoord(rank, name, op) {
        if (rank === 1) {
            return `${name}`;
        }
        else if (rank === 2) {
            return `${name}.y`;
        }
        else if (rank === 3) {
            return `${name}.z`;
        }
        else if (rank === 4) {
            return `${name}.w`;
        }
        else {
            throw Error(`Cumulative ${op} for rank ${rank} is not yet supported`);
        }
    }

    /**
     * @license
     * Copyright 2022 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function cumImpl(op, x, backend, axis, exclusive, reverse) {
        const xRank = x.shape.length;
        const permutation = tf.backend_util.getAxesPermutation([axis], xRank);
        let permutedX = x;
        if (permutation != null) {
            permutedX = transpose({ inputs: { x }, backend, attrs: { perm: permutation } });
        }
        const permutedAxis = tf.backend_util.getInnerMostAxes(1, xRank)[0];
        if (permutedAxis !== xRank - 1) {
            throw new Error(`WebGPU cumprod shader expects an inner-most axis=${x.shape.length - 1} ` +
                `but got axis=${axis}`);
        }
        const size = permutedX.shape[permutedAxis];
        let result = identity({ inputs: { x: permutedX }, backend });
        // Use cum parallel algorithm, inspired by:
        // https://developer.nvidia.com/gpugems/gpugems3/part-vi-gpu-computing/chapter-39-parallel-prefix-sum-scan-cuda
        // Note: although the algorithm is called sum, it works for any associtative
        // operator with an identity.
        for (let i = 0; i <= Math.ceil(Math.log2(size)) - 1; i++) {
            const program = new CumProgram(op, permutedX.shape, false, reverse);
            const prevResult = result;
            const uniformData = [{ type: 'float32', data: [i] }];
            result =
                backend.runWebGPUProgram(program, [result], result.dtype, uniformData);
            backend.disposeData(prevResult.dataId);
        }
        // For exclusive cum, shift the end result in the direction of product or sum
        // and add 1 for product or 0 for sum to the front index.
        if (exclusive) {
            const program = new CumProgram(op, permutedX.shape, exclusive, reverse);
            const prevResult = result;
            const uniformData = [{ type: 'float32', data: [0] }];
            result =
                backend.runWebGPUProgram(program, [result], result.dtype, uniformData);
            backend.disposeData(prevResult.dataId);
        }
        if (permutation != null) {
            const reversePermutation = tf.backend_util.getUndoAxesPermutation(permutation);
            const reverseTransposedResult = transpose({ inputs: { x: result }, backend, attrs: { perm: reversePermutation } });
            backend.disposeData(result.dataId);
            backend.disposeData(permutedX.dataId);
            return reverseTransposedResult;
        }
        return result;
    }

    /**
     * @license
     * Copyright 2022 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function cumprod(args) {
        const { inputs, backend, attrs } = args;
        const { x } = inputs;
        const { axis, exclusive, reverse } = attrs;
        return cumImpl(CumOpType.Prod, x, backend, axis, exclusive, reverse);
    }
    const cumprodConfig = {
        kernelName: tf.Cumprod,
        backendName: 'webgpu',
        kernelFunc: cumprod
    };

    /**
     * @license
     * Copyright 2022 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function cumsum(args) {
        const { inputs, backend, attrs } = args;
        const { x } = inputs;
        const { axis, exclusive, reverse } = attrs;
        return cumImpl(CumOpType.Sum, x, backend, axis, exclusive, reverse);
    }
    const cumsumConfig = {
        kernelName: tf.Cumsum,
        backendName: 'webgpu',
        kernelFunc: cumsum
    };

    /**
     * @license
     * Copyright 2022 Google LLC.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function denseBincount(args) {
        const { inputs, backend, attrs } = args;
        const { x, weights } = inputs;
        const { size, binaryOutput } = attrs;
        const xRankOne = x.shape.length === 1;
        const weightsSize = tf.util.sizeFromShape(weights.shape);
        const hasWeights = weightsSize > 0;
        const dtype = weights.dtype;
        const xSize = xRankOne ? [x.shape[0]] : [x.shape[0], x.shape[1]];
        const outputSize = xRankOne ? [size] : [x.shape[0], size];
        const output = fill({ backend, attrs: { shape: outputSize, value: 0, dtype } });
        const program = new BincountProgram(xSize, hasWeights, binaryOutput);
        const uniformData = [{ type: 'int32', data: [size] }];
        const bincountInputs = hasWeights ? [x, weights] : [x];
        const res = backend.runWebGPUProgram(program, bincountInputs, dtype, uniformData, output);
        return res;
    }
    const denseBincountConfig = {
        kernelName: tf.DenseBincount,
        backendName: 'webgpu',
        kernelFunc: denseBincount
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    class DepthToSpaceProgram {
        constructor(outputShape, dataFormat) {
            this.variableNames = ['x'];
            this.workgroupSize = [64, 1, 1];
            this.size = true;
            this.uniforms = 'blockSize : i32,';
            this.outputShape = outputShape;
            this.dispatchLayout = flatDispatchLayout(this.outputShape);
            this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
            this.shaderKey = `depthToSpace_${dataFormat}`;
            this.dataFormat = dataFormat;
        }
        getUserCode() {
            const userCode = `
      ${getMainHeaderString('index')} {
        if (index < uniforms.size) {
          let coords = getCoordsFromIndex(index);
          let b = coords[0];
          let h = ${this.getHeightCoordString()};
          let w = ${this.getWidthCoordString()};
          let d = ${this.getDepthCoordString()};

          let in_h = h / uniforms.blockSize;
          let offset_h = h % uniforms.blockSize;
          let in_w = w / uniforms.blockSize;
          let offset_w = w % uniforms.blockSize;
          let offset_d = (offset_h * uniforms.blockSize + offset_w) *
            ${this.getOutputDepthSize()};
          let in_d = d + offset_d;

          let rlt = ${this.getInputSamplingString()};
          setOutputAtIndex(index, rlt);
        }
      }`;
            return userCode;
        }
        getHeightCoordString() {
            if (this.dataFormat === 'NHWC') {
                return `coords[1]`;
            }
            else {
                return `coords[2]`;
            }
        }
        getWidthCoordString() {
            if (this.dataFormat === 'NHWC') {
                return `coords[2]`;
            }
            else {
                return `coords[3]`;
            }
        }
        getDepthCoordString() {
            if (this.dataFormat === 'NHWC') {
                return `coords[3]`;
            }
            else {
                return `coords[1]`;
            }
        }
        getOutputDepthSize() {
            if (this.dataFormat === 'NHWC') {
                return `uniforms.outShape[3]`;
            }
            else {
                return `uniforms.outShape[1]`;
            }
        }
        getInputSamplingString() {
            if (this.dataFormat === 'NHWC') {
                return `getX(b, in_h, in_w, in_d)`;
            }
            else {
                return `getX(b, in_d, in_h, in_w)`;
            }
        }
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function depthToSpace(args) {
        const { inputs, backend, attrs } = args;
        const { x } = inputs;
        const { blockSize, dataFormat } = attrs;
        const batchSize = x.shape[0];
        const inputHeight = (dataFormat === 'NHWC') ? x.shape[1] : x.shape[2];
        const inputWidth = (dataFormat === 'NHWC') ? x.shape[2] : x.shape[3];
        const inputDepth = (dataFormat === 'NHWC') ? x.shape[3] : x.shape[1];
        const outputHeight = inputHeight * blockSize;
        const outputWidth = inputWidth * blockSize;
        const outputDepth = inputDepth / (blockSize * blockSize);
        const outputShape = (dataFormat === 'NHWC') ?
            [batchSize, outputHeight, outputWidth, outputDepth] :
            [batchSize, outputDepth, outputHeight, outputWidth];
        const uniformData = [
            { type: 'int32', data: [blockSize] },
        ];
        const program = new DepthToSpaceProgram(outputShape, dataFormat);
        return backend.runWebGPUProgram(program, [x], x.dtype, uniformData);
    }
    const depthToSpaceConfig = {
        kernelName: tf.DepthToSpace,
        backendName: 'webgpu',
        kernelFunc: depthToSpace
    };

    /**
     * @license
     * Copyright 2022 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    class DepthwiseConv2DNCHWSharedProgram {
        constructor(outputShape, filterHeight, filterWidth, addBias = false, activation = null, hasPreluActivation = false) {
            this.variableNames = ['x', 'W'];
            this.uniforms = `pad : vec2<i32>, inDims : vec2<i32>,`;
            this.workgroupSize = [16, 16, 1];
            this.outputShape = outputShape;
            this.dispatchLayout = { x: [3], y: [2], z: [0, 1] };
            this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
            if (addBias) {
                this.variableNames.push('bias');
            }
            if (hasPreluActivation) {
                this.variableNames.push('preluActivationWeights');
            }
            this.addBias = addBias;
            this.activation = activation;
            this.hasPreluActivation = hasPreluActivation;
            this.filterHeight = filterHeight;
            this.filterWidth = filterWidth;
            this.shaderKey = `depthwiseNCHW_${this.activation}_${this.filterHeight}_${this.filterWidth}`;
        }
        getUserCode() {
            const filterSize = this.filterWidth * this.filterHeight;
            const flatWorkgroupSize = this.workgroupSize[0] * this.workgroupSize[1] * this.workgroupSize[2];
            const tileAHeight = this.workgroupSize[1] + this.filterHeight - 1;
            const tileAWidth = this.workgroupSize[0] + this.filterWidth - 1;
            const userCode = `
      ${activationFnSnippet(this.activation, this.hasPreluActivation, false, 4)}

      var<workgroup> mm_Asub : array<array<f32, ${tileAWidth}>, ${tileAHeight}>;
      var<workgroup> mm_Bsub : array<array<f32, ${this.filterWidth}>, ${this.filterHeight}>;
      fn readX(batch : i32, channel : i32, row : i32, col : i32) -> f32 {
        var value = 0.0;
        if (row >=0 && row < uniforms.inDims[0] && col >=0 && col < uniforms.inDims[1])
        {
          value = getX(batch, channel, row, col);
        }
        return value;
      }

      ${getMainHeaderString()} {
        let coords = getOutputCoords();
        let batch = coords[0];
        let xRCCorner = vec2<i32>(coords.zw) - uniforms.pad;
        let channelMul = uniforms.wShape[3];
        let d1 = coords[1] / channelMul;
        let q = coords[1] % channelMul;

        let inputRowStart = xRCCorner.x;
        let inputColStart = xRCCorner.y;

        let localRow = i32(localId.y);
        let localCol = i32(localId.x);

        // Load one tile of X into local memory.
        for (var inputRow = localRow; inputRow < ${tileAHeight}; inputRow = inputRow + ${this.workgroupSize[1]}) {
          for (var inputCol = localCol; inputCol < ${tileAWidth}; inputCol = inputCol + ${this.workgroupSize[0]}) {
            let rowOffset = inputRow - localRow;
            let colOffset = inputCol - localCol;
            mm_Asub[inputRow][inputCol] = readX(batch, d1, inputRowStart + rowOffset, inputColStart + colOffset);
          }
        }

        // Load one tile of W into local memory.
        var wIndex = i32(localIndex);
        ${filterSize < flatWorkgroupSize ?
            `if (wIndex < ${filterSize})` :
            `for(; wIndex < ${filterSize}; wIndex = wIndex + ${flatWorkgroupSize})`}

        {
          let wRow = wIndex / ${this.filterWidth};
          let wCol = wIndex % ${this.filterWidth};
          mm_Bsub[wRow][wCol] = getW(wRow, wCol, d1, q);
        }

        workgroupBarrier();

        var value = 0.0;
        for (var wR = 0; wR < ${this.filterHeight}; wR = wR + 1) {
          for (var wC = 0; wC < ${this.filterWidth}; wC = wC + 1) {
            let xVal = mm_Asub[localRow + wR][localCol + wC];
            let wVal = mm_Bsub[wR][wC];
            value = fma(xVal, wVal, value);
          }
        }
        ${biasActivationSnippet(this.addBias, this.activation)}
        if (coordsInBounds4D(coords, uniforms.outShape)) {
          setOutputAtCoords(coords[0], coords[1], coords[2], coords[3], value);
        }
      }
    `;
            return userCode;
        }
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    class DepthwiseConv2DVec4Program {
        constructor(convInfo, addBias = false, activation = null, hasPreluActivation = false) {
            this.variableNames = ['x', 'W'];
            this.uniforms = 'pad : vec2<i32>, inDims : vec2<i32>,';
            this.workgroupSize = [4, 4, 4];
            this.workPerThread = 4;
            this.isVec4 = true;
            this.outputShape = convInfo.outShape;
            this.dispatchLayout = { x: [3], y: [2], z: [0, 1] };
            this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize, [4, this.workPerThread, 1]);
            tf.util.assert(convInfo.dataFormat === 'channelsLast', () => 'TODO: NCHW is unimplemented');
            if (addBias) {
                this.variableNames.push('bias');
            }
            if (hasPreluActivation) {
                this.variableNames.push('preluActivationWeights');
            }
            this.convInfo = convInfo;
            this.addBias = addBias;
            this.activation = activation;
            this.hasPreluActivation = hasPreluActivation;
            this.shaderKey =
                `depthwiseVec4_${activation}_${this.convInfo.filterHeight}_${this.convInfo.filterWidth}_${this.convInfo.strideHeight}_${this.convInfo.strideWidth}_${this.workPerThread}`;
        }
        getUserCode() {
            const xNumber = (this.workPerThread - 1) * this.convInfo.strideWidth +
                this.convInfo.filterWidth;
            const strideHeight = this.convInfo.strideHeight;
            const strideWidth = this.convInfo.strideWidth;
            const userCode = `
      ${activationFnSnippet(this.activation, this.hasPreluActivation, true, 4)}
      fn readX(batch : i32, row : i32, col : i32, channel : i32) -> vec4<f32> {
        var value = vec4<f32>(0.0);
        if (col >=0 && col < uniforms.inDims[1]) {
          value = getX(batch, row, col, channel);
        }
        return value;
      }

      ${getMainHeaderString()} {
        let batch = i32(globalId.z) / uniforms.outShape[1];
        let r = i32(globalId.z) % uniforms.outShape[1];
        let c = i32(globalId.y) * ${this.workPerThread};
        let d1 = i32(globalId.x) * 4;
        let xRCCorner = vec2<i32>(r, c) * vec2<i32>(${strideHeight}, ${strideWidth}) - uniforms.pad;

        let xRCorner = xRCCorner.x;
        let xCCorner = xRCCorner.y;
        var xVals : array<vec4<f32>, ${xNumber}>;
        var dotProd : array<vec4<f32>, ${this.workPerThread}>;
        for (var i = 0; i < ${this.workPerThread}; i++) {
          dotProd[i] = vec4<f32>(0.0);
        }

        // Use constant instead of uniform can give better performance.
        for (var wR = 0; wR < ${this.convInfo.filterHeight}; wR = wR + 1) {
          let xR = xRCorner + wR;
          if (xR >=0 && xR < uniforms.inDims[0]) {
            for (var i = 0; i < ${xNumber}; i++) {
              xVals[i] = readX(batch, xR, xCCorner + i, d1);
            }
            for (var wC = 0; wC < ${this.convInfo.filterWidth}; wC = wC + 1) {
              let wValue = getW(wR, wC, d1, 0);
              for (var i = 0; i < ${this.workPerThread}; i++) {
                dotProd[i] = fma(xVals[i * ${strideWidth} + wC], wValue, dotProd[i]);
              }
            }
          }
        }

        for (var i = 0; i < ${this.workPerThread}; i = i + 1) {
          let coords = vec4<i32>(batch, r, c + i, d1);
          if (coordsInBounds4D(coords, uniforms.outShape)) {
            var value = dotProd[i];
            ${biasActivationSnippet(this.addBias, this.activation)}
            setOutputAtCoords(coords[0], coords[1], coords[2], coords[3], value);
          }
        }
      }
    `;
            return userCode;
        }
    }

    /**
     * @license
     * Copyright 2019 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    class DepthwiseConv2DProgram {
        constructor(convInfo, addBias = false, activation = null, hasPreluActivation = false) {
            this.variableNames = ['x', 'W'];
            this.uniforms = `pad : vec2<i32>, inDims : vec2<i32>, filterHeight : i32,
      filterWidth : i32, stride : vec2<i32>, dilation : vec2<i32>,`;
            // This is an experimental value.
            this.workgroupSize = [256, 1, 1];
            this.size = true;
            this.outputShape = convInfo.outShape;
            this.dispatchLayout = flatDispatchLayout(this.outputShape);
            this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
            this.isChannelsLast = convInfo.dataFormat === 'channelsLast';
            if (addBias) {
                this.variableNames.push('bias');
            }
            if (hasPreluActivation) {
                this.variableNames.push('preluActivationWeights');
            }
            this.convInfo = convInfo;
            this.addBias = addBias;
            this.activation = activation;
            this.hasPreluActivation = hasPreluActivation;
            this.shaderKey = `depthwise_${this.activation}_${this.isChannelsLast}`;
        }
        getUserCode() {
            const getXSnippet = this.isChannelsLast ? 'getX(batch, xR, xC, d1);' :
                'getX(batch, d1, xR, xC);';
            const userCode = `
      ${activationFnSnippet(this.activation, this.hasPreluActivation, false, 4)}

      ${getMainHeaderString('index')} {
        if (index < uniforms.size) {
          let coords = getOutputCoords();
          let batch = coords[0];
          let xRCCorner = vec2<i32>(coords.${this.isChannelsLast ? 'yz' : 'zw'}) * uniforms.stride - uniforms.pad;
          let d2 = coords[${this.isChannelsLast ? 3 : 1}];
          let channelMul = uniforms.wShape[3];
          let d1 = d2 / channelMul;
          let q = d2 % channelMul;

          let inputRowStart = xRCCorner.x;
          let inputColStart = xRCCorner.y;
          let inputRowEnd = inputRowStart + uniforms.filterHeight *
              uniforms.dilation[0];
          let inputColEnd = inputColStart + uniforms.filterWidth *
              uniforms.dilation[1];

          // Convolve x(?, ?, d1)|x(d1, ?, ?) with w(:, :, d1, q) to get
          // y(yR, yC, d2)|y(d2, yR, yC). ? = to be determined. : = across all
          // values in that axis. x(?, ?, d1) and y(yR, yC, d2) is for NHWC.
          // x(d1, ?, ?) and y(d2, yR, yC) is for NCHW.
          var value = 0.0;

          // Extract if checking out of for loop for performance.
          if (inputRowStart >= 0 && inputColStart >= 0 &&
            inputRowEnd < uniforms.inDims[0] &&
                inputColEnd < uniforms.inDims[1]) {
              for (var wR = 0; wR < uniforms.filterHeight; wR = wR + 1) {
                let xR = inputRowStart + wR * uniforms.dilation[0];

                for (var wC = 0; wC < uniforms.filterWidth; wC = wC + 1) {
                  let xC = inputColStart + wC * uniforms.dilation[1];

                  let xVal = ${getXSnippet};
                  let wVal = getW(wR, wC, d1, q);
                  value = value + xVal * wVal;
                }
              }
            } else {
              for (var wR = 0; wR < uniforms.filterHeight; wR = wR + 1) {
                let xR = inputRowStart + wR * uniforms.dilation[0];

                if (xR < 0 || xR >= uniforms.inDims[0]) {
                  continue;
                }

                for (var wC = 0; wC < uniforms.filterWidth; wC = wC + 1) {
                  let xC = inputColStart + wC * uniforms.dilation[1];

                  if (xC < 0 || xC >= uniforms.inDims[1]) {
                    continue;
                  }

                  let xVal = ${getXSnippet};
                  let wVal = getW(wR, wC, d1, q);
                  value = value + xVal * wVal;
                }
              }
            }
            ${biasActivationSnippet(this.addBias, this.activation)}
          setOutputAtCoords(coords[0], coords[1], coords[2], coords[3], value);
        }
      }
    `;
            return userCode;
        }
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function depthwiseConv2dNative(args) {
        const { inputs, backend, attrs } = args;
        const { x, filter } = inputs;
        const { strides, pad, dataFormat, dilations, dimRoundingMode } = attrs;
        const $dataFormat = tf.backend_util.convertConv2DDataFormat(dataFormat);
        let $dilations = dilations;
        if ($dilations == null) {
            $dilations = [1, 1];
        }
        const convInfo = tf.backend_util.computeConv2DInfo(x.shape, filter.shape, strides, $dilations, pad, dimRoundingMode, true /* depthwise */, $dataFormat);
        const dimensions = [
            { type: 'int32', data: [convInfo.padInfo.top, convInfo.padInfo.left] },
            { type: 'int32', data: [convInfo.inHeight, convInfo.inWidth] },
        ];
        const isChannelsLast = convInfo.dataFormat === 'channelsLast';
        let program;
        if (!isChannelsLast && convInfo.inHeight > 16 && convInfo.inWidth > 16 &&
            convInfo.strideHeight === 1 && convInfo.strideWidth === 1 &&
            convInfo.dilationWidth === 1 && convInfo.dilationHeight === 1 &&
            convInfo.inChannels === convInfo.outChannels) {
            program = new DepthwiseConv2DNCHWSharedProgram(convInfo.outShape, convInfo.filterHeight, convInfo.filterWidth);
        }
        else if (isChannelsLast && convInfo.outHeight > 4 && convInfo.outWidth > 4 &&
            convInfo.strideWidth <= 2 &&
            convInfo.inChannels === convInfo.outChannels &&
            convInfo.dilationHeight === 1 && convInfo.dilationWidth === 1 &&
            convInfo.inChannels % 4 === 0) {
            program = new DepthwiseConv2DVec4Program(convInfo);
        }
        else {
            program = new DepthwiseConv2DProgram(convInfo);
            dimensions.push({ type: 'int32', data: [convInfo.filterHeight] }, { type: 'int32', data: [convInfo.filterWidth] }, { type: 'int32', data: [convInfo.strideHeight, convInfo.strideWidth] }, {
                type: 'int32',
                data: [convInfo.dilationHeight, convInfo.dilationWidth]
            });
        }
        return backend.runWebGPUProgram(program, [x, filter], x.dtype, dimensions);
    }
    const depthwiseConv2dNativeConfig = {
        kernelName: tf.DepthwiseConv2dNative,
        backendName: 'webgpu',
        kernelFunc: depthwiseConv2dNative,
    };

    /**
     * @license
     * Copyright 2022 Google LLC.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    class DiagProgram {
        constructor(size) {
            this.variableNames = ['x'];
            this.workgroupSize = [64, 1, 1];
            this.size = true;
            this.outputShape = [size, size];
            this.dispatchLayout = flatDispatchLayout(this.outputShape);
            this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
            this.shaderKey = 'diag';
        }
        getUserCode() {
            const userCode = `
      ${getMainHeaderString('index')} {
        if (index < uniforms.size) {
          let coords = getOutputCoords();
          let value = select(0.0, getX(coords[0]), coords[0] == coords[1]);
          setOutputAtIndex(index, value);
        }
      }
    `;
            return userCode;
        }
    }

    /**
     * @license
     * Copyright 2022 Google LLC.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function diag(args) {
        const { inputs, backend } = args;
        const { x } = inputs;
        const outShape = [...x.shape, ...x.shape];
        const xSize = tf.util.sizeFromShape(x.shape);
        const flat = reshape({ inputs: { x }, backend, attrs: { shape: [xSize] } });
        const program = new DiagProgram(xSize);
        const res = backend.runWebGPUProgram(program, [flat], flat.dtype);
        const out = reshape({ inputs: { x: res }, backend, attrs: { shape: outShape } });
        backend.disposeData(flat.dataId);
        backend.disposeData(res.dataId);
        return out;
    }
    const diagConfig = {
        kernelName: tf.Diag,
        backendName: 'webgpu',
        kernelFunc: diag
    };

    /**
     * @license
     * Copyright 2022 Google LLC.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    class Dilation2DProgram {
        constructor(convInfo) {
            this.variableNames = ['x', 'w'];
            this.uniforms = 'filterDims: vec2<i32>, pad: vec2<i32>, stride: vec2<i32>, dilation: vec2<i32>';
            this.workgroupSize = [64, 1, 1];
            this.size = true;
            this.outputShape = convInfo.outShape;
            this.dispatchLayout = flatDispatchLayout(this.outputShape);
            this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
            this.shaderKey = 'dilation2d';
        }
        getUserCode() {
            const userCode = `
       ${getMainHeaderString('index')} {
         if (index < uniforms.size) {
           let neg_infinity = -3.4e38;
           let coords = getOutputCoords();
           let batch = coords.x;
           let d1 = coords.w;
           let outTopLeftCorner = coords.yz * uniforms.stride - uniforms.pad;
           let hBeg = outTopLeftCorner.x;
           let wBeg = outTopLeftCorner.y;

           var curVal = neg_infinity;
           for (var h = 0; h < uniforms.filterDims[0]; h = h + 1) {
             let hIn = hBeg + h * uniforms.dilation[0];

             if (hIn >= 0 && hIn < uniforms.xShape[1]) {
               for (var w = 0; w < uniforms.filterDims[1]; w = w + 1) {
                 let wIn = wBeg + w * uniforms.dilation[1];

                 if (wIn >= 0 && wIn < uniforms.xShape[2]) {
                   let val = getX(batch, hIn, wIn, d1) + getW(h, w, d1);
                   if (val > curVal) {
                     curVal = val;
                   }
                 }
               }
             }
           }

           setOutputAtIndex(index, curVal);
         }
       }
     `;
            return userCode;
        }
    }

    /**
     * @license
     * Copyright 2022 Google LLC.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function dilation2D(args) {
        const { inputs, backend, attrs } = args;
        const { x, filter } = inputs;
        const { strides, pad, dilations } = attrs;
        const convInfo = tf.backend_util.computeDilation2DInfo(x.shape, filter.shape, strides, pad, 'NHWC' /* dataFormat */, dilations);
        const padInfo = [convInfo.padInfo.top, convInfo.padInfo.left];
        const uniformData = [
            { type: 'int32', data: [convInfo.filterHeight, convInfo.filterWidth] },
            { type: 'int32', data: [...padInfo] },
            { type: 'int32', data: [convInfo.strideHeight, convInfo.strideWidth] },
            { type: 'int32', data: [convInfo.dilationHeight, convInfo.dilationWidth] }
        ];
        const program = new Dilation2DProgram(convInfo);
        const out = backend.runWebGPUProgram(program, [x, filter], x.dtype, uniformData);
        return out;
    }
    const dilation2DConfig = {
        kernelName: tf.Dilation2D,
        backendName: 'webgpu',
        kernelFunc: dilation2D
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const multiplyKernelFunc = binaryKernelFunc({
        opType: BinaryOpType.MUL,
        cpuKernelImpl: multiplyImplCPU,
        supportsComplex: true
    });
    const multiplyConfig = {
        kernelName: tf.Multiply,
        backendName: 'webgpu',
        kernelFunc: multiplyKernelFunc
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function sum(args) {
        const { inputs, backend, attrs } = args;
        const { x } = inputs;
        const { axis, keepDims } = attrs;
        return reduce(x, axis, keepDims, 'sum', backend);
    }
    const sumConfig = {
        kernelName: tf.Sum,
        backendName: 'webgpu',
        kernelFunc: sum
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function einsum(args) {
        const { inputs, backend, attrs } = args;
        const { equation } = attrs;
        const tensors = inputs;
        const { allDims, summedDims, idDims } = tf.backend_util.decodeEinsumEquation(equation, tensors.length);
        tf.backend_util.checkEinsumDimSizes(allDims.length, idDims, tensors);
        const { path, steps } = tf.backend_util.getEinsumComputePath(summedDims, idDims);
        const nSteps = steps.length;
        let out = null;
        let numDimsRemaining = allDims.length;
        const tensorsToDispose = [];
        for (let i = 0; i < nSteps; ++i) {
            for (const idTerm of steps[i]) {
                const { permutationIndices: perm, expandDims: dimsToExpand } = tf.backend_util.getEinsumPermutation(numDimsRemaining, idDims[idTerm]);
                let x;
                if (tf.backend_util.isIdentityPermutation(perm)) {
                    x = tensors[idTerm];
                }
                else {
                    x = transpose({ inputs: { x: tensors[idTerm] }, backend, attrs: { perm } });
                    tensorsToDispose.push(x);
                }
                const targetShape = x.shape.slice();
                for (let k = 0; k < dimsToExpand.length; ++k) {
                    targetShape.splice(dimsToExpand[k], 0, 1);
                }
                if (!tf.util.arraysEqual(x.shape, targetShape)) {
                    x = reshape({ inputs: { x }, backend, attrs: { shape: targetShape } });
                    tensorsToDispose.push(x);
                }
                if (out === null) {
                    out = x;
                }
                else {
                    // tslint:disable-next-line: no-unnecessary-type-assertion
                    out =
                        multiplyKernelFunc({ inputs: { a: x, b: out }, backend });
                    tensorsToDispose.push(out);
                }
            }
            if (i < nSteps - 1) {
                if (path[i] >= 0) {
                    out = sum({
                        inputs: { x: out },
                        backend,
                        attrs: {
                            axis: path[i] - (allDims.length - numDimsRemaining),
                            keepDims: false
                        }
                    });
                    tensorsToDispose.push(out);
                }
                numDimsRemaining--;
            }
        }
        // Clean up intermediate tensors.
        for (const tensorInfo of tensorsToDispose) {
            if (tensorInfo === out) {
                continue;
            }
            backend.disposeData(tensorInfo.dataId);
        }
        return out;
    }
    const einsumConfig = {
        kernelName: tf.Einsum,
        backendName: 'webgpu',
        kernelFunc: einsum
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const elu = unaryKernelFunc({ opType: UnaryOpType.ELU });
    const eluConfig = {
        kernelName: tf.Elu,
        backendName: 'webgpu',
        kernelFunc: elu
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const equal = binaryKernelFunc({ opType: BinaryOpType.EQUAL, dtype: 'bool', cpuKernelImpl: equalImplCPU });
    const equalConfig = {
        kernelName: tf.Equal,
        backendName: 'webgpu',
        kernelFunc: equal
    };

    /**
     * @license
     * Copyright 2022 Google LLC.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const erf = unaryKernelFunc({ opType: UnaryOpType.ERF });
    const erfConfig = {
        kernelName: tf.Erf,
        backendName: 'webgpu',
        kernelFunc: erf
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const exp = unaryKernelFunc({
        opType: UnaryOpType.EXP,
        cpuKernelImpl: expImplCPU,
        dtype: 'float32',
    });
    const expConfig = {
        kernelName: tf.Exp,
        backendName: 'webgpu',
        kernelFunc: exp
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the License);
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an AS IS BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function expandDims(args) {
        const { inputs, attrs, backend } = args;
        const { dim } = attrs;
        const { input } = inputs;
        const inputRank = input.shape.length;
        const newShape = input.shape.slice();
        let $dim = dim;
        if (dim < 0) {
            // Negative value is counted from the tail of rank.
            tf.util.assert(-(inputRank + 1) <= dim, () => `Axis must be in the interval [${-(inputRank + 1)}, ${inputRank}]`);
            $dim = inputRank + dim + 1;
        }
        newShape.splice($dim, 0, 1);
        return reshape({ inputs: { x: input }, backend, attrs: { shape: newShape } });
    }
    const expandDimsConfig = {
        kernelName: tf.ExpandDims,
        backendName: 'webgpu',
        kernelFunc: expandDims,
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const expm1 = unaryKernelFunc({ opType: UnaryOpType.EXPM1, cpuKernelImpl: expm1ImplCPU });
    const expm1Config = {
        kernelName: tf.Expm1,
        backendName: 'webgpu',
        kernelFunc: expm1
    };

    /**
     * @license
     * Copyright 2022 Google LLC.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    class FFTProgram {
        constructor(component, shape) {
            this.variableNames = ['real', 'imag'];
            this.outputShape = [];
            this.uniforms = 'exponentMultiplier : f32, denominator: f32,';
            this.workgroupSize = [64, 1, 1];
            this.size = true;
            this.outputShape = shape;
            this.dispatchLayout = flatDispatchLayout(this.outputShape);
            this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
            this.component = component;
            this.shaderKey = `fft_${component}`;
        }
        getUserCode() {
            const opString = this.component === 'real' ?
                'return real * expR - imag * expI;' :
                'return real * expI + imag * expR;';
            const userCode = `
    fn unaryOpComplex(real: f32, expR: f32, imag: f32, expI: f32) -> f32 {
      ${opString}
    }

    fn mulMatDFT(batch: i32, index: i32) -> f32 {
      let indexRatio = f32(index) / f32(uniforms.realShape[1]);
      let exponentMultiplierTimesIndexRatio =
          uniforms.exponentMultiplier * indexRatio;

      var result = 0.0;

      for (var i = 0; i < uniforms.realShape[1]; i = i + 1) {
        // x = (-2|2 * PI / N) * index * i;
        let x = exponentMultiplierTimesIndexRatio * f32(i);
        let expR = cos(x);
        let expI = sin(x);
        let real = getReal(batch, i);
        let imag = getImag(batch, i);

        result = result +
            unaryOpComplex(real, expR, imag, expI) / uniforms.denominator;
      }

      return result;
    }

    ${getMainHeaderString('index')} {
      if (index < uniforms.size) {
        let coords = getOutputCoords();
        setOutputAtIndex(index, mulMatDFT(coords[0], coords[1]));
      }
    }
  `;
            return userCode;
        }
    }

    /**
     * @license
     * Copyright 2022 Google LLC.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function fftImpl(x, inverse, backend) {
        const xData = backend.tensorMap.get(x.dataId);
        const inputSize = tf.util.sizeFromShape(x.shape);
        // Collapse all outer dimensions to a single batch dimension.
        const innerDimensionSize = x.shape[x.shape.length - 1];
        const batch = inputSize / innerDimensionSize;
        const toDispose = [];
        const input2D = reshape({ inputs: { x }, backend, attrs: { shape: [batch, innerDimensionSize] } });
        toDispose.push(input2D);
        const xShape = input2D.shape;
        const realProgram = new FFTProgram('real', xShape);
        const imagProgram = new FFTProgram('imag', xShape);
        const inputs = [
            {
                dataId: xData.complexTensorInfos.real.dataId,
                dtype: xData.complexTensorInfos.real.dtype,
                shape: xShape
            },
            {
                dataId: xData.complexTensorInfos.imag.dataId,
                dtype: xData.complexTensorInfos.imag.dtype,
                shape: xShape
            }
        ];
        const exponentMultiplier = inverse ? 2.0 * Math.PI : -2.0 * Math.PI;
        const denominator = inverse ? xShape[1] : 1.0;
        const uniformData = [
            { type: 'float32', data: [exponentMultiplier] },
            { type: 'float32', data: [denominator] }
        ];
        const realPart = backend.runWebGPUProgram(realProgram, inputs, 'float32', uniformData);
        toDispose.push(realPart);
        const imagPart = backend.runWebGPUProgram(imagProgram, inputs, 'float32', uniformData);
        toDispose.push(imagPart);
        const complexOutput = complex({ inputs: { real: realPart, imag: imagPart }, backend });
        toDispose.push(complexOutput);
        const complexOutputReshaped = reshape({ inputs: { x: complexOutput }, backend, attrs: { shape: x.shape } });
        toDispose.forEach(t => backend.disposeData(t.dataId));
        return complexOutputReshaped;
    }

    /**
     * @license
     * Copyright 2022 Google LLC.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function fft(args) {
        const { inputs, backend } = args;
        const { input } = inputs;
        return fftImpl(input, false /* inverse */, backend);
    }
    const fftConfig = {
        kernelName: tf.FFT,
        backendName: 'webgpu',
        kernelFunc: fft
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    class FlipLeftRightProgram {
        constructor(imageShape) {
            this.outputShape = [];
            this.variableNames = ['x'];
            this.workgroupSize = [64, 1, 1];
            this.size = true;
            this.outputShape = imageShape;
            this.dispatchLayout = flatDispatchLayout(this.outputShape);
            this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
            this.shaderKey = 'flipLeftRight';
        }
        getUserCode() {
            const userCode = `
      ${getMainHeaderString('index')} {
        if (index < uniforms.size) {
          let coords = getCoordsFromIndex(index);
          let coordX = uniforms.xShape[2] - coords[2] - 1;
          let outputValue = getX(coords[0], coords[1], coordX, coords[3]);
          setOutputAtIndex(index, outputValue);
        }
      }
    `;
            return userCode;
        }
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const flipLeftRightConfig = {
        kernelName: tf.FlipLeftRight,
        backendName: 'webgpu',
        kernelFunc: ({ inputs, backend }) => {
            const { image } = inputs;
            const webgpuBackend = backend;
            const program = new FlipLeftRightProgram(image.shape);
            const output = webgpuBackend.runWebGPUProgram(program, [image], image.dtype);
            return output;
        }
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const floor = unaryKernelFunc({ opType: UnaryOpType.FLOOR, cpuKernelImpl: floorImplCPU });
    const floorConfig = {
        kernelName: tf.Floor,
        backendName: 'webgpu',
        kernelFunc: floor
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const floorDiv = binaryKernelFunc({ opType: BinaryOpType.INT_DIV, dtype: 'int32' });
    const floorDivConfig = {
        kernelName: tf.FloorDiv,
        backendName: 'webgpu',
        kernelFunc: floorDiv
    };

    /**
     * @license
     * Copyright 2022 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    class FromPixelsProgram {
        constructor(outputShape, numChannels, importVideo = false) {
            this.isFromPixels = true;
            this.outputShape = [0];
            this.variableNames = [];
            this.workgroupSize = [256, 1, 1]; // The empirical value.
            this.outputShape = outputShape;
            this.dispatchLayout = flatDispatchLayout(this.outputShape);
            this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize, [numChannels, 1, 1]);
            this.importVideo = importVideo;
            this.shaderKey = `fromPixels_${this.importVideo}`;
        }
        getUserCode() {
            const textureLoad = this.importVideo ?
                'textureLoad(src, vec2<i32>(coords.yx));' :
                'textureLoad(src, vec2<i32>(coords.yx), 0)';
            const textureType = this.importVideo ? 'texture_external' : 'texture_2d<f32>';
            return `
      @binding(1) @group(0) var src: ${textureType};
      ${getMainHeaderString('index')} {
        let flatIndex = index * uniforms.numChannels;
        if (flatIndex < uniforms.size) {
          let coords = getCoordsFromIndex(flatIndex);
          let values = ${textureLoad};
          for (var i = 0; i < uniforms.numChannels; i = i + 1) {
            result[flatIndex + i] = i32(floor(255.0 * values[i]));
          }
        }
      }
  `;
        }
    }

    /**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use backend file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const fromPixelsConfig = {
        kernelName: tf.FromPixels,
        backendName: 'webgpu',
        kernelFunc: fromPixels,
    };
    let fromPixels2DContext;
    let willReadFrequently = tf.env().getBool('CANVAS2D_WILL_READ_FREQUENTLY_FOR_GPU');
    function fromPixels(args) {
        const { inputs, backend, attrs } = args;
        let { pixels } = inputs;
        const { numChannels } = attrs;
        if (pixels == null) {
            throw new Error('pixels passed to tf.browser.fromPixels() can not be null');
        }
        const isVideo = typeof (HTMLVideoElement) !== 'undefined' &&
            pixels instanceof HTMLVideoElement;
        const isImage = typeof (HTMLImageElement) !== 'undefined' &&
            pixels instanceof HTMLImageElement;
        const isCanvas = (typeof (HTMLCanvasElement) !== 'undefined' &&
            pixels instanceof HTMLCanvasElement) ||
            (typeof (OffscreenCanvas) !== 'undefined' &&
                pixels instanceof OffscreenCanvas);
        const isImageBitmap = typeof (ImageBitmap) !== 'undefined' && pixels instanceof ImageBitmap;
        const [width, height] = isVideo ?
            [
                pixels.videoWidth,
                pixels.videoHeight
            ] :
            [pixels.width, pixels.height];
        const outputShape = [height, width, numChannels];
        // Disable importExternalTexture temporarily as it has problem in spec and
        // browser impl
        const importVideo = false  ;
        const isVideoOrImage = isVideo || isImage;
        if (isImageBitmap || isCanvas || isVideoOrImage) {
            let textureInfo;
            {
                if (isVideoOrImage) {
                    const newWillReadFrequently = tf.env().getBool('CANVAS2D_WILL_READ_FREQUENTLY_FOR_GPU');
                    if (fromPixels2DContext == null ||
                        newWillReadFrequently !== willReadFrequently) {
                        willReadFrequently = newWillReadFrequently;
                        fromPixels2DContext =
                            document.createElement('canvas').getContext('2d', { willReadFrequently });
                    }
                    fromPixels2DContext.canvas.width = width;
                    fromPixels2DContext.canvas.height = height;
                    fromPixels2DContext.drawImage(pixels, 0, 0, width, height);
                    pixels = fromPixels2DContext.canvas;
                }
                const usage = GPUTextureUsage.COPY_DST |
                    GPUTextureUsage.RENDER_ATTACHMENT | GPUTextureUsage.TEXTURE_BINDING;
                const format = 'rgba8unorm';
                const texture = backend.textureManager.acquireTexture(outputShape[1], outputShape[0], format, usage);
                backend.queue.copyExternalImageToTexture({ source: pixels }, { texture }, [outputShape[1], outputShape[0]]);
                textureInfo = { width, height, format, usage, texture };
            }
            const size = tf.util.sizeFromShape(outputShape);
            const strides = tf.util.computeStrides(outputShape);
            const program = new FromPixelsProgram(outputShape, numChannels, importVideo);
            const uniformData = [
                { type: 'uint32', data: [size] }, { type: 'uint32', data: [numChannels] },
                { type: 'uint32', data: [...strides] }
            ];
            const input = backend.makeTensorInfo([height, width], 'int32');
            const info = backend.tensorMap.get(input.dataId);
            info.resourceInfo = textureInfo;
            const result = backend.runWebGPUProgram(program, [input], 'int32', uniformData);
            backend.disposeData(input.dataId);
            return result;
        }
        // TODO: Encoding should happen on GPU once we no longer have to download
        // image data to the CPU.
        const imageData = pixels.data;
        let pixelArray = imageData;
        if (numChannels != null && numChannels !== 4) {
            pixelArray = new Uint8Array(pixels.width * pixels.height * numChannels);
            const dataLength = imageData.length;
            let j = 0;
            for (let i = 0; i < dataLength; i++) {
                if (i % 4 < numChannels) {
                    pixelArray[j++] = imageData[i];
                }
            }
        }
        const output = backend.makeTensorInfo(outputShape, 'int32', new Int32Array(pixelArray));
        backend.uploadToGPU(output.dataId);
        return output;
    }

    /**
     * @license
     * Copyright 2019 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    class BatchNormProgram {
        constructor(xShape, meanShape, varianceShape, offsetShape, scaleShape) {
            this.uniforms = 'varianceEpsilon : f32,';
            // This is an experimental value.
            this.workgroupSize = [128, 1, 1];
            this.size = true;
            this.variableNames = ['x', 'mean', 'variance'];
            tf.backend_util.assertAndGetBroadcastShape(xShape, meanShape);
            tf.backend_util.assertAndGetBroadcastShape(xShape, varianceShape);
            this.outputShape = xShape;
            this.dispatchLayout = flatDispatchLayout(this.outputShape);
            this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
            if (offsetShape != null) {
                tf.backend_util.assertAndGetBroadcastShape(xShape, offsetShape);
                this.variableNames.push('offset');
            }
            if (scaleShape != null) {
                tf.backend_util.assertAndGetBroadcastShape(xShape, scaleShape);
                this.variableNames.push('scale');
            }
            this.offsetShape = offsetShape;
            this.scaleShape = scaleShape;
            this.shaderKey = 'batchNorm';
        }
        getUserCode() {
            let offsetSnippet = '0.0';
            if (this.offsetShape != null) {
                offsetSnippet = 'getOffsetByOutputIndex(index)';
            }
            let scaleSnippet = '1.0';
            if (this.scaleShape != null) {
                scaleSnippet = 'getScaleByOutputIndex(index)';
            }
            const userCode = `
      ${getMainHeaderString('index')} {
        if (index < uniforms.size)
        {
          let xValue = getXByOutputIndex(index);
          let meanValue = getMeanByOutputIndex(index);
          let varianValue = getVarianceByOutputIndex(index);
          let offsetValue = ${offsetSnippet};
          let scaleValue = ${scaleSnippet};
          let inv = scaleValue * inverseSqrt(varianValue + f32(uniforms.varianceEpsilon));
          setOutputAtIndex(index,dot(vec3<f32>(xValue, -meanValue, offsetValue), vec3<f32>(inv, inv, 1.0)));
        }
      }
  `;
            return userCode;
        }
    }

    /**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const fusedBatchNormConfig = {
        kernelName: tf.FusedBatchNorm,
        backendName: 'webgpu',
        kernelFunc: ({ inputs, attrs, backend }) => {
            const { x, scale, offset, mean, variance } = inputs;
            const { varianceEpsilon } = attrs;
            const webGPUBackend = backend;
            const batchNormInputs = [x, mean, variance];
            let offsetShape = null;
            if (offset != null) {
                offsetShape = offset.shape;
                batchNormInputs.push(offset);
            }
            let scaleShape = null;
            if (scale != null) {
                scaleShape = scale.shape;
                batchNormInputs.push(scale);
            }
            const program = new BatchNormProgram(x.shape, mean.shape, variance.shape, offsetShape, scaleShape);
            const uniformData = [{ type: 'float32', data: [varianceEpsilon] }];
            return webGPUBackend.runWebGPUProgram(program, batchNormInputs, x.dtype, uniformData);
        }
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function fusedConv2d(args) {
        const { inputs, backend, attrs } = args;
        const { x, filter, bias, preluActivationWeights } = inputs;
        const { strides, pad, dataFormat, dilations, dimRoundingMode, activation, leakyreluAlpha } = attrs;
        const $dataFormat = tf.backend_util.convertConv2DDataFormat(dataFormat);
        const convInfo = tf.backend_util.computeConv2DInfo(x.shape, filter.shape, strides, dilations, pad, dimRoundingMode, false /* depthwise */, $dataFormat);
        return conv2DImpl({
            x,
            filter,
            convInfo,
            backend,
            bias,
            preluActivationWeights,
            leakyreluAlpha,
            activation
        });
    }
    const fusedConv2DConfig = {
        kernelName: tf.FusedConv2D,
        backendName: 'webgpu',
        kernelFunc: fusedConv2d,
    };

    /**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function fusedDepthwiseConv2D(args) {
        const { inputs, backend, attrs } = args;
        const { x, filter, bias, preluActivationWeights } = inputs;
        const { strides, pad, dilations, dimRoundingMode, activation, leakyreluAlpha } = attrs;
        let $dilations = dilations;
        if ($dilations == null) {
            $dilations = [1, 1];
        }
        tf.util.assert(tf.backend_util.eitherStridesOrDilationsAreOne(strides, $dilations), () => 'Error in depthwiseConv2d: Either strides or dilations must be ' +
            `1. Got strides ${strides} and dilations '${$dilations}'`);
        const convInfo = tf.backend_util.computeConv2DInfo(x.shape, filter.shape, strides, $dilations, pad, dimRoundingMode, true /* depthwise */);
        const programInputs = [x, filter];
        const hasBias = bias != null;
        const hasPreluActivationWeights = preluActivationWeights != null;
        if (hasBias) {
            programInputs.push(bias);
        }
        if (hasPreluActivationWeights) {
            programInputs.push(preluActivationWeights);
        }
        const dimensions = [
            { type: 'int32', data: [convInfo.padInfo.top, convInfo.padInfo.left] },
            { type: 'int32', data: [convInfo.inHeight, convInfo.inWidth] },
        ];
        let program;
        if (convInfo.outHeight > 4 && convInfo.outWidth > 4 &&
            convInfo.strideWidth <= 2 &&
            convInfo.inChannels === convInfo.outChannels &&
            convInfo.dilationHeight === 1 && convInfo.dilationWidth === 1 &&
            convInfo.inChannels % 4 === 0) {
            program = new DepthwiseConv2DVec4Program(convInfo, hasBias, activation, hasPreluActivationWeights);
        }
        else {
            program = new DepthwiseConv2DProgram(convInfo, hasBias, activation, hasPreluActivationWeights);
            dimensions.push({ type: 'int32', data: [convInfo.filterHeight] }, { type: 'int32', data: [convInfo.filterWidth] }, { type: 'int32', data: [convInfo.strideHeight, convInfo.strideWidth] }, {
                type: 'int32',
                data: [convInfo.dilationHeight, convInfo.dilationWidth]
            });
        }
        if (activation === 'leakyrelu') {
            dimensions.push({ type: 'float32', data: [leakyreluAlpha] });
            program.uniforms += ' alpha : f32,';
        }
        const result = backend.runWebGPUProgram(program, programInputs, 'float32', dimensions);
        return result;
    }
    const fusedDepthwiseConv2DConfig = {
        kernelName: tf.FusedDepthwiseConv2D,
        backendName: 'webgpu',
        kernelFunc: fusedDepthwiseConv2D,
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    class GatherNDProgram {
        constructor(sliceDim, shape) {
            this.variableNames = ['A', 'indices'];
            this.workgroupSize = [64, 1, 1];
            this.size = true;
            this.outputShape = shape;
            this.dispatchLayout = flatDispatchLayout(this.outputShape);
            this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
            this.shaderKey = `gathernd_${sliceDim}`;
            this.sliceDim = sliceDim;
            this.uniforms = `sliceDim : i32, strides : ${getCoordsDataType(sliceDim)},`;
        }
        getUserCode() {
            let strideString;
            if (this.sliceDim > 1) {
                strideString = 'uniforms.strides[j]';
            }
            else {
                strideString = 'uniforms.strides';
            }
            const userCode = `
      ${getMainHeaderString('index')} {
        if (index < uniforms.size) {
          let coords = getCoordsFromIndex(index);
          var flattenIndex = 0;
          for (var j = 0; j < uniforms.sliceDim; j = j + 1) {
            let indexTemp = i32(round(getIndices(coords[0], j)));
            let strideNum = ${strideString};
            flattenIndex = flattenIndex + indexTemp * strideNum;
          }

          setOutputAtIndex(index, getA(flattenIndex, coords[1]));
        }
      }
      `;
            return userCode;
        }
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function gatherNd(args) {
        const { inputs, backend } = args;
        const { params, indices } = inputs;
        const indicesShape = indices.shape;
        const sliceRank = indicesShape[indicesShape.length - 1];
        const paramsSize = tf.util.sizeFromShape(params.shape);
        const [resultShape, numSlices, sliceSize, strides] = tf.backend_util.prepareAndValidate(params, indices);
        const flattenIndices = reshape({ inputs: { x: indices }, backend, attrs: { shape: [numSlices, sliceRank] } });
        const flattenX = reshape({
            inputs: { x: params },
            backend,
            attrs: { shape: [(tf.util.sizeFromShape(params.shape) / sliceSize), sliceSize] }
        });
        if (backend.shouldExecuteOnCPU([params, indices]) ||
            params.dtype === 'string') {
            const indicesData = backend.readSync(indices.dataId);
            const paramsBuf = backend.bufferSync(params);
            const outValue = gatherNdImplCPU(indicesData, paramsBuf, params.dtype, numSlices, sliceRank, sliceSize, strides, params.shape, paramsSize);
            return backend.makeTensorInfo(resultShape, params.dtype, outValue.values);
        }
        const program = new GatherNDProgram(sliceRank, [numSlices, sliceSize]);
        const uniformData = [{ type: 'int32', data: [sliceRank] }, { type: 'int32', data: strides }];
        const res = backend.runWebGPUProgram(program, [flattenX, flattenIndices], flattenX.dtype, uniformData);
        const reshaped = reshape({ inputs: { x: res }, backend, attrs: { shape: resultShape } });
        backend.disposeData(flattenIndices.dataId);
        backend.disposeData(flattenX.dataId);
        backend.disposeData(res.dataId);
        return reshaped;
    }
    const gatherNdConfig = {
        kernelName: tf.GatherNd,
        backendName: 'webgpu',
        kernelFunc: gatherNd
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    class GatherProgram {
        constructor(aShape, outputShape) {
            this.variableNames = ['A', 'indices'];
            this.workgroupSize = [64, 1, 1];
            this.size = true;
            this.outputShape = aShape.slice();
            this.aShape = aShape;
            this.outputShape = outputShape;
            this.dispatchLayout = flatDispatchLayout(this.outputShape);
            this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
            this.shaderKey = `gather`;
        }
        getUserCode() {
            const sourceCoords = getSourceCoords(this.aShape);
            const userCode = `
      ${getMainHeaderString('index')} {
        if (index < uniforms.size) {
          let resRC = getCoordsFromIndex(index);
          let indexZ = i32(getIndices(resRC.x, resRC.z));
          let inBounds = select(0.0, 1.0, indexZ >= 0 && indexZ < uniforms.aShape[2]);
          setOutputAtIndex(index, inBounds * getA(${sourceCoords}));
        }
      }
    `;
            return userCode;
        }
    }
    // The input and output are always flattened into rank 4 tensors.
    function getSourceCoords(aShape) {
        const currentCoords = ['resRC.x', 'resRC.y', 'resRC.z', 'resRC.w'];
        const sourceCoords = [];
        for (let i = 0; i < aShape.length; i++) {
            if (i === 2) {
                sourceCoords.push('indexZ');
            }
            else {
                sourceCoords.push(`${currentCoords[i]}`);
            }
        }
        return sourceCoords.join();
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function gatherV2(args) {
        const { inputs, backend, attrs } = args;
        const { x, indices } = inputs;
        const { axis, batchDims } = attrs;
        // Unlike WebGL, WebGPU won't check if index is out of bound by calling
        // backend.readSync() function in debug mode.
        const parsedAxis = tf.util.parseAxisParam(axis, x.shape)[0];
        const shapeInfo = tf.backend_util.segment_util.collectGatherOpShapeInfo(x, indices, parsedAxis, batchDims);
        const indicesSize = tf.util.sizeFromShape(indices.shape);
        const toDispose = [];
        const flattenX = reshape({
            inputs: { x },
            backend,
            attrs: {
                shape: [
                    shapeInfo.batchSize, shapeInfo.outerSize, shapeInfo.dimSize,
                    shapeInfo.sliceSize
                ]
            }
        });
        const flattenIndex = reshape({
            inputs: { x: indices },
            backend,
            attrs: { shape: [shapeInfo.batchSize, indicesSize / shapeInfo.batchSize] }
        });
        toDispose.push(flattenX);
        toDispose.push(flattenIndex);
        const flattenOutputShape = [
            shapeInfo.batchSize, shapeInfo.outerSize, indicesSize / shapeInfo.batchSize,
            shapeInfo.sliceSize
        ];
        if (backend.shouldExecuteOnCPU([x, indices])) {
            const indicesBufferInfo = backend.tensorMap.get(flattenIndex.dataId);
            const indicesValues = indicesBufferInfo.values;
            const indicesBuf = tf.buffer(flattenIndex.shape, flattenIndex.dtype, indicesValues);
            const xBufferInfo = backend.tensorMap.get(flattenX.dataId);
            const xValues = xBufferInfo.values;
            const xBuf = tf.buffer(flattenX.shape, flattenX.dtype, xValues);
            const outBuf = gatherV2ImplCPU(xBuf, indicesBuf, flattenOutputShape);
            toDispose.forEach(t => backend.disposeData(t.dataId));
            return backend.makeTensorInfo(shapeInfo.outputShape, outBuf.dtype, outBuf.values);
        }
        const program = new GatherProgram(flattenX.shape, flattenOutputShape);
        const res = backend.runWebGPUProgram(program, [flattenX, flattenIndex], flattenX.dtype);
        toDispose.push(res);
        const reshaped = reshape({ inputs: { x: res }, backend, attrs: { shape: shapeInfo.outputShape } });
        toDispose.forEach(t => backend.disposeData(t.dataId));
        return reshaped;
    }
    const gatherV2Config = {
        kernelName: tf.GatherV2,
        backendName: 'webgpu',
        kernelFunc: gatherV2
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const greater = binaryKernelFunc({
        opType: BinaryOpType.GREATER,
        cpuKernelImpl: greaterImplCPU,
        dtype: 'bool',
    });
    const greaterConfig = {
        kernelName: tf.Greater,
        backendName: 'webgpu',
        kernelFunc: greater
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const greaterEqual = binaryKernelFunc({
        opType: BinaryOpType.GREATER_EQUAL,
        dtype: 'bool',
        cpuKernelImpl: greaterEqualImplCPU
    });
    const greaterEqualConfig = {
        kernelName: tf.GreaterEqual,
        backendName: 'webgpu',
        kernelFunc: greaterEqual
    };

    /**
     * @license
     * Copyright 2022 Google LLC.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function ifft(args) {
        const { inputs, backend } = args;
        const { input } = inputs;
        return fftImpl(input, true /* inverse */, backend);
    }
    const ifftConfig = {
        kernelName: tf.IFFT,
        backendName: 'webgpu',
        kernelFunc: ifft
    };

    /**
     * @license
     * Copyright 2022 Google LLC.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const isFinite = unaryKernelFunc({ opType: UnaryOpType.IS_FINITE, dtype: 'bool' });
    const isFiniteConfig = {
        kernelName: tf.IsFinite,
        backendName: 'webgpu',
        kernelFunc: isFinite
    };

    /**
     * @license
     * Copyright 2022 Google LLC.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const isInf = unaryKernelFunc({ opType: UnaryOpType.IS_INF, dtype: 'bool' });
    const isInfConfig = {
        kernelName: tf.IsInf,
        backendName: 'webgpu',
        kernelFunc: isInf
    };

    /**
     * @license
     * Copyright 2022 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const isNaN = unaryKernelFunc({ opType: UnaryOpType.IS_NAN, dtype: 'bool' });
    const isNaNConfig = {
        kernelName: tf.IsNan,
        backendName: 'webgpu',
        kernelFunc: isNaN
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function leakyRelu(args) {
        const { inputs, backend, attrs } = args;
        const { x } = inputs;
        const { alpha } = attrs;
        const uniformData = [{ type: 'float32', data: [alpha] }];
        const program = new UnaryOpProgram(x.shape, UnaryOpType.LEAKYRELU, 'alpha : f32,');
        return backend.runWebGPUProgram(program, [x], 'float32', uniformData);
    }
    const leakyReluConfig = {
        kernelName: tf.LeakyRelu,
        backendName: 'webgpu',
        kernelFunc: leakyRelu
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const less = binaryKernelFunc({ opType: BinaryOpType.LESS, dtype: 'bool', cpuKernelImpl: lessImplCPU });
    const lessConfig = {
        kernelName: tf.Less,
        backendName: 'webgpu',
        kernelFunc: less
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const lessEqual = binaryKernelFunc({
        opType: BinaryOpType.LESS_EQUAL,
        dtype: 'bool',
        cpuKernelImpl: lessEqualImplCPU
    });
    const lessEqualConfig = {
        kernelName: tf.LessEqual,
        backendName: 'webgpu',
        kernelFunc: lessEqual
    };

    /**
     * @license
     * Copyright 2022 Google LLC.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    class LinSpaceProgram {
        constructor(shape) {
            this.variableNames = [];
            this.outputShape = [];
            this.uniforms = 'start : f32, step : f32,';
            this.workgroupSize = [64, 1, 1];
            this.size = true;
            this.outputShape = [shape];
            this.dispatchLayout = flatDispatchLayout(this.outputShape);
            this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
            this.shaderKey = 'linSpace';
        }
        getUserCode() {
            const userCode = `
      ${getMainHeaderString('index')} {
        if (index < uniforms.size) {
          setOutputAtIndex(index, uniforms.start + f32(index) * uniforms.step);
        }
      }
    `;
            return userCode;
        }
    }

    /**
     * @license
     * Copyright 2022 Google LLC.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function linSpace(args) {
        const { backend, attrs } = args;
        const { start, stop, num } = attrs;
        const step = (stop - start) / (num - 1);
        const program = new LinSpaceProgram(num);
        const uniformData = [{ type: 'float32', data: [start] }, { type: 'float32', data: [step] }];
        return backend.runWebGPUProgram(program, [], 'float32', uniformData);
    }
    const linSpaceConfig = {
        kernelName: tf.LinSpace,
        backendName: 'webgpu',
        kernelFunc: linSpace
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const log = unaryKernelFunc({ opType: UnaryOpType.LOG, cpuKernelImpl: logImplCPU });
    const logConfig = {
        kernelName: tf.Log,
        backendName: 'webgpu',
        kernelFunc: log
    };

    /**
     * @license
     * Copyright 2022 Google LLC.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const log1p = unaryKernelFunc({ opType: UnaryOpType.LOG1P });
    const log1pConfig = {
        kernelName: tf.Log1p,
        backendName: 'webgpu',
        kernelFunc: log1p
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const logicalAnd = binaryKernelFunc({ opType: BinaryOpType.LOGICAL_AND, dtype: 'bool' });
    const logicalAndConfig = {
        kernelName: tf.LogicalAnd,
        backendName: 'webgpu',
        kernelFunc: logicalAnd
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const logicalNot = unaryKernelFunc({ opType: UnaryOpType.LOGICAL_NOT });
    const logicalNotConfig = {
        kernelName: tf.LogicalNot,
        backendName: 'webgpu',
        kernelFunc: logicalNot
    };

    /**
     * @license
     * Copyright 2022 Google LLC.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const logicalOr = binaryKernelFunc({ opType: BinaryOpType.LOGICAL_OR });
    const logicalOrConfig = {
        kernelName: tf.LogicalOr,
        backendName: 'webgpu',
        kernelFunc: logicalOr
    };

    /**
     * @license
     * Copyright 2022 Google LLC.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const powOperatorSnippet = `
  var powValue = 0.0;
  let basis = uniforms.bias + uniforms.alpha * sum;
  if (uniforms.beta == 0.5) {
    powValue = inverseSqrt(basis);
  } else if (uniforms.beta == 1.0) {
    powValue = 1.0 / basis;
  } else {
    powValue = exp(log(basis) * (-uniforms.beta));
  }
`;
    class LRNProgram {
        constructor(xShape) {
            this.outputShape = [];
            this.variableNames = ['x'];
            this.uniforms = 'radius : i32, bias : f32, alpha : f32, beta : f32,';
            this.workgroupSize = [64, 1, 1];
            this.size = true;
            this.outputShape = xShape;
            this.dispatchLayout = flatDispatchLayout(this.outputShape);
            this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
            this.shaderKey = 'lrn';
        }
        getUserCode() {
            const userCode = `
    ${getMainHeaderString('index')} {
      if (index < uniforms.size) {
        let coords = getOutputCoords();
        let b = coords[0];
        let r = coords[1];
        let c = coords[2];
        let d = coords[3];

        let x = getX(b, r, c, d);
        var sum = 0.0;
        for (var i = -uniforms.radius; i <= uniforms.radius; i = i + 1) {
          let idx = d + i;
          if (idx >= 0 && idx < uniforms.xShape[3]) {
            let z = getX(b, r, c, idx);
            sum = sum + z * z;
          }
        }
        ${powOperatorSnippet}

        setOutputAtIndex(index, x * powValue);
      }
    }
  `;
            return userCode;
        }
    }
    class LRNSharedProgram {
        constructor(xShape, radius) {
            this.outputShape = [];
            this.variableNames = ['x'];
            this.uniforms = 'radius : i32, bias : f32, alpha : f32, beta : f32,';
            this.workgroupSize = [256, 1, 1];
            this.maxAllowRadius = 16;
            tf.util.assert(radius <= this.maxAllowRadius, () => `Radius must be less than or equal to ${this.maxAllowRadius}, current radius is ${radius}`);
            this.outputShape = xShape;
            // The reason why not using this.workgroupSize[0] + 2 * maxAllowRadius here
            // is to make sure that there is only one time global memory load access for
            // each thread.
            this.elementsPerWorkgroup = this.workgroupSize[0] - 2 * this.maxAllowRadius;
            this.dispatchLayout = { x: [3], y: [2], z: [0, 1] };
            this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, [
                this.elementsPerWorkgroup, this.workgroupSize[1], this.workgroupSize[2]
            ]);
            this.shaderKey = 'lrn_shared';
        }
        getUserCode() {
            const userCode = `
    var <workgroup>lrnSub: array<f32, ${this.workgroupSize[0]}>;
    const elementsPerWorkgroup = ${this.elementsPerWorkgroup};
    const maxAllowRadius = ${this.maxAllowRadius};

    ${getMainHeaderString()} {
      let localDepth = i32(localId.x);
      let workgroupDepth = i32(workgroupId.x) * elementsPerWorkgroup;
      let xDepth = workgroupDepth + localDepth - maxAllowRadius;
      let b = i32(globalId.z) / uniforms.xShape[1];
      let r = i32(globalId.z) - b * uniforms.xShape[1];
      let c = i32(globalId.y);
      let d = workgroupDepth + localDepth;

      var x = 0.0;
      if (xDepth >= 0 && xDepth < uniforms.xShape[3]) {
        x = getX(b, r, c, xDepth);
      }
      lrnSub[localDepth] = x;
      workgroupBarrier();

      if (localDepth < elementsPerWorkgroup && d < uniforms.outShape[3]) {
        var sum = 0.0;
        let index = localDepth + maxAllowRadius;
        for (var i = -uniforms.radius; i <= uniforms.radius; i = i + 1) {
          let z = lrnSub[index + i];
          sum = sum + z * z;
        }
        ${powOperatorSnippet}

        setOutputAtCoords(b, r, c, d, lrnSub[index] * powValue);
      }
    } `;
            return userCode;
        }
    }

    /**
     * @license
     * Copyright 2022 Google LLC.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function lrn(args) {
        const { inputs, backend, attrs } = args;
        const { x } = inputs;
        const { depthRadius, bias, alpha, beta } = attrs;
        // When the adjacent channels is less than or equal to 16, which could cover
        // most cases, we use shared memory version to get better performance.
        // The theoretical adjacent channels may be very large, but the shared memory
        // size of hardware is limited, so we use the naive version when the adjacent
        // channels is large.
        let program;
        if (depthRadius > 16) {
            program = new LRNProgram(x.shape);
        }
        else {
            program = new LRNSharedProgram(x.shape, depthRadius);
        }
        const uniformData = [
            { type: 'int32', data: [depthRadius] }, { type: 'float32', data: [bias] },
            { type: 'float32', data: [alpha] }, { type: 'float32', data: [beta] }
        ];
        const res = backend.runWebGPUProgram(program, [x], x.dtype, uniformData);
        return res;
    }
    const lrnConfig = {
        kernelName: tf.LRN,
        backendName: 'webgpu',
        kernelFunc: lrn
    };

    /**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const maximum = binaryKernelFunc({
        opType: BinaryOpType.MAX,
        cpuKernelImpl: maximumImplCPU,
    });
    const maximumConfig = {
        kernelName: tf.Maximum,
        backendName: 'webgpu',
        kernelFunc: maximum
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function maxPool(args) {
        const { inputs, backend, attrs } = args;
        const { x } = inputs;
        const { filterSize, strides, pad, dimRoundingMode } = attrs;
        const dilations = 1;
        const convInfo = tf.backend_util.computePool2DInfo(x.shape, filterSize, strides, dilations, pad, dimRoundingMode);
        return poolImpl(x, convInfo, 'max', backend);
    }
    const maxPoolConfig = {
        kernelName: tf.MaxPool,
        backendName: 'webgpu',
        kernelFunc: maxPool
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function min(args) {
        const { inputs, backend, attrs } = args;
        const { x } = inputs;
        const { axis, keepDims } = attrs;
        return reduce(x, axis, keepDims, 'min', backend);
    }
    const minConfig = {
        kernelName: tf.Min,
        backendName: 'webgpu',
        kernelFunc: min
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const minimum = binaryKernelFunc({
        opType: BinaryOpType.MIN,
        cpuKernelImpl: minimumImplCPU,
    });
    const minimumConfig = {
        kernelName: tf.Minimum,
        backendName: 'webgpu',
        kernelFunc: minimum
    };

    /**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    class MirrorPadProgram {
        constructor(xShape, paddings, mode) {
            this.uniforms = '';
            this.variableNames = ['x'];
            this.workgroupSize = [64, 1, 1];
            this.size = true;
            this.outputShape = paddings.map((p, i) => p[0] /* beforePad */ + xShape[i] + p[1] /* afterPad */);
            this.dispatchLayout = flatDispatchLayout(this.outputShape);
            this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
            this.xShape = xShape;
            paddings.map((_, i) => {
                this.uniforms += ` pad${i} : vec2<i32>,`;
            });
            this.offset = mode === 'reflect' ? 0 : 1;
            this.shaderKey = `mirrorPad_${mode}`;
        }
        getUserCode() {
            const rank = this.xShape.length;
            // The length of paddings are same with the rank of the input tensor.
            const start = this.xShape.map((_, i) => `uniforms.pad${i}[0]`).join(',');
            const end = this.xShape
                .map((_, i) => `uniforms.pad${i}[0] + uniforms.xShape${rank > 1 ? `[${i}]` : ''}`)
                .join(',');
            const shaderStart = rank === 1 ? 'start' : 'start[i]';
            const shaderEnd = rank === 1 ? 'end' : 'end[i]';
            const shaderOutC = rank === 1 ? 'outC' : 'outC[i]';
            const dtype = getCoordsDataType(rank);
            const unpackedCoords = rank > 1 ?
                ['coords[0]', 'coords[1]', 'coords[2]', 'coords[3]'].slice(0, rank) :
                'coords';
            return `
      ${getMainHeaderString('index')} {
        if (index < uniforms.size) {
          let start = ${dtype}(${start});
          let end = ${dtype}(${end});
          var outC = getCoordsFromIndex(index);
          for (var i = 0; i < ${rank}; i = i + 1) {
            if (${shaderOutC} < ${shaderStart}) {
              ${shaderOutC} = ${shaderStart} * 2 - ${shaderOutC} - ${this.offset};
            } else if(${shaderOutC} >= ${shaderEnd}) {
              ${shaderOutC} = (${shaderEnd} - 1) * 2 - ${shaderOutC} + ${this.offset};
            }
          }
          let coords = outC - start;
          setOutputAtIndex(index, getX(${unpackedCoords}));
        }
      }
    `;
        }
    }

    /**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const mirrorPadConfig = {
        kernelName: tf.MirrorPad,
        backendName: 'webgpu',
        kernelFunc: ({ inputs, attrs, backend }) => {
            const { x } = inputs;
            const { paddings, mode } = attrs;
            const webGPUBackend = backend;
            const uniformData = paddings.map(p => {
                return { type: 'int32', data: [p[0], p[1]] };
            });
            const program = new MirrorPadProgram(x.shape, paddings, mode);
            const output = webGPUBackend.runWebGPUProgram(program, [x], x.dtype, uniformData);
            return output;
        }
    };

    /**
     * @license
     * Copyright 2022 Google LLC.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const mod = binaryKernelFunc({ opType: BinaryOpType.MOD });
    const modConfig = {
        kernelName: tf.Mod,
        backendName: 'webgpu',
        kernelFunc: mod
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    // This doesn't use unaryKernelFunc because negImplCPU is not of type
    // SimpleUnaryKernelImplCPU.
    function neg(args) {
        const { inputs, backend } = args;
        const { x } = inputs;
        if (backend.shouldExecuteOnCPU([x])) {
            const xData = backend.tensorMap.get(x.dataId);
            const [outValues, newShape] = negImplCPU(xData.values, x.shape, x.dtype);
            return backend.makeTensorInfo(newShape, x.dtype, outValues);
        }
        const program = new UnaryOpProgram(x.shape, UnaryOpType.NEG);
        return backend.runWebGPUProgram(program, [x], x.dtype);
    }
    const negConfig = {
        kernelName: tf.Neg,
        backendName: 'webgpu',
        kernelFunc: neg
    };

    /**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function nonMaxSuppressionV3(args) {
        console.warn('tf.nonMaxSuppression() in webgpu locks the UI thread. ' +
            'Call tf.nonMaxSuppressionAsync() instead');
        const { inputs, backend, attrs } = args;
        const { boxes, scores } = inputs;
        const { maxOutputSize, iouThreshold, scoreThreshold } = attrs;
        const boxesVals = backend.readSync(boxes.dataId);
        const scoresVals = backend.readSync(scores.dataId);
        const { selectedIndices } = tf.kernel_impls.nonMaxSuppressionV3Impl(boxesVals, scoresVals, maxOutputSize, iouThreshold, scoreThreshold);
        return backend.makeTensorInfo([selectedIndices.length], 'int32', new Int32Array(selectedIndices));
    }
    const nonMaxSuppressionV3Config = {
        kernelName: tf.NonMaxSuppressionV3,
        backendName: 'webgpu',
        kernelFunc: nonMaxSuppressionV3
    };

    /**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function nonMaxSuppressionV5(args) {
        console.warn('tf.nonMaxSuppression() in webgpu locks the UI thread. ' +
            'Call tf.nonMaxSuppressionAsync() instead');
        const { inputs, backend, attrs } = args;
        const { boxes, scores } = inputs;
        const { maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma } = attrs;
        const boxesVals = backend.readSync(boxes.dataId);
        const scoresVals = backend.readSync(scores.dataId);
        const maxOutputSizeVal = maxOutputSize;
        const iouThresholdVal = iouThreshold;
        const scoreThresholdVal = scoreThreshold;
        const softNmsSigmaVal = softNmsSigma;
        const { selectedIndices, selectedScores } = tf.kernel_impls.nonMaxSuppressionV5Impl(boxesVals, scoresVals, maxOutputSizeVal, iouThresholdVal, scoreThresholdVal, softNmsSigmaVal);
        return [
            backend.makeTensorInfo([selectedIndices.length], 'int32', new Int32Array(selectedIndices)),
            backend.makeTensorInfo([selectedScores.length], 'float32', new Float32Array(selectedScores))
        ];
    }
    const nonMaxSuppressionV5Config = {
        kernelName: tf.NonMaxSuppressionV5,
        backendName: 'webgpu',
        kernelFunc: nonMaxSuppressionV5
    };

    /**
     * @license
     * Copyright 2022 Google LLC.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    class OneHotProgram {
        constructor(numIndices, depth) {
            this.variableNames = ['x'];
            this.uniforms = 'onValue : f32, offValue : f32,';
            this.workgroupSize = [64, 1, 1];
            this.size = true;
            this.outputShape = [numIndices, depth];
            this.dispatchLayout = flatDispatchLayout(this.outputShape);
            this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
            this.shaderKey = 'onehot';
        }
        getUserCode() {
            const userCode = `
      ${getMainHeaderString('index')} {
        if(index < uniforms.size) {
          let coords = getCoordsFromIndex(index);
          setOutputAtIndex(index, mix(uniforms.offValue, uniforms.onValue,
                                      f32(i32(round(getX(coords.x))) == coords.y)));
        }
      }
    `;
            return userCode;
        }
    }

    /**
     * @license
     * Copyright 2022 Google LLC.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function oneHot(args) {
        const { inputs, backend, attrs } = args;
        const { indices } = inputs;
        const { dtype, depth, onValue, offValue } = attrs;
        const indicesSize = tf.util.sizeFromShape(indices.shape);
        const program = new OneHotProgram(indicesSize, depth);
        const reshaped = reshape({ inputs: { x: indices }, backend, attrs: { shape: [indicesSize] } });
        const uniformData = [{ type: 'float32', data: [onValue] }, { type: 'float32', data: [offValue] }];
        const result = backend.runWebGPUProgram(program, [reshaped], dtype, uniformData);
        backend.disposeData(reshaped.dataId);
        const outShape = [...indices.shape, depth];
        const out = reshape({ inputs: { x: result }, backend, attrs: { shape: outShape } });
        backend.disposeData(result.dataId);
        return out;
    }
    const oneHotConfig = {
        kernelName: tf.OneHot,
        backendName: 'webgpu',
        kernelFunc: oneHot
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function zerosLike(args) {
        const { inputs, backend } = args;
        const { x } = inputs;
        if (x.dtype === 'complex64') {
            const realPart = real({ inputs: { input: x }, backend });
            const r = zerosLike({ inputs: { x: realPart }, backend });
            const imagPart = imag({ inputs: { input: x }, backend });
            const i = zerosLike({ inputs: { x: imagPart }, backend });
            const result = complex({ inputs: { real: r, imag: i }, backend });
            backend.disposeData(realPart.dataId);
            backend.disposeData(r.dataId);
            backend.disposeData(imagPart.dataId);
            backend.disposeData(i.dataId);
            return result;
        }
        else {
            return fill({
                attrs: {
                    shape: x.shape,
                    dtype: x.dtype,
                    value: x.dtype === 'string' ? '' : 0
                },
                backend
            });
        }
    }
    const zerosLikeConfig = {
        kernelName: tf.ZerosLike,
        backendName: 'webgpu',
        kernelFunc: zerosLike
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function onesLike(args) {
        const { inputs, backend } = args;
        const { x } = inputs;
        if (x.dtype === 'string') {
            throw new Error('onesLike is not supported under string dtype');
        }
        else if (x.dtype === 'complex64') {
            const realPart = real({ inputs: { input: x }, backend });
            const r = onesLike({ inputs: { x: realPart }, backend });
            const imagPart = imag({ inputs: { input: x }, backend });
            const i = zerosLike({ inputs: { x: imagPart }, backend });
            const result = complex({ inputs: { real: r, imag: i }, backend });
            backend.disposeData(realPart.dataId);
            backend.disposeData(r.dataId);
            backend.disposeData(imagPart.dataId);
            backend.disposeData(i.dataId);
            return result;
        }
        else {
            return fill({ attrs: { shape: x.shape, dtype: x.dtype, value: 1 }, backend });
        }
    }
    const onesLikeConfig = {
        kernelName: tf.OnesLike,
        backendName: 'webgpu',
        kernelFunc: onesLike
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function pack(args) {
        const { inputs, backend, attrs } = args;
        const { axis } = attrs;
        if (inputs.length === 1) {
            return expandDims({ inputs: { input: inputs[0] }, backend, attrs: { dim: axis } });
        }
        const shape = inputs[0].shape;
        const dtype = inputs[0].dtype;
        inputs.forEach(t => {
            tf.util.assertShapesMatch(shape, t.shape, 'All tensors passed to stack must have matching shapes');
            tf.util.assert(dtype === t.dtype, () => 'All tensors passed to stack must have matching dtypes');
        });
        const intermediateTensorInfos = [];
        const expandedTensors = inputs.map(t => {
            const expandedT = expandDims({ inputs: { input: t }, backend, attrs: { dim: axis } });
            intermediateTensorInfos.push(expandedT);
            return expandedT;
        });
        const result = concat({ inputs: expandedTensors, backend, attrs: { axis } });
        intermediateTensorInfos.forEach(t => backend.disposeData(t.dataId));
        return result;
    }
    const packConfig = {
        kernelName: tf.Pack,
        backendName: 'webgpu',
        kernelFunc: pack
    };

    /**
     * @license
     * Copyright 2019 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    class PadProgram {
        constructor(xShape, paddings) {
            this.variableNames = ['x'];
            this.uniforms = 'constantValue : f32,';
            this.workgroupSize = [64, 1, 1];
            this.size = true;
            this.outputShape = paddings.map((p, i) => p[0] /* beforePad */ + xShape[i] + p[1] /* afterPad */);
            this.dispatchLayout = flatDispatchLayout(this.outputShape);
            this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
            paddings.map((_, i) => {
                this.uniforms += ` pad${i} : vec2<i32>,`;
            });
            this.xShape = xShape;
            this.shaderKey = 'pad';
        }
        getUserCode() {
            const rank = this.xShape.length;
            const type = getCoordsDataType(rank);
            // The length of paddings are same with the rank of the input tensor.
            const start = this.xShape.map((_, i) => `uniforms.pad${i}[0]`).join(',');
            const end = this.xShape
                .map((_, i) => `uniforms.pad${i}[0] + uniforms.xShape${rank > 1 ? `[${i}]` : ''}`)
                .join(',');
            const startValue = rank > 1 ? `${type}(${start})` : `${start}`;
            const endValue = rank > 1 ? `${type}(${end})` : `${end}`;
            const leftPadCondition = rank > 1 ? `any(outC < start)` : `outC < start`;
            const rightPadCondition = rank > 1 ? `any(outC >= end)` : `outC >= end`;
            const unpackedCoords = rank > 1 ?
                ['coords[0]', 'coords[1]', 'coords[2]', 'coords[3]'].slice(0, rank) :
                'coords';
            const userCode = `
      ${getMainHeaderString('index')} {
        if (index < uniforms.size) {
          let start = ${startValue};
          let end = ${endValue};
          let outC = getCoordsFromIndex(index);

          if (${leftPadCondition} || ${rightPadCondition}) {
            setOutputAtIndex(index, uniforms.constantValue);
          } else {
            let coords = outC - start;
            setOutputAtIndex(index, getX(${unpackedCoords}));
          }
        }
      }
    `;
            return userCode;
        }
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const padV2 = (args) => {
        const { inputs, backend, attrs } = args;
        const { x } = inputs;
        const { paddings, constantValue } = attrs;
        if (paddings.every(p => tf.util.arraysEqual(p, [0, 0]))) {
            return identity({ inputs: { x }, backend });
        }
        if (tf.util.sizeFromShape(x.shape) === 0) {
            // Short-circuit the computation, since x doesn't have value, only
            // the shape is used to compute output shape to pad.
            const outputShape = paddings.map((p, i) => p[0] /* beforePad */ + x.shape[i] + p[1] /* afterPad */);
            return fill({
                backend,
                attrs: { shape: outputShape, value: constantValue, dtype: x.dtype }
            });
        }
        const uniformData = [{ type: 'float32', data: [constantValue] }];
        paddings.map(p => uniformData.push({ type: 'int32', data: [p[0], p[1]] }));
        const program = new PadProgram(x.shape, paddings);
        return backend.runWebGPUProgram(program, [x], x.dtype, uniformData);
    };
    const padV2Config = {
        kernelName: tf.PadV2,
        backendName: 'webgpu',
        kernelFunc: padV2
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const pow = binaryKernelFunc({
        opType: BinaryOpType.POW,
    });
    const powConfig = {
        kernelName: tf.Pow,
        backendName: 'webgpu',
        kernelFunc: pow
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function prelu(args) {
        const { inputs, backend } = args;
        const { x, alpha } = inputs;
        const program = new BinaryOpProgram(BinaryOpType.PRELU, x.shape, alpha.shape);
        return backend.runWebGPUProgram(program, [x, alpha], 'float32');
    }
    const preluConfig = {
        kernelName: tf.Prelu,
        backendName: 'webgpu',
        kernelFunc: prelu
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function prod(args) {
        const { inputs, backend, attrs } = args;
        const { x } = inputs;
        const { axis, keepDims } = attrs;
        return reduce(x, axis, keepDims, 'prod', backend);
    }
    const prodConfig = {
        kernelName: tf.Prod,
        backendName: 'webgpu',
        kernelFunc: prod
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const range = (args) => {
        const { backend, attrs } = args;
        const { start, stop, step, dtype } = attrs;
        const values = rangeImplCPU(start, stop, step, dtype);
        return backend.makeTensorInfo([values.length], dtype, values);
    };
    const rangeConfig = {
        kernelName: tf.Range,
        backendName: 'webgpu',
        kernelFunc: range
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const realDiv = binaryKernelFunc({ opType: BinaryOpType.DIV });
    const realDivConfig = {
        kernelName: tf.RealDiv,
        backendName: 'webgpu',
        kernelFunc: realDiv
    };

    /**
     * @license
     * Copyright 2022 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const reciprocal = unaryKernelFunc({ opType: UnaryOpType.RECIPROCAL });
    const reciprocalConfig = {
        kernelName: tf.Reciprocal,
        backendName: 'webgpu',
        kernelFunc: reciprocal
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const relu = unaryKernelFunc({ opType: UnaryOpType.RELU });
    const reluConfig = {
        kernelName: tf.Relu,
        backendName: 'webgpu',
        kernelFunc: relu
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const relu6 = unaryKernelFunc({ opType: UnaryOpType.RELU6 });
    const relu6Config = {
        kernelName: tf.Relu6,
        backendName: 'webgpu',
        kernelFunc: relu6
    };

    /**
     * @license
     * Copyright 2019 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    class ResizeBilinearProgram {
        constructor(inputShape, newHeight, newWidth) {
            this.variableNames = ['x'];
            this.uniforms = 'adjustHeightWidth : vec2<f32>, halfPixelCenters : f32,';
            this.workgroupSize = [64, 1, 1];
            this.size = true;
            this.outputShape = [inputShape[0], newHeight, newWidth, inputShape[3]];
            this.dispatchLayout = flatDispatchLayout(this.outputShape);
            this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
            this.shaderKey = `resizeBilinear`;
        }
        getUserCode() {
            const userCode = `
      ${getMainHeaderString('index')} {
        if (index < uniforms.size) {
        let coords = getCoordsFromIndex(index);
          let b = coords[0];
          let d = coords[3];
          let rc = coords.yz;

          let effectiveInSize = vec2<f32>(
            f32(uniforms.xShape.y) - uniforms.adjustHeightWidth[0],
            f32(uniforms.xShape.z) - uniforms.adjustHeightWidth[1]);

          let effectiveOutSize = vec2<f32>(
            f32(uniforms.outShape.y) - uniforms.adjustHeightWidth[0],
            f32(uniforms.outShape.z) - uniforms.adjustHeightWidth[1]);

          let effectiveInputOverOutputRatioRC =
              effectiveInSize / effectiveOutSize;

          // Fractional source index
          let sourceFracIndexRC =
            (vec2<f32>(rc) + vec2<f32>(uniforms.halfPixelCenters)) *
            effectiveInputOverOutputRatioRC - vec2<f32>(uniforms.halfPixelCenters);

          // Compute the four integer indices.
          let sourceFloorRC = vec2<i32>(sourceFracIndexRC);
          let sourceCeilRC = vec2<i32>(
            min(vec2<f32>(uniforms.xShape.yz) - vec2<f32>(1.0), ceil(sourceFracIndexRC)));

          let topLeft = getX(b, sourceFloorRC.x, sourceFloorRC.y, d);
          let bottomLeft = getX(b, sourceCeilRC.x, sourceFloorRC.y, d);
          let topRight = getX(b, sourceFloorRC.x, sourceCeilRC.y, d);
          let bottomRight = getX(b, sourceCeilRC.x, sourceCeilRC.y, d);

          let fracRC = sourceFracIndexRC - vec2<f32>(sourceFloorRC);

          let top = topLeft + (topRight - topLeft) * fracRC.y;
          let bottom = bottomLeft + (bottomRight - bottomLeft) * fracRC.y;
          let newValue = top + (bottom - top) * fracRC.x;

          setOutputAtIndex(index, newValue);
        }
      }
    `;
            return userCode;
        }
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function resizeBilinear(args) {
        const { inputs, backend, attrs } = args;
        const { images } = inputs;
        const { alignCorners, size, halfPixelCenters } = attrs;
        const [newHeight, newWidth] = size;
        const adjustHeight = alignCorners && newHeight > 1 ? 1.0 : 0.0;
        const adjustWidth = alignCorners && newWidth > 1 ? 1.0 : 0.0;
        const halfPixelCentersValue = halfPixelCenters ? 0.5 : 0.0;
        const uniformData = [
            { type: 'float32', data: [adjustHeight, adjustWidth] },
            { type: 'float32', data: [halfPixelCentersValue] }
        ];
        const program = new ResizeBilinearProgram(images.shape, newHeight, newWidth);
        return backend.runWebGPUProgram(program, [images], 'float32', uniformData);
    }
    const resizeBilinearConfig = {
        kernelName: tf.ResizeBilinear,
        backendName: 'webgpu',
        kernelFunc: resizeBilinear
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    class ResizeNearestNeighborProgram {
        constructor(inputShape, newHeight, newWidth, halfPixelCenters) {
            this.variableNames = ['x'];
            this.uniforms = 'adjustHeightWidth : vec2<f32>, roundBase : f32,';
            this.workgroupSize = [64, 1, 1];
            this.size = true;
            this.outputShape = [inputShape[0], newHeight, newWidth, inputShape[3]];
            this.dispatchLayout = flatDispatchLayout(this.outputShape);
            this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
            this.halfPixelCenters = halfPixelCenters;
            this.shaderKey = `resizeNearest_${halfPixelCenters}`;
        }
        getUserCode() {
            let sourceFracIndexRC;
            if (this.halfPixelCenters) {
                sourceFracIndexRC =
                    `max((vec2<f32>(rc) + vec2<f32>(0.5)) * effectiveInputOverOutputRatioRC` +
                        `, vec2<f32>(0.0))`;
            }
            else {
                sourceFracIndexRC = `vec2<f32>(rc) * effectiveInputOverOutputRatioRC`;
            }
            const userCode = `
      ${getMainHeaderString('index')} {
        if (index < uniforms.size) {
          let coords = getCoordsFromIndex(index);
          let b = coords[0];
          let d = coords[3];
          let rc = coords.yz;

          let effectiveInSize = vec2<f32>(
            f32(uniforms.xShape.y) - uniforms.adjustHeightWidth[0],
            f32(uniforms.xShape.z) - uniforms.adjustHeightWidth[1]);

          let effectiveOutSize = vec2<f32>(
            f32(uniforms.outShape.y) - uniforms.adjustHeightWidth[0],
            f32(uniforms.outShape.z) - uniforms.adjustHeightWidth[1]);

          let effectiveInputOverOutputRatioRC =
              effectiveInSize / effectiveOutSize;

          // Fractional source index
          let sourceFracIndexRC = ${sourceFracIndexRC};

          // Compute the coordinators of nearest neighbor point.
          let inputShapeRC = vec2<f32>(f32(uniforms.xShape.y), f32(uniforms.xShape.z));
          let sourceNearestRC = vec2<i32>(
            min(inputShapeRC - 1.0, floor(sourceFracIndexRC + uniforms.roundBase)));
          let newValue = getX(b, sourceNearestRC.x, sourceNearestRC.y, d);

          setOutputAtIndex(index, newValue);
        }
      }
    `;
            return userCode;
        }
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function resizeNearestNeighbor(args) {
        const { inputs, backend, attrs } = args;
        const { images } = inputs;
        const { alignCorners, halfPixelCenters, size } = attrs;
        const [newHeight, newWidth] = size;
        const adjustHeight = alignCorners && newHeight > 1 ? 1.0 : 0.0;
        const adjustWidth = alignCorners && newWidth > 1 ? 1.0 : 0.0;
        // When align corners is false, we rounds the value with floor.
        const roundBase = alignCorners ? 0.5 : 0.0;
        const uniformData = [
            { type: 'float32', data: [adjustHeight, adjustWidth] },
            { type: 'float32', data: [roundBase] }
        ];
        const program = new ResizeNearestNeighborProgram(images.shape, newHeight, newWidth, halfPixelCenters);
        return backend.runWebGPUProgram(program, [images], images.dtype, uniformData);
    }
    const resizeNearestNeighborConfig = {
        kernelName: tf.ResizeNearestNeighbor,
        backendName: 'webgpu',
        kernelFunc: resizeNearestNeighbor
    };

    /**
     * @license
     * Copyright 2022 Google LLC.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    class ReverseProgram {
        constructor(xShape) {
            this.variableNames = ['x'];
            this.workgroupSize = [64, 1, 1];
            this.size = true;
            this.outputShape = xShape;
            this.dispatchLayout = flatDispatchLayout(this.outputShape);
            this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
            this.uniforms = ` axis : vec4<i32>,`;
            this.shaderKey = 'reverse';
        }
        getUserCode() {
            const reverseCoordsSnippet = `
      // Using uniform variables as judging conditions, so the function has
      // coherent execution within all threads.
      fn getReverseCoords(coords : vec4<i32>) -> vec4<i32> {
        var reverseCoords = coords;
        if (uniforms.axis[0] == 1) {
          reverseCoords[0] = uniforms.xShape[0] - coords[0] - 1;
        }
        if (uniforms.axis[1] == 1) {
          reverseCoords[1] = uniforms.xShape[1] - coords[1] - 1;
        }
        if (uniforms.axis[2] == 1) {
          reverseCoords[2] = uniforms.xShape[2] - coords[2] - 1;
        }
        if (uniforms.axis[3] == 1) {
          reverseCoords[3] = uniforms.xShape[3] - coords[3] - 1;
        }

        return reverseCoords;
      }
    `;
            const userCode = `
      ${reverseCoordsSnippet}
      ${getMainHeaderString('index')} {
        if (index < uniforms.size) {
          let coords = getCoordsFromIndex(index);
          let reverseCoords = getReverseCoords(coords);
          setOutputAtIndex(index, getX(reverseCoords[0],
              reverseCoords[1], reverseCoords[2], reverseCoords[3]));
        }
      }
    `;
            return userCode;
        }
    }

    /**
     * @license
     * Copyright 2022 Google LLC.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function reverse(args) {
        const { inputs, backend, attrs } = args;
        const { x } = inputs;
        const { dims } = attrs;
        const xRank = x.shape.length;
        if (xRank === 0) {
            return identity({ inputs: { x }, backend });
        }
        const xShape = x.shape;
        const xShape4D = [1, 1, 1, 1];
        xShape.forEach((d, i) => {
            const index = i + 4 - xRank;
            xShape4D[index] = d;
        });
        const axes = tf.util.parseAxisParam(dims, x.shape);
        const dims4D = [0, 0, 0, 0];
        axes.forEach(ax => {
            const index = ax + 4 - xRank;
            dims4D[index] = 1;
        });
        const uniformData = [{ type: 'int32', data: dims4D }];
        const xReshaped = reshape({ inputs: { x }, backend, attrs: { shape: xShape4D } });
        const program = new ReverseProgram(xShape4D);
        const values = backend.runWebGPUProgram(program, [xReshaped], xReshaped.dtype, uniformData);
        backend.disposeData(xReshaped.dataId);
        const result = reshape({ inputs: { x: values }, backend, attrs: { shape: xShape } });
        backend.disposeData(values.dataId);
        return result;
    }
    const reverseConfig = {
        kernelName: tf.Reverse,
        backendName: 'webgpu',
        kernelFunc: reverse
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    class RotateProgram {
        constructor(imageShape, fillValue) {
            this.outputShape = [];
            this.variableNames = ['x'];
            this.workgroupSize = [64, 1, 1];
            this.size = true;
            this.outputShape = imageShape;
            this.dispatchLayout = flatDispatchLayout(this.outputShape);
            this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
            this.uniforms = `centerX : f32, centerY : f32, sinRadians : f32,
          cosRadians : f32,`;
            this.shaderKey = 'rotate';
            this.outputShape = imageShape;
            if (typeof fillValue === 'number') {
                this.uniforms += ` fillValue : f32,`;
                this.fillSnippet = `var outputValue = uniforms.fillValue;`;
                this.shaderKey += '_float';
            }
            else {
                this.uniforms += ` fillValue : vec3<f32>,`;
                this.fillSnippet = `var outputValue = uniforms.fillValue[coords[3]];`;
                this.shaderKey += '_vec3';
            }
        }
        getUserCode() {
            const userCode = `
        ${getMainHeaderString('index')} {
          if (index < uniforms.size) {
            let coords = getCoordsFromIndex(index);
            let coordXFloat = (f32(coords[2]) - uniforms.centerX) *
                uniforms.cosRadians - (f32(coords[1]) - uniforms.centerY) *
                uniforms.sinRadians;
            let coordYFloat = (f32(coords[2]) - uniforms.centerX) *
                uniforms.sinRadians + (f32(coords[1]) - uniforms.centerY) *
                uniforms.cosRadians;
            let coordX = i32(round(coordXFloat + uniforms.centerX));
            let coordY = i32(round(coordYFloat + uniforms.centerY));
            ${this.fillSnippet}
            if(coordX >= 0 && coordX < uniforms.xShape[2] && coordY >= 0 &&
                coordY < uniforms.xShape[1]) {
              outputValue = getX(coords[0], coordY, coordX, coords[3]);
            }
            setOutputAtIndex(index, outputValue);
          }
        }
      `;
            return userCode;
        }
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const rotateWithOffsetConfig = {
        kernelName: tf.RotateWithOffset,
        backendName: 'webgpu',
        kernelFunc: ({ inputs, attrs, backend }) => {
            const { image } = inputs;
            const { radians, fillValue, center } = attrs;
            const webgpuBackend = backend;
            const program = new RotateProgram(image.shape, fillValue);
            const [centerX, centerY] = tf.backend_util.getImageCenter(center, image.shape[1], image.shape[2]);
            const uniformData = [
                { type: 'float32', data: [centerX] },
                { type: 'float32', data: [centerY] },
                { type: 'float32', data: [Math.sin(radians)] },
                { type: 'float32', data: [Math.cos(radians)] }
            ];
            if (typeof fillValue === 'number') {
                uniformData.push({ type: 'float32', data: [Number.parseFloat(fillValue.toFixed(2))] });
            }
            else {
                uniformData.push({ type: 'float32', data: fillValue });
            }
            const output = webgpuBackend.runWebGPUProgram(program, [image], image.dtype, uniformData);
            return output;
        }
    };

    /**
     * @license
     * Copyright 2022 Google LLC.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const round = unaryKernelFunc({ opType: UnaryOpType.ROUND });
    const roundConfig = {
        kernelName: tf.Round,
        backendName: 'webgpu',
        kernelFunc: round
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const rsqrt = unaryKernelFunc({ opType: UnaryOpType.RSQRT, cpuKernelImpl: rsqrtImplCPU });
    const rsqrtConfig = {
        kernelName: tf.Rsqrt,
        backendName: 'webgpu',
        kernelFunc: rsqrt
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    class ScatterProgram {
        constructor(flattenXShape, sliceDim, indicesRank, updatesRank, strides, shape, outputDtype, sumDupeIndices = true) {
            this.variableNames = ['updates', 'indices'];
            this.workgroupSize = [64, 1, 1];
            this.atomic = true;
            this.outputShape = shape;
            this.type = outputDtype;
            this.sumDupeIndices = sumDupeIndices;
            this.dispatchLayout = flatDispatchLayout(flattenXShape);
            // Dispatching based on |updates| shape instead of output shape.
            this.dispatch =
                computeDispatch(this.dispatchLayout, flattenXShape, this.workgroupSize);
            this.sliceDimGreaterThanOne = sliceDim > 1;
            this.shaderKey = `scatter_${indicesRank}_${updatesRank}_${this.sliceDimGreaterThanOne}_${outputDtype}_${sumDupeIndices}`;
            const stridesType = getCoordsDataType(strides.length);
            this.uniforms =
                `sliceDim : i32, strides: ${stridesType}, updatesSize: i32,`;
            this.updatesRank = updatesRank;
            this.indicesRank = indicesRank;
        }
        getUserCode() {
            let indicesString = '';
            if (this.indicesRank === 1) {
                indicesString = 'coords[0]';
            }
            else if (this.indicesRank === 2) {
                indicesString = 'coords[0], j';
            }
            const indicesSnippet = `getIndices(${indicesString})`;
            const strideString = this.sliceDimGreaterThanOne ? 'uniforms.strides[j]' :
                'uniforms.strides';
            let outCoordsString = '';
            let getUpdatesCoordsFromFlatIndex = '';
            if (this.dispatchLayout.x.length === 1) {
                outCoordsString = 'flattenedIndex';
                getUpdatesCoordsFromFlatIndex = `
      fn getUpdatesCoordsFromFlatIndex(index : i32) -> i32 {
        return index;
      }
      `;
            }
            else if (this.dispatchLayout.x.length === 2) {
                outCoordsString = 'vec2<i32>(flattenedIndex, coords[1])';
                getUpdatesCoordsFromFlatIndex = `
      fn getUpdatesCoordsFromFlatIndex(index : i32) -> vec2<i32> {
        // N.B. |updates| could be a scalar tensor, conceptually representing a
        // 2D tensor with all values equal to that. By design, its size must be
        // the same as |outShape[1]| in one dimension, and |indicesShape[0]|
        // gives the other.
        let sliceSize = uniforms.outShape[1];
        let d0 = index / sliceSize;
        let d1 = index - d0 * sliceSize;
        return vec2<i32>(d0, d1);
      }
      `;
            }
            const updatesString = Array.from({ length: this.updatesRank }, (_, idx) => `coords[${idx}]`);
            const updatesSnippet = `getUpdates(${updatesString.join(', ')})`;
            const userCode = `
    ${getUpdatesCoordsFromFlatIndex}
      ${getMainHeaderString('index')} {
        if (index < uniforms.updatesSize) {
          let coords = getUpdatesCoordsFromFlatIndex(index);
          var flattenedIndex = 0;
          for (var j = 0; j < uniforms.sliceDim; j = j + 1) {
            let indexInside = i32(round(${indicesSnippet}));
            flattenedIndex = flattenedIndex + indexInside * ${strideString};
          }
          let updateValue =
              ${mapToWgslTypes(this.type, false)}(${updatesSnippet});
          let flatIndex = getOutputIndexFromCoords(${outCoordsString});

          ${this.sumDupeIndices ?
            atomicAddSnippet('&result[flatIndex]', 'updateValue', this.type) :
            `atomicStore(&result[flatIndex], bitcast<i32>(updateValue));`}
        }
      }`;
            return userCode;
        }
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function scatterNd(args) {
        const { inputs, backend, attrs } = args;
        const { indices, updates } = inputs;
        const { shape } = attrs;
        const { sliceRank, numUpdates, sliceSize, strides, outputSize } = tf.backend_util.calculateShapes(updates, indices, shape);
        const flattenShape = [outputSize / sliceSize, sliceSize];
        if (outputSize === 0) {
            return backend.makeTensorInfo(shape, indices.dtype);
        }
        const flattenIndices = reshape({ inputs: { x: indices }, backend, attrs: { shape: [numUpdates, sliceRank] } });
        const flattenX = reshape({ inputs: { x: updates }, backend, attrs: { shape: [numUpdates, sliceSize] } });
        const type = flattenX.dtype;
        const output = fill({ backend, attrs: { shape: flattenShape, value: 0, dtype: type } });
        const size = tf.util.sizeFromShape(flattenX.shape);
        const uniformData = [
            { type: 'int32', data: [sliceRank] }, { type: 'int32', data: strides },
            { type: 'int32', data: [size] }
        ];
        const program = new ScatterProgram(flattenX.shape, sliceRank, flattenIndices.shape.length, flattenX.shape.length, strides, flattenShape, type);
        const res = backend.runWebGPUProgram(program, [flattenX, flattenIndices], type, uniformData, output);
        const reshaped = reshape({ inputs: { x: res }, backend, attrs: { shape } });
        backend.disposeData(flattenIndices.dataId);
        backend.disposeData(flattenX.dataId);
        backend.disposeData(res.dataId);
        return reshaped;
    }
    const scatterNdConfig = {
        kernelName: tf.ScatterNd,
        backendName: 'webgpu',
        kernelFunc: scatterNd
    };

    /**
     * @license
     * Copyright 2022 Google LLC.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    class SearchSortedProgram {
        constructor(outputShape, side) {
            this.outputShape = [];
            this.variableNames = ['sortedSequence', 'values'];
            this.uniforms = 'numInputs : i32,';
            this.workgroupSize = [64, 1, 1];
            this.size = true;
            this.outputShape = outputShape;
            this.dispatchLayout = flatDispatchLayout(this.outputShape);
            this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
            this.side = side;
            this.shaderKey = `search_sorted_${side}`;
        }
        getUserCode() {
            const boundComparator = this.side === 'left' ? '<' : '<=';
            const userCode = `
      fn findBound(batch: i32, value: f32) -> i32 {
        var left = i32(0);
        var right = uniforms.numInputs;
        while (left < right) {
          var mid = (left + right) / 2;
          if (getSortedSequence(batch, mid) ${boundComparator} value) {
            left = mid + 1;
          } else {
            right = mid;
          }
        }
        return right;
      }

      ${getMainHeaderString('index')} {
        if (index < uniforms.size) {
          let coords = getCoordsFromIndex(index);
          let value = getValuesByOutputIndex(index);
          setOutputAtIndexI32(index, findBound(coords[0], value));
        }
      }
    `;
            return userCode;
        }
    }

    /**
     * @license
     * Copyright 2022 Google LLC.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function searchSorted(args) {
        const { inputs, backend, attrs } = args;
        const { sortedSequence, values } = inputs;
        const { side } = attrs;
        const program = new SearchSortedProgram([values.shape[0], values.shape[1]], side);
        const uniformData = [{ type: 'int32', data: [sortedSequence.shape[1]] }];
        return backend.runWebGPUProgram(program, [sortedSequence, values], 'int32', uniformData);
    }
    const searchSortedConfig = {
        kernelName: tf.SearchSorted,
        backendName: 'webgpu',
        kernelFunc: searchSorted,
    };

    /**
     * @license
     * Copyright 2019 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    class SelectProgram {
        constructor(cRank, shape, rank) {
            this.variableNames = ['c', 'a', 'b'];
            this.workgroupSize = [64, 1, 1];
            this.size = true;
            this.outputShape = shape;
            this.dispatchLayout = flatDispatchLayout(this.outputShape);
            this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
            this.cRank = cRank;
            this.rank = rank;
            this.shaderKey = 'select';
        }
        getUserCode() {
            // TODO(WGSL): below code can be merged with getUserCode.
            let cCoords;
            let abCoords;
            if (this.rank > 4) {
                throw Error(`Where for rank ${this.rank} is not yet supported`);
            }
            if (this.rank === 1) {
                abCoords = `resRC`;
                cCoords = `resRC`;
            }
            else {
                const currentCoords = ['resRC.x', 'resRC.y', 'resRC.z', 'resRC.w'];
                const cCoordVars = [];
                const abCoordVars = [];
                for (let i = 0; i < this.outputShape.length; i++) {
                    abCoordVars.push(`${currentCoords[i]}`);
                    if (i < this.cRank) {
                        cCoordVars.push(`${currentCoords[i]}`);
                    }
                }
                cCoords = cCoordVars.join();
                abCoords = abCoordVars.join();
            }
            const userCode = `
      ${getMainHeaderString('index')} {
        if (index < uniforms.size) {
          let resRC = getCoordsFromIndex(index);
          let cVal = getC(${cCoords});
          if (cVal >= 1.0) {
            setOutputAtIndex(index, getA(${abCoords}));
          } else {
            setOutputAtIndex(index, getB(${abCoords}));
          }
        }
      }
    `;
            return userCode;
        }
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function select$1(args) {
        const { inputs, backend } = args;
        const { condition, t, e } = inputs;
        const program = new SelectProgram(condition.shape.length, t.shape, t.shape.length);
        return backend.runWebGPUProgram(program, [condition, t, e], tf.upcastType(t.dtype, e.dtype));
    }
    const selectConfig = {
        kernelName: tf.Select,
        backendName: 'webgpu',
        kernelFunc: select$1
    };

    /**
     * @license
     * Copyright 2022 Google LLC.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const selu = unaryKernelFunc({ opType: UnaryOpType.SELU });
    const seluConfig = {
        kernelName: tf.Selu,
        backendName: 'webgpu',
        kernelFunc: selu
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const sigmoid$1 = unaryKernelFunc({ opType: UnaryOpType.SIGMOID });
    const sigmoidConfig = {
        kernelName: tf.Sigmoid,
        backendName: 'webgpu',
        kernelFunc: sigmoid$1,
    };

    /**
     * @license
     * Copyright 2022 Google LLC.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const sign = unaryKernelFunc({ opType: UnaryOpType.SIGN });
    const signConfig = {
        kernelName: tf.Sign,
        backendName: 'webgpu',
        kernelFunc: sign
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const sin = unaryKernelFunc({ opType: UnaryOpType.SIN });
    const sinConfig = {
        kernelName: tf.Sin,
        backendName: 'webgpu',
        kernelFunc: sin
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const sinh = unaryKernelFunc({ opType: UnaryOpType.SINH });
    const sinhConfig = {
        kernelName: tf.Sinh,
        backendName: 'webgpu',
        kernelFunc: sinh
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const sub = binaryKernelFunc({ opType: BinaryOpType.SUB, cpuKernelImpl: subImplCPU, supportsComplex: true });
    const subConfig = {
        kernelName: tf.Sub,
        backendName: 'webgpu',
        kernelFunc: sub
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function softmax(args) {
        const { inputs, backend, attrs } = args;
        const { logits } = inputs;
        const { dim } = attrs;
        const axes = tf.util.parseAxisParam([dim], logits.shape);
        const maxLogit = max({
            inputs: { x: logits },
            backend,
            attrs: { reductionIndices: axes, keepDims: false }
        });
        const expandedShape = tf.backend_util.expandShapeToKeepDim(maxLogit.shape, axes);
        const maxLogitsReshaped = reshape({ inputs: { x: maxLogit }, backend, attrs: { shape: expandedShape } });
        const a = sub({ inputs: { a: logits, b: maxLogitsReshaped }, backend });
        const b = exp({ inputs: { x: a }, backend });
        const sumExp = sum({ inputs: { x: b }, backend, attrs: { axis: axes, keepDims: false } });
        const sumExpReshaped = reshape({ inputs: { x: sumExp }, backend, attrs: { shape: expandedShape } });
        const res = realDiv({ inputs: { a: b, b: sumExpReshaped }, backend });
        backend.disposeData(maxLogit.dataId);
        backend.disposeData(maxLogitsReshaped.dataId);
        backend.disposeData(a.dataId);
        backend.disposeData(b.dataId);
        backend.disposeData(sumExp.dataId);
        backend.disposeData(sumExpReshaped.dataId);
        return res;
    }
    const softmaxConfig = {
        kernelName: tf.Softmax,
        backendName: 'webgpu',
        kernelFunc: softmax
    };

    /**
     * @license
     * Copyright 2022 Google LLC.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const softplus = unaryKernelFunc({ opType: UnaryOpType.SOFTPLUS });
    const softplusConfig = {
        kernelName: tf.Softplus,
        backendName: 'webgpu',
        kernelFunc: softplus
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const spaceToBatchND = (args) => {
        const { inputs, backend, attrs } = args;
        const { x } = inputs;
        const { blockShape, paddings } = attrs;
        tf.util.assert(x.shape.length <= 4, () => 'spaceToBatchND for rank > 4 with a WebGPU backend not ' +
            'implemented yet');
        const prod = blockShape.reduce((a, b) => a * b);
        const completePaddings = [[0, 0]];
        completePaddings.push(...paddings);
        for (let i = 1 + blockShape.length; i < x.shape.length; ++i) {
            completePaddings.push([0, 0]);
        }
        const toDispose = [];
        const paddedX = padV2({
            inputs: { x },
            backend,
            attrs: { paddings: completePaddings, constantValue: 0 }
        });
        const reshapedPaddedShape = tf.backend_util.getReshaped(paddedX.shape, blockShape, prod, false);
        const permutedReshapedPaddedPermutation = tf.backend_util.getPermuted(reshapedPaddedShape.length, blockShape.length, false);
        const flattenShape = tf.backend_util.getReshapedPermuted(paddedX.shape, blockShape, prod, false);
        const reshapedPaddedX = reshape({ inputs: { x: paddedX }, backend, attrs: { shape: reshapedPaddedShape } });
        const paddedXT = transpose({
            inputs: { x: reshapedPaddedX },
            backend,
            attrs: { perm: permutedReshapedPaddedPermutation }
        });
        const result = reshape({ inputs: { x: paddedXT }, backend, attrs: { shape: flattenShape } });
        toDispose.push(paddedX);
        toDispose.push(reshapedPaddedX);
        toDispose.push(paddedXT);
        toDispose.forEach(t => backend.disposeData(t.dataId));
        return result;
    };
    const spaceToBatchNDConfig = {
        kernelName: tf.SpaceToBatchND,
        backendName: 'webgpu',
        kernelFunc: spaceToBatchND
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    class TileProgram {
        constructor(aShape, reps) {
            this.variableNames = ['A'];
            this.workgroupSize = [64, 1, 1];
            this.size = true;
            const outputShape = new Array(aShape.length);
            for (let i = 0; i < outputShape.length; i++) {
                outputShape[i] = aShape[i] * reps[i];
            }
            this.outputShape = outputShape;
            this.dispatchLayout = flatDispatchLayout(this.outputShape);
            this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
            this.rank = this.outputShape.length;
            this.shaderKey = 'tile';
        }
        getUserCode() {
            const sourceCoords = getSourceCoords$1(this.rank, 'uniforms.');
            const userCode = `
      ${getMainHeaderString('index')} {
        if (index < uniforms.size) {
          let resRC = getCoordsFromIndex(index);
          setOutputAtIndex(index, getA(${sourceCoords}));
        }
      }
    `;
            return userCode;
        }
    }
    function getSourceCoords$1(rank, uniformPrefix = '') {
        if (rank >= 5) {
            throw Error(`Tile for rank ${rank} is not yet supported`);
        }
        if (rank === 1) {
            return `(resRC % ${uniformPrefix}aShape)`;
        }
        const currentCoords = ['resRC.x', 'resRC.y', 'resRC.z', 'resRC.w'];
        const sourceCoords = [];
        for (let i = 0; i < rank; i++) {
            sourceCoords.push(`(${currentCoords[i]} % ${uniformPrefix}aShape[${i}])`);
        }
        return sourceCoords.join();
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function tile(params) {
        const { inputs, backend, attrs } = params;
        const { x } = inputs;
        const { reps } = attrs;
        // tile gpu program cannot handle rank >= 5 case.
        if (backend.shouldExecuteOnCPU([x]) || x.dtype === 'string' ||
            x.shape.length >= 5) {
            // Even thought string tensor is always on CPU, just to be consistent on how
            // to access tensor data.
            const data = backend.readSync(x.dataId);
            const value = x.dtype === 'string' ?
                data.map(d => tf.util.decodeString(d)) :
                data;
            const buf = tf.buffer(x.shape, x.dtype, value);
            const outBuf = tileImplCPU(buf, reps);
            return backend.makeTensorInfo(outBuf.shape, outBuf.dtype, outBuf.values);
        }
        const program = new TileProgram(x.shape, reps);
        const output = backend.runWebGPUProgram(program, [x], x.dtype);
        return output;
    }
    const tileConfig = {
        kernelName: tf.Tile,
        backendName: 'webgpu',
        kernelFunc: tile,
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function sparseToDense(args) {
        const { inputs, backend, attrs } = args;
        const { sparseIndices, sparseValues, defaultValue } = inputs;
        const { outputShape } = attrs;
        const { sliceRank, numUpdates, sliceSize, strides, outputSize } = tf.backend_util.calculateShapes(sparseValues, sparseIndices, outputShape);
        const sumDupeIndices = false;
        if (sparseValues.dtype === 'string') {
            const indicesBuf = backend.bufferSync(sparseIndices);
            const updatesBuf = backend.bufferSync(sparseValues);
            const $defaultValue = tf.util.decodeString(backend.readSync(defaultValue.dataId)[0]);
            const outBuf = scatterImplCPU(indicesBuf, updatesBuf, outputShape, outputSize, sliceSize, numUpdates, sliceRank, strides, $defaultValue, sumDupeIndices);
            return backend.makeTensorInfo(outputShape, outBuf.dtype, outBuf.values);
        }
        const flattenShape = [outputSize / sliceSize, sliceSize];
        const $sparseIndices = reshape({
            inputs: { x: sparseIndices },
            backend,
            attrs: { shape: [numUpdates, sliceRank] }
        });
        const $sparseValues = sparseValues.shape.length ?
            reshape({
                inputs: { x: sparseValues },
                backend,
                attrs: { shape: [numUpdates, sliceSize] }
            }) :
            identity({ inputs: { x: sparseValues }, backend });
        const type = $sparseValues.dtype;
        const zero = backend.makeTensorInfo([], type, tf.util.makeZerosTypedArray(1, type));
        // Fill output tensor with the default value.
        const $defaultValue = reshape({
            inputs: { x: defaultValue },
            backend,
            attrs: { shape: Array(flattenShape.length).fill(1) }
        });
        const $denseValues = tile({ inputs: { x: $defaultValue }, backend, attrs: { reps: flattenShape } });
        const size = tf.util.sizeFromShape([numUpdates, sliceSize]);
        const uniformData = [
            { type: 'int32', data: [sliceRank] },
            { type: 'int32', data: strides },
            { type: 'int32', data: [size] },
        ];
        switch (numUpdates) {
            case 0:
                break;
            case 1:
                {
                    const program = new ScatterProgram([numUpdates, sliceSize], sliceRank, $sparseIndices.shape.length, $sparseValues.shape.length, strides, flattenShape, type, sumDupeIndices);
                    backend.runWebGPUProgram(program, [$sparseValues, $sparseIndices], type, uniformData, $denseValues);
                }
                break;
            default:
                {
                    // First replace the default value with 0 at indices.
                    const program = new ScatterProgram([numUpdates, sliceSize], sliceRank, $sparseIndices.shape.length, zero.shape.length, strides, flattenShape, type, sumDupeIndices);
                    backend.runWebGPUProgram(program, [zero, $sparseIndices], type, uniformData, $denseValues);
                }
                {
                    // Then replace 0 with the (sum of) sparse value(s) at indices.
                    const program = new ScatterProgram([numUpdates, sliceSize], sliceRank, $sparseIndices.shape.length, $sparseValues.shape.length, strides, flattenShape, type);
                    backend.runWebGPUProgram(program, [$sparseValues, $sparseIndices], type, uniformData, $denseValues);
                }
        }
        const denseValues = reshape({ inputs: { x: $denseValues }, backend, attrs: { shape: outputShape } });
        backend.disposeData($sparseIndices.dataId);
        backend.disposeData($sparseValues.dataId);
        backend.disposeData($defaultValue.dataId);
        backend.disposeData(zero.dataId);
        backend.disposeData($denseValues.dataId);
        return denseValues;
    }
    const sparseToDenseConfig = {
        kernelName: tf.SparseToDense,
        backendName: 'webgpu',
        kernelFunc: sparseToDense
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function splitV(args) {
        const { inputs, backend, attrs } = args;
        const { x } = inputs;
        const { numOrSizeSplits, axis } = attrs;
        const $axis = tf.util.parseAxisParam(axis, x.shape)[0];
        const splitSizes = tf.backend_util.prepareSplitSize(x, numOrSizeSplits, $axis);
        const xRank = x.shape.length;
        const begin = new Array(xRank).fill(0);
        const size = x.shape.slice();
        return splitSizes.map(s => {
            const sliceSize = [...size];
            sliceSize[$axis] = s;
            const sliceT = slice({ inputs: { x }, backend, attrs: { begin, size: sliceSize } });
            begin[$axis] += s;
            return sliceT;
        });
    }
    const splitVConfig = {
        kernelName: tf.SplitV,
        backendName: 'webgpu',
        kernelFunc: splitV
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const sqrt = unaryKernelFunc({ opType: UnaryOpType.SQRT });
    const sqrtConfig = {
        kernelName: tf.Sqrt,
        backendName: 'webgpu',
        kernelFunc: sqrt
    };

    /**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const squareConfig = {
        kernelName: tf.Square,
        backendName: 'webgpu',
        kernelFunc: ({ inputs, backend }) => {
            const { x } = inputs;
            const webGPUBackend = backend;
            const program = new UnaryOpProgram(x.shape, UnaryOpType.SQUARE);
            return webGPUBackend.runWebGPUProgram(program, [x], x.dtype);
        }
    };

    /**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const squaredDifference = binaryKernelFunc({
        opType: BinaryOpType.SQUARED_DIFFERENCE,
    });
    const squaredDifferenceConfig = {
        kernelName: tf.SquaredDifference,
        backendName: 'webgpu',
        kernelFunc: squaredDifference
    };

    /**
     * @license
     * Copyright 2022 Google LLC.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function step({ inputs, attrs, backend }) {
        const { x } = inputs;
        const program = new UnaryOpProgram(x.shape, UnaryOpType.STEP, 'stepAlpha : f32,');
        const uniformData = [{ type: 'float32', data: [attrs.alpha] }];
        return backend.runWebGPUProgram(program, [x], x.dtype, uniformData);
    }
    const stepConfig = {
        kernelName: tf.Step,
        backendName: 'webgpu',
        kernelFunc: step
    };

    /**
     * @license
     * Copyright 2019 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    class StridedSliceProgram {
        constructor(destSize) {
            this.variableNames = ['x'];
            // TODO(xing.xu): Increase the workPerThread.
            this.workPerThread = 1;
            this.workgroupSize = [64, 1, 1];
            this.size = true;
            this.outputShape = destSize;
            this.dispatchLayout = flatDispatchLayout(this.outputShape);
            this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize, [this.workPerThread, 1, 1]);
            const dtype = getCoordsDataType(this.outputShape.length);
            this.uniforms = `begin : ${dtype},  strides : ${dtype}, `;
            this.shaderKey = 'stridedSlice';
        }
        getUserCode() {
            const rank = this.outputShape.length;
            let newCoords = '';
            if (rank === 1) {
                newCoords = 'coords * uniforms.strides + uniforms.begin';
            }
            else {
                let outputAxis = 0;
                newCoords =
                    this.outputShape
                        .map((_, i) => {
                        outputAxis++;
                        return this.outputShape.length === 1 ?
                            `coords * uniforms.strides[${i}] + uniforms.begin[${i}]` :
                            `coords[${outputAxis - 1}] * uniforms.strides[${i}] + uniforms.begin[${i}]`;
                    })
                        .join(',');
            }
            const userCode = `
       ${getMainHeaderString('index')} {
         if (index < uniforms.size) {
           let coords = getCoordsFromIndex(index);
           setOutputAtIndex(index, getX(${newCoords}));
         }
       }
     `;
            return userCode;
        }
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function stridedSlice(args) {
        const { inputs, backend, attrs } = args;
        const { x } = inputs;
        const { begin, end, strides, beginMask, endMask, ellipsisMask, newAxisMask, shrinkAxisMask } = attrs;
        const { finalShapeSparse, finalShape, isIdentity, sliceDim0, isSimpleSlice, begin: $begin, end: $end, strides: $strides } = tf.slice_util.sliceInfo(x.shape, begin, end, strides, beginMask, endMask, ellipsisMask, newAxisMask, shrinkAxisMask);
        let result;
        if (isIdentity) {
            // Optimization #1, slice is a no-op plus reshape
            result = reshape({ inputs: { x }, backend, attrs: { shape: finalShape } });
        }
        else if (sliceDim0 || isSimpleSlice) {
            // Optimization #2, slice is memory contiguous (only occurs in dim 0)
            tf.util.assert(x.shape.length >= 1, () => `Input must have rank at least 1, got: ${x.shape.length}`);
            const size = tf.slice_util.computeOutShape($begin, $end, $strides);
            // To tolerate begin[0] > end[0] (a 0-output slice), we min(begin, end).
            const sliced = slice({ inputs: { x }, backend, attrs: { begin: $begin, size } });
            result =
                reshape({ inputs: { x: sliced }, backend, attrs: { shape: finalShape } });
            backend.disposeData(sliced.dataId);
        }
        else {
            const shouldExecuteOnCPU = backend.shouldExecuteOnCPU([x]);
            if (shouldExecuteOnCPU) {
                const values = backend.readSync(x.dataId);
                const xBuf = tf.buffer(x.shape, x.dtype, values);
                const resultValues = stridedSliceImplCPU(finalShapeSparse, xBuf, $strides, $begin);
                result = backend.makeTensorInfo(finalShape, x.dtype, resultValues.values);
            }
            else {
                const program = new StridedSliceProgram(finalShapeSparse);
                const uniformData = [{ type: 'int32', data: $begin }, { type: 'int32', data: $strides }];
                const resultValues = backend.runWebGPUProgram(program, [x], x.dtype, uniformData);
                result = reshape({ inputs: { x: resultValues }, backend, attrs: { shape: finalShape } });
                backend.disposeData(resultValues.dataId);
            }
        }
        return result;
    }
    const stridedSliceConfig = {
        kernelName: tf.StridedSlice,
        backendName: 'webgpu',
        kernelFunc: stridedSlice
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function stringNGrams(args) {
        const { inputs, backend, attrs } = args;
        const { separator, nGramWidths, leftPad, rightPad, padWidth, preserveShortSequences } = attrs;
        const { data, dataSplits } = inputs;
        const $data = backend.readSync(data.dataId);
        const $dataSplits = backend.readSync(dataSplits.dataId);
        const [nGrams, nGramsSplits] = stringNGramsImplCPU($data, $dataSplits, separator, nGramWidths, leftPad, rightPad, padWidth, preserveShortSequences);
        return [
            backend.makeTensorInfo([nGrams.length], 'string', nGrams),
            backend.makeTensorInfo(dataSplits.shape, 'int32', nGramsSplits),
        ];
    }
    const stringNGramsConfig = {
        kernelName: tf.StringNGrams,
        backendName: 'webgpu',
        kernelFunc: stringNGrams,
    };

    /**
     * @license
     * Copyright 2022 Google LLC.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const tan = unaryKernelFunc({ opType: UnaryOpType.TAN });
    const tanConfig = {
        kernelName: tf.Tan,
        backendName: 'webgpu',
        kernelFunc: tan
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    const tanh = unaryKernelFunc({ opType: UnaryOpType.TANH });
    const tanhConfig = {
        kernelName: tf.Tanh,
        backendName: 'webgpu',
        kernelFunc: tanh
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    // Based on Algorithm 2 of Bitonic Top K, ref:
    // https://anilshanbhag.in/static/papers/gputopk_sigmod18.pdf
    // The original algorithm is based on computing the top K only, however
    // since for TFJS we require the indices of the top K values as well then the
    // algorithm found here is a bit modified. Rather than producing the values
    // at each step, the indices containing the top K are generated instead.
    // The output values are not generated to reduce the number of outputs in the
    // GPU, the values can easily be retrieved from the indices using a gather
    // op.
    class SwapProgram {
        constructor(shape) {
            this.variableNames = ['x', 'indices'];
            this.workgroupSize = [256, 1, 1];
            this.size = true;
            this.outputShape = shape;
            this.dispatchLayout = flatDispatchLayout(this.outputShape);
            this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
            this.uniforms = `inputSize : i32, firstPass : i32, negativeInf : f32,
        dir : i32, inc : i32,`;
            this.shaderKey = 'swap';
        }
        getUserCode() {
            const userCode = `
        ${getMainHeaderString('index')} {
          if (index < uniforms.size) {
            let outC = getCoordsFromIndex(index);
            let batch = outC[0];
            let elemIdx = outC[1];
            // We compare elements pair-wise within a group of size 2 * inc.
            // The comparing rule for each group alternates between ascending
            // and descending. Within each group, we compare each pair at
            // positions i and i+inc. To decide whether an element at position i
            // is x0 or x1, we mod it by 2 * inc, if the result is smaller than
            // inc, it is in the first half of the group, we denote it as x0,
            // otherwise we denote it as x1.
            // For example, as shown in the Bitonic top K paper referenced
            // above, Figure5(a) shows that element[1] is in the second half of
            // the group when group size is 2, but it is in the first half of
            // the group when group size is 4.
            let isFirstInPair = elemIdx % (2 * uniforms.inc) < uniforms.inc;
            var i = 0;
            if (isFirstInPair) {
              i = elemIdx;
            } else {
              i = elemIdx - uniforms.inc;
            }

            var i0 = 0;
            if (uniforms.firstPass == 1) {
              i0 = i;
            } else {
              i0 = i32(getIndices(batch, i));
            }

            var i1 = 0;
            if (uniforms.firstPass == 1) {
              i1 = i + uniforms.inc;
            } else {
              i1 = i32(getIndices(batch, i + uniforms.inc));
            }

            var x0 = f32(0.0);
            var x1 = f32(0.0);
            if (i0 < uniforms.inputSize) {
              x0 = getX(batch, i0);
            } else {
              x0 = uniforms.negativeInf;
            }
            if (i1 < uniforms.inputSize) {
              x1 = getX(batch, i1);
            } else {
              x1 = uniforms.negativeInf;
            }

            let reverse = elemIdx % (2 * uniforms.dir) >= uniforms.dir;
            let isGreater = x0 > x1 || (x0 == x1 && i1 > i0);
            if (reverse == isGreater) {
              // Elements in opposite order of direction
              let iTemp = i0;
              i0 = i1;
              i1 = iTemp;
            }
            if (isFirstInPair) {
              setOutputAtIndex(index, f32(i0));
            } else {
              setOutputAtIndex(index, f32(i1));
            }
          }
        }
      `;
            return userCode;
        }
    }
    class MergeProgram {
        constructor(shape) {
            this.variableNames = ['x', 'indices'];
            this.workgroupSize = [256, 1, 1];
            this.size = true;
            this.outputShape = shape;
            this.dispatchLayout = flatDispatchLayout(this.outputShape);
            this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
            // |n| Size of the original input of TopK
            // |firstPass| indicates if this is the first time swap is being used which
            // means no indices input containing the top K is present yet.
            // |k| Top k elements desired
            this.uniforms = `inputSize : i32, firstPass : i32, k : i32,`;
            this.shaderKey = 'merge';
        }
        getUserCode() {
            const userCode = `
        ${getMainHeaderString('index')} {
          if (index < uniforms.size) {
            let outC = getCoordsFromIndex(index);
            let batch = outC[0];
            let elemIdx = outC[1];
            // The output size is half of the previous size.
            // If the previous sequence is | | | | _ _ _ _  | | | |  _ _ _ _
            // (k=4), we only need to output the indices at positions |, the
            // indices at positions _ can be thrown away, see Figure5(b) After
            // Phase 2 (Merge phase) in the Bitonic Top K paper referenced
            // above.
            // For example, the paper shows we only need to output the orange
            // bars. The output sequence should look like this | | | | | | | |.
            // Because the sequence is halved, to map the output index back to
            // the previous sequence to find the corresponding value, we need
            // to double the index. When we double the index, we basically
            // interpolate a position, so 2i looks like
            // | _ | _ | _ | _ | _ | _ | _. We move the | to the first k
            // position of each 2k positions by - elemIdx % k. E.g. for output
            // at index 4,5,6,7, we want to get the corresponding element at
            // original index 8,9,10,11, for output at index 8,9,10,11,
            // we want to get the corresponding element at original index
            // 16,17,18,19, so on and so forth.

            var i = 0;
            if (elemIdx < uniforms.k) {
              i = elemIdx;
            } else {
              i = elemIdx * 2 - elemIdx % uniforms.k;
            }
            var i0 = 0;
            if (uniforms.firstPass == 1) {
              i0 = i;
            } else {
              i0 = i32(getIndices(batch, i));
            }
            var i1 = 0;
            if (uniforms.firstPass == 1) {
              i1 = i + uniforms.k;
            } else {
              i1 = i32(getIndices(batch, i + uniforms.k));
            }

            let x0 = getX(batch, i0);
            var x1 = f32(0.0);
            if (i1 < uniforms.inputSize) {
              x1 = getX(batch, i1);
            } else {
              x1 = x0;
            }

            if (x0 >= x1) {
              setOutputAtIndex(index, f32(i0));
            } else {
              setOutputAtIndex(index, f32(i1));
            }
          }
        }
      `;
            return userCode;
        }
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function disposeIntermediateTensorInfoOrNull(backend, tensorInfo) {
        if (tensorInfo !== null) {
            backend.disposeData(tensorInfo.dataId);
        }
    }
    function roundUpToPow2(num) {
        let pow2 = 1;
        while (pow2 < num) {
            pow2 *= 2;
        }
        return pow2;
    }
    // Based on Algorithm 2 of Bitonic Top K, ref:
    // https://anilshanbhag.in/static/papers/gputopk_sigmod18.pdf
    function topK(args) {
        const { inputs, backend, attrs } = args;
        const { x } = inputs;
        const { k, sorted } = attrs;
        const xShape = x.shape;
        const lastDim = xShape[xShape.length - 1];
        if (backend.shouldExecuteOnCPU([x])) {
            const xVals = backend.readSync(x.dataId);
            const [allTopKVals, allTopKIndices] = topKImplCPU(xVals, xShape, x.dtype, k, sorted);
            return [
                backend.makeTensorInfo(allTopKVals.shape, allTopKVals.dtype, allTopKVals.values),
                backend.makeTensorInfo(allTopKIndices.shape, allTopKIndices.dtype, allTopKIndices.values)
            ];
        }
        if (k === 0) {
            xShape[xShape.length - 1] = 0;
            return [
                backend.makeTensorInfo(xShape, x.dtype, []),
                backend.makeTensorInfo(xShape, 'int32', [])
            ];
        }
        if (lastDim === 1 /* firstPass */) {
            return [
                x, fill({ attrs: { shape: xShape, dtype: 'int32', value: 0 }, backend })
            ];
        }
        // Reshape into a 2d tensor [batch, lastDim] and compute topk along lastDim.
        const xSize = tf.util.sizeFromShape(xShape);
        const batch = xSize / lastDim;
        const x2D = reshape({ inputs: { x }, attrs: { shape: [batch, lastDim] }, backend });
        const kPow2 = roundUpToPow2(k);
        const lastDimPow2 = roundUpToPow2(lastDim);
        // Only the indices containing the top K are kept at every step to reduce
        // number of outputs in the GPU algorithms, so once the final set of indices
        // is computed then gather is used to grab the corresponding values
        // from the original input.
        let indices = null;
        // GPU algorithm always takes in an indices input but this input is not used
        // on the first run of a GPU algorithm, therefore if indices is null we simply
        // pass in x2D instead of it but the value will not actually be used
        const getInputs = () => indices === null ? [x2D, x2D] : [x2D, indices];
        const runSwap = (dir, inc, shape) => {
            const inputs = getInputs();
            const program = new SwapProgram(shape);
            const firstPass = indices === null ? 1 : 0;
            const uniformDataSwap = [
                { type: 'int32', data: [lastDim] },
                { type: 'int32', data: [firstPass] },
                { type: 'float32', data: [Number.NEGATIVE_INFINITY] },
                { type: 'int32', data: [dir] },
                { type: 'int32', data: [inc] }
            ];
            const prevIndices = indices;
            indices = backend.runWebGPUProgram(program, inputs, 'int32', uniformDataSwap);
            disposeIntermediateTensorInfoOrNull(backend, prevIndices);
        };
        // Step 1: local sort
        for (let len = 1; len < kPow2; len *= 2) {
            const dir = len * 2;
            for (let inc = len; inc >= 1; inc /= 2) {
                runSwap(dir, inc, [batch, lastDimPow2]);
            }
        }
        // Step 2: merge
        for (let indicesSize = lastDimPow2; indicesSize > kPow2; indicesSize /= 2) {
            const inputs = getInputs();
            const mergeProgram = new MergeProgram([batch, indicesSize / 2]);
            const firstPass = indices === null ? 1 : 0;
            const uniformDataMerge = [
                { type: 'int32', data: [lastDim] },
                { type: 'int32', data: [firstPass] },
                { type: 'int32', data: [kPow2] }
            ];
            const prevIndices = indices;
            indices = backend.runWebGPUProgram(mergeProgram, inputs, 'int32', uniformDataMerge);
            disposeIntermediateTensorInfoOrNull(backend, prevIndices);
            // Step 3: rebuild
            const len = kPow2 / 2;
            const dir = len * 2;
            for (let inc = len; inc >= 1; inc /= 2) {
                runSwap(dir, inc, indices.shape);
            }
        }
        // Keep only the requested top K results instead of kPow2
        let prevIndices = indices;
        indices = slice({ inputs: { x: indices }, backend, attrs: { begin: 0, size: [batch, k] } });
        disposeIntermediateTensorInfoOrNull(backend, prevIndices);
        // Gather values on last dimension
        let values = gatherV2({ inputs: { x: x2D, indices }, backend, attrs: { axis: 1, batchDims: 1 } });
        disposeIntermediateTensorInfoOrNull(backend, x2D);
        // Reshape back to the original input shape, except that the last
        // dimension is k.
        const newShape = xShape.slice(0, -1);
        newShape.push(k);
        prevIndices = indices;
        indices = reshape({ inputs: { x: indices }, attrs: { shape: newShape }, backend });
        disposeIntermediateTensorInfoOrNull(backend, prevIndices);
        const prevValues = values;
        values = reshape({ inputs: { x: values }, attrs: { shape: newShape }, backend });
        disposeIntermediateTensorInfoOrNull(backend, prevValues);
        return [values, indices];
    }
    const topKConfig = {
        kernelName: tf.TopK,
        backendName: 'webgpu',
        kernelFunc: topK
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    class TransformProgram {
        constructor(outShape) {
            this.variableNames = ['Image', 'Transforms'];
            this.uniforms = 'interpolationModeId : i32, fillModeId : i32, fillValue : f32,';
            this.workgroupSize = [64, 1, 1];
            this.size = true;
            this.outputShape = outShape;
            this.dispatchLayout = flatDispatchLayout(this.outputShape);
            this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
            this.shaderKey = 'transform';
        }
        getUserCode() {
            const userCode = `
          fn mapCoord(outCoord : f32, len : f32) -> f32{
            var inCoord = outCoord;
            if(uniforms.fillModeId == 2) {
              if (inCoord < 0.0) {
                if (len <= 1.0) {
                  inCoord = 0.0;
                } else {
                  let sz2 = 2.0 * len;
                  if (inCoord < sz2) {
                    inCoord = sz2 * f32(i32(f32(-inCoord / sz2))) +
                    inCoord;
                  }
                  if (inCoord < -len) {
                    inCoord = inCoord + sz2;
                  } else {
                    inCoord = -inCoord - 1.0;
                  }
                }
              } else if (inCoord > len - 1.0) {
                if (len <= 1.0) {
                  inCoord = 0.0;
                } else {
                  let sz2 = 2.0 * len;
                  inCoord = inCoord - sz2 * f32(i32(f32(inCoord / sz2)));
                  if (inCoord >= len) {
                    inCoord = sz2 - inCoord - 1.0;
                  }
                }
              }
              return clamp(inCoord, 0.0, len - 1.0);
            } else if (uniforms.fillModeId == 3) {
              if (inCoord < 0.0) {
                if (len <= 1.0) {
                  inCoord = 0.0;
                } else {
                  let sz = len - 1.0;
                  inCoord = inCoord + len * (f32(i32(f32(-inCoord / sz))) + 1.0);
                }
              } else if (inCoord > len - 1.0) {
                if (len <= 1.0) {
                  inCoord = 0.0;
                } else {
                  let sz = len - 1.0;
                  inCoord = inCoord - len * f32(i32(f32(inCoord / sz)));
                }
              }
              return clamp(inCoord, 0.0, len - 1.0);
            } else if (uniforms.fillModeId == 4) {
              return clamp(outCoord, 0.0, len - 1.0);
            }
            return outCoord;
          }
          fn readWithFillValue(batch : i32, coordY : i32, coordX : i32,
            channel : i32) -> f32 {
            var outputValue : f32;
            if (0 <= coordY && coordY < uniforms.imageShape[1] && 0 <= coordX && coordX < uniforms.imageShape[2]) {
                outputValue = getImage(batch, coordY, coordX, channel);
            } else {
              outputValue = uniforms.fillValue;
            }
            return outputValue;
          }

          ${getMainHeaderString('index')} {
            if (index < uniforms.size) {
              let coords = getCoordsFromIndex(index);
              var outputValue : f32;
              let batch = coords[0];
              let x = coords[2];
              let y = coords[1];
              let channel = coords[3];
              let xf = f32(x);
              let yf = f32(y);
              let a1 = getTransforms(batch, 0);
              let a2 = getTransforms(batch, 1);
              let a3 = getTransforms(batch, 2);
              let b1 = getTransforms(batch, 3);
              let b2 = getTransforms(batch, 4);
              let b3 = getTransforms(batch, 5);
              let c1 = getTransforms(batch, 6);
              let c2 = getTransforms(batch, 7);
              let projection = c1 * xf + c2 * yf + 1.0;
              if (projection == 0.0) {
                outputValue = uniforms.fillValue;
              } else {
                let inX = (a1 * xf + a2 * yf + a3) / projection;
                let inY = (b1 * xf + b2 * yf + b3) / projection;
                let mapX = mapCoord(inX, f32(uniforms.imageShape[2]));
                let mapY = mapCoord(inY, f32(uniforms.imageShape[1]));

                if (uniforms.interpolationModeId == 1) {
                  let coordY = i32(round(mapY));
                  let coordX = i32(round(mapX));
                  outputValue = readWithFillValue(batch, coordY, coordX,
                    channel);
                } else {
                  let yFloor = floor(mapY);
                  let xFloor = floor(mapX);
                  let yCeil = yFloor + 1.0;
                  let xCeil = xFloor + 1.0;
                  let valueYFloor = (xCeil - mapX) *
                  readWithFillValue(batch, i32(yFloor), i32(xFloor), channel) +
                  (mapX - xFloor) *
                  readWithFillValue(batch, i32(yFloor), i32(xCeil), channel);
                  let valueYCeil = (xCeil - mapX) *
                  readWithFillValue(batch, i32(yCeil), i32(xFloor), channel) +
                  (mapX - xFloor) *
                  readWithFillValue(batch, i32(yCeil), i32(xCeil), channel);
                  outputValue = (yCeil - mapY) * valueYFloor +
                  (mapY - yFloor) * valueYCeil;
                }
              }
              setOutputAtIndex(index, outputValue);
            }
          }
        `;
            return userCode;
        }
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function transform(args) {
        const { inputs, backend, attrs } = args;
        const { image, transforms } = inputs;
        const { interpolation, fillMode, fillValue, outputShape } = attrs;
        const [batch, imageHeight, imageWidth, numChannels] = image.shape;
        const [outHeight, outWidth] = outputShape != null ? outputShape : [imageHeight, imageWidth];
        const outShape = [batch, outHeight, outWidth,
            numChannels];
        const program = new TransformProgram(outShape);
        const interpolationModeId = interpolation === 'nearest' ? 1 : 2;
        let fillModeId;
        switch (fillMode) {
            case 'constant':
                fillModeId = 1;
                break;
            case 'reflect':
                fillModeId = 2;
                break;
            case 'wrap':
                fillModeId = 3;
                break;
            case 'nearest':
                fillModeId = 4;
                break;
            default:
                fillModeId = 1;
                break;
        }
        const uniformData = [
            { type: 'int32', data: [interpolationModeId] },
            { type: 'int32', data: [fillModeId] }, { type: 'float32', data: [fillValue] }
        ];
        return backend.runWebGPUProgram(program, [image, transforms], 'float32', uniformData);
    }
    const transformConfig = {
        kernelName: tf.Transform,
        backendName: 'webgpu',
        kernelFunc: transform
    };

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function unpack(args) {
        const { inputs, backend, attrs } = args;
        const { value } = inputs;
        let { axis } = attrs;
        if (axis < 0) {
            axis += value.shape.length;
        }
        const x = value;
        const xRank = x.shape.length;
        const num = value.shape[axis];
        const outShape = new Array(xRank - 1);
        let outIndex = 0;
        for (let i = 0; i < xRank; i++) {
            if (i !== axis) {
                outShape[outIndex++] = x.shape[i];
            }
        }
        const toDispose = [];
        const begin = new Array(xRank).fill(0);
        const size = x.shape.slice();
        size[axis] = 1;
        const res = new Array(num);
        for (let i = 0; i < res.length; i++) {
            begin[axis] = i;
            const sliced = slice({ inputs: { x }, backend, attrs: { begin, size } });
            const reshaped = reshape({ inputs: { x: sliced }, backend, attrs: { shape: outShape } });
            res[i] = reshaped;
            toDispose.push(sliced);
        }
        toDispose.forEach(t => backend.disposeData(t.dataId));
        return res;
    }
    const unpackConfig = {
        kernelName: tf.Unpack,
        backendName: 'webgpu',
        kernelFunc: unpack
    };

    /**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    // List all kernel configs here
    const kernelConfigs = [
        _fusedMatMulConfig,
        absConfig,
        acosConfig,
        acoshConfig,
        addConfig,
        addNConfig,
        allConfig,
        anyConfig,
        argMaxConfig,
        argMinConfig,
        asinConfig,
        asinhConfig,
        atanConfig,
        atan2Config,
        atanhConfig,
        avgPoolConfig,
        avgPoolGradConfig,
        batchMatMulConfig,
        batchToSpaceNDConfig,
        bincountConfig,
        castConfig,
        ceilConfig,
        clipByValueConfig,
        complexConfig,
        concatConfig,
        conv2DConfig,
        conv2DBackpropFilterConfig,
        conv2DBackpropInputConfig,
        cosConfig,
        coshConfig,
        cropAndResizeConfig,
        cumprodConfig,
        cumsumConfig,
        denseBincountConfig,
        depthToSpaceConfig,
        depthwiseConv2dNativeConfig,
        diagConfig,
        dilation2DConfig,
        einsumConfig,
        eluConfig,
        equalConfig,
        erfConfig,
        expConfig,
        expandDimsConfig,
        expm1Config,
        fftConfig,
        fillConfig,
        flipLeftRightConfig,
        fromPixelsConfig,
        floorConfig,
        floorDivConfig,
        fusedBatchNormConfig,
        fusedConv2DConfig,
        fusedDepthwiseConv2DConfig,
        gatherNdConfig,
        gatherV2Config,
        greaterConfig,
        greaterEqualConfig,
        identityConfig,
        ifftConfig,
        imagConfig,
        isFiniteConfig,
        isInfConfig,
        isNaNConfig,
        leakyReluConfig,
        lessConfig,
        lessEqualConfig,
        linSpaceConfig,
        log1pConfig,
        logConfig,
        logicalAndConfig,
        logicalNotConfig,
        logicalOrConfig,
        lrnConfig,
        maxConfig,
        maximumConfig,
        maxPoolConfig,
        meanConfig,
        minConfig,
        minimumConfig,
        mirrorPadConfig,
        modConfig,
        multiplyConfig,
        negConfig,
        nonMaxSuppressionV3Config,
        nonMaxSuppressionV5Config,
        notEqualConfig,
        oneHotConfig,
        onesLikeConfig,
        packConfig,
        padV2Config,
        powConfig,
        preluConfig,
        prodConfig,
        rangeConfig,
        realConfig,
        realDivConfig,
        reciprocalConfig,
        reluConfig,
        relu6Config,
        reshapeConfig,
        resizeBilinearConfig,
        resizeNearestNeighborConfig,
        reverseConfig,
        rotateWithOffsetConfig,
        roundConfig,
        rsqrtConfig,
        scatterNdConfig,
        searchSortedConfig,
        selectConfig,
        seluConfig,
        sigmoidConfig,
        signConfig,
        sinConfig,
        sinhConfig,
        sliceConfig,
        stepConfig,
        stridedSliceConfig,
        stringNGramsConfig,
        softmaxConfig,
        softplusConfig,
        spaceToBatchNDConfig,
        sparseToDenseConfig,
        splitVConfig,
        sqrtConfig,
        squareConfig,
        squaredDifferenceConfig,
        subConfig,
        sumConfig,
        tanConfig,
        tanhConfig,
        tileConfig,
        topKConfig,
        transformConfig,
        transposeConfig,
        unpackConfig,
        zerosLikeConfig
    ];
    for (const kernelConfig of kernelConfigs) {
        tf.registerKernel(kernelConfig);
    }

    /**
     * @license
     * Copyright 2023 Google LLC.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function getMainHeaderString$1() {
        var params = [];
        for (var _i = 0; _i < arguments.length; _i++) {
            params[_i] = arguments[_i];
        }
        var snippet;
        switch (params.length) {
            case 0:
                snippet = "fn main() ";
                break;
            case 1:
                snippet = "fn main(".concat(params[0], " : i32)");
                break;
            default:
                throw Error('Unreachable');
        }
        return snippet;
    }

    /**
     * @license
     * Copyright 2023 Google LLC.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    var GetpointsConfidenceProgram = /** @class */ (function () {
        function GetpointsConfidenceProgram(bShape) {
            // A is heatmapScores, B is heatmapValues.
            this.variableNames = ['A', 'B'];
            this.size = true;
            var workgroupSizeX = 32;
            this.workgroupSize = [workgroupSizeX, 1, 1];
            this.outputShape = [bShape[0], 1];
            this.dispatchLayout =
                flatDispatchLayout(this.outputShape);
            this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize);
            this.shaderKey = 'getpointsConfidenceOp';
        }
        GetpointsConfidenceProgram.prototype.getUserCode = function () {
            return "\n        ".concat(getMainHeaderString$1('index'), " {\n          if (index < uniforms.size) {\n            let y = B[index * 2];\n            let x = B[index * 2 + 1];\n            let outIndex = y * uniforms.aShape.x * uniforms.aShape.z + x * uniforms.aShape.z + index;\n            result[index] = A[outIndex];\n          }\n        }\n        ");
        };
        return GetpointsConfidenceProgram;
    }());
    function getPointsConfidenceWebGPU(a, b) {
        var webgpuBackend = tf.backend();
        var program = new GetpointsConfidenceProgram(b.shape);
        var outInfo = webgpuBackend.runWebGPUProgram(program, [a, b], 'float32');
        var value = tf.engine().makeTensorFromTensorInfo(outInfo);
        return value;
    }

    /**
     * @license
     * Copyright 2023 Google LLC.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function getPointsConfidenceGPU(a, b) {
        if (tf.backend() instanceof WebGPUBackend) {
            return getPointsConfidenceWebGPU(a, b);
        }
        throw new Error('getPointsConfidenceWebGPU is not supported in this backend!');
    }

    /**
     * @license
     * Copyright 2023 Google LLC.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    var GetOffsetVectorsProgram = /** @class */ (function () {
        function GetOffsetVectorsProgram(outputShape) {
            // A is heatmapScores, B is heatMapCoords.
            this.variableNames = ['A', 'B'];
            this.size = true;
            this.supportedLastDimension = 2;
            // Only 2d tensor whose last dimension is 2 is supported.
            if (outputShape.length !== 2 ||
                outputShape[1] !== this.supportedLastDimension) {
                throw new Error("GetOffsetVectorsProgram only supports shape of [x, ".concat(this.supportedLastDimension, "], but current shape is ").concat(outputShape));
            }
            var workgroupSizeX = 32;
            this.workgroupSize = [workgroupSizeX, 1, 1];
            this.outputShape = outputShape;
            var computeDispatchInfo = [outputShape[0], 1];
            this.dispatchLayout =
                flatDispatchLayout(computeDispatchInfo);
            this.dispatch = computeDispatch(this.dispatchLayout, computeDispatchInfo, this.workgroupSize);
            this.shaderKey = 'GetOffsetVectors';
        }
        GetOffsetVectorsProgram.prototype.getUserCode = function () {
            return "\n    fn getOffsetPoint(y: i32, x: i32, index: i32) -> vec2<i32> {\n      let outIndexY = y * uniforms.bShape.x * uniforms.bShape.y + x * uniforms.bShape.y + index;\n      let outIndexX = outIndexY + uniforms.bShape.z;\n      let outY = i32(B[outIndexY]);\n      let outX = i32(B[outIndexX]);\n      return vec2<i32>(outY, outX);\n    }\n\n    ".concat(getMainHeaderString$1('index'), " {\n      if (index < uniforms.size) {\n        let indexY = index * ").concat(this.supportedLastDimension, ";\n        let indexX = indexY + 1;\n        let heatmapY = A[indexY];\n        let heatmapX = A[indexX];\n        let out = getOffsetPoint(i32(heatmapY), i32(heatmapX), index);\n        result[indexY] = f32(out[0]);\n        result[indexX] = f32(out[1]);\n      }\n    }\n    ");
        };
        return GetOffsetVectorsProgram;
    }());
    function getOffsetVectorsWebGPU(a, b) {
        var webgpuBackend = tf.backend();
        var program = new GetOffsetVectorsProgram(a.shape);
        var outInfo = webgpuBackend.runWebGPUProgram(program, [a, b], 'float32');
        var value = tf.engine().makeTensorFromTensorInfo(outInfo);
        return value;
    }

    /**
     * @license
     * Copyright 2023 Google LLC.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function getOffsetVectorsGPU(a, b) {
        if (tf.backend() instanceof WebGPUBackend) {
            return getOffsetVectorsWebGPU(a, b);
        }
        throw new Error('getOffsetVectorsGPU is not supported in this backend!');
    }

    /**
     * @license
     * Copyright 2019 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function mod$1(a, b) {
        return tf.tidy(function () {
            var floored = tf.div(a, tf.scalar(b, 'int32'));
            return tf.sub(a, tf.mul(floored, tf.scalar(b, 'int32')));
        });
    }
    function argmax2d(inputs) {
        var _a = inputs.shape, height = _a[0], width = _a[1], depth = _a[2];
        return tf.tidy(function () {
            var reshaped = tf.reshape(inputs, [height * width, depth]);
            var coords = tf.argMax(reshaped, 0);
            var yCoords = tf.expandDims(tf.div(coords, tf.scalar(width, 'int32')), 1);
            var xCoords = tf.expandDims(mod$1(coords, width), 1);
            return tf.concat([yCoords, xCoords], 1);
        });
    }
    function getPointsConfidence(heatmapScores, heatMapCoords) {
        var numKeypoints = heatMapCoords.shape[0];
        var result = new Float32Array(numKeypoints);
        for (var keypoint = 0; keypoint < numKeypoints; keypoint++) {
            var y = heatMapCoords.get(keypoint, 0);
            var x = heatMapCoords.get(keypoint, 1);
            result[keypoint] = heatmapScores.get(y, x, keypoint);
        }
        return result;
    }
    function getOffsetPoints(heatMapCoordsBuffer, outputStride, offsetsBuffer) {
        return tf.tidy(function () {
            var offsetVectors = getOffsetVectors(heatMapCoordsBuffer, offsetsBuffer);
            return tf.add(tf.cast(tf.mul(heatMapCoordsBuffer.toTensor(), tf.scalar(outputStride, 'int32')), 'float32'), offsetVectors);
        });
    }
    function getOffsetVectors(heatMapCoordsBuffer, offsetsBuffer) {
        var result = [];
        for (var keypoint = 0; keypoint < COCO_KEYPOINTS.length; keypoint++) {
            var heatmapY = heatMapCoordsBuffer.get(keypoint, 0).valueOf();
            var heatmapX = heatMapCoordsBuffer.get(keypoint, 1).valueOf();
            var _a = getOffsetPoint$1(heatmapY, heatmapX, keypoint, offsetsBuffer), x = _a.x, y = _a.y;
            result.push(y);
            result.push(x);
        }
        return tf.tensor2d(result, [COCO_KEYPOINTS.length, 2]);
    }
    function getOffsetPoint$1(y, x, keypoint, offsetsBuffer) {
        return {
            y: offsetsBuffer.get(y, x, keypoint),
            x: offsetsBuffer.get(y, x, keypoint + COCO_KEYPOINTS.length)
        };
    }
    function getOffsetPointsGPU(heatMapCoordsBuffer, outputStride, offsetsBuffer) {
        return tf.tidy(function () {
            var offsetVectors = getOffsetVectorsGPU(heatMapCoordsBuffer, offsetsBuffer);
            return tf.add(tf.cast(tf.mul(heatMapCoordsBuffer, tf.scalar(outputStride, 'int32')), 'float32'), offsetVectors);
        });
    }

    /**
     * @license
     * Copyright 2019 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    /**
     * Detects a single pose and finds its parts from part scores and offset
     * vectors. It returns a single pose detection. It works as follows:
     * argmax2d is done on the scores to get the y and x index in the heatmap
     * with the highest score for each part, which is essentially where the
     * part is most likely to exist. This produces a tensor of size 17x2, with
     * each row being the y and x index in the heatmap for each keypoint.
     * The offset vector for each part is retrieved by getting the
     * y and x from the offsets corresponding to the y and x index in the
     * heatmap for that part. This produces a tensor of size 17x2, with each
     * row being the offset vector for the corresponding keypoint.
     * To get the keypoint, each part’s heatmap y and x are multiplied
     * by the output stride then added to their corresponding offset vector,
     * which is in the same scale as the original image.
     *
     * @param heatmapScores 3-D tensor with shape `[height, width, numParts]`.
     * The value of heatmapScores[y, x, k]` is the score of placing the `k`-th
     * object part at position `(y, x)`.
     *
     * @param offsets 3-D tensor with shape `[height, width, numParts * 2]`.
     * The value of [offsets[y, x, k], offsets[y, x, k + numParts]]` is the
     * short range offset vector of the `k`-th  object part at heatmap
     * position `(y, x)`.
     *
     * @param outputStride The output stride that was used when feed-forwarding
     * through the PoseNet model.  Must be 32, 16, or 8.
     *
     * @return A promise that resolves with single pose with a confidence score,
     * which contains an array of keypoints indexed by part id, each with a score
     * and position.
     */
    function decodeSinglePose(heatmapScores, offsets, outputStride) {
        return __awaiter(this, void 0, void 0, function () {
            var totalScore, heatmapValues, allTensorBuffers, scoresBuffer, offsetsBuffer, heatmapValuesBuffer, offsetPoints, offsetPointsBuffer, keypointConfidence, keypoints;
            return __generator(this, function (_a) {
                switch (_a.label) {
                    case 0:
                        totalScore = 0.0;
                        heatmapValues = argmax2d(heatmapScores);
                        return [4 /*yield*/, Promise.all([heatmapScores.buffer(), offsets.buffer(), heatmapValues.buffer()])];
                    case 1:
                        allTensorBuffers = _a.sent();
                        scoresBuffer = allTensorBuffers[0];
                        offsetsBuffer = allTensorBuffers[1];
                        heatmapValuesBuffer = allTensorBuffers[2];
                        offsetPoints = getOffsetPoints(heatmapValuesBuffer, outputStride, offsetsBuffer);
                        return [4 /*yield*/, offsetPoints.buffer()];
                    case 2:
                        offsetPointsBuffer = _a.sent();
                        keypointConfidence = Array.from(getPointsConfidence(scoresBuffer, heatmapValuesBuffer));
                        keypoints = keypointConfidence.map(function (score, keypointId) {
                            totalScore += score;
                            return {
                                y: offsetPointsBuffer.get(keypointId, 0),
                                x: offsetPointsBuffer.get(keypointId, 1),
                                score: score,
                                name: COCO_KEYPOINTS[keypointId]
                            };
                        });
                        heatmapValues.dispose();
                        offsetPoints.dispose();
                        return [2 /*return*/, { keypoints: keypoints, score: totalScore / keypoints.length }];
                }
            });
        });
    }
    /**
     * Detects a single pose and finds its parts from part scores and offset
     * vectors with GPU.
     */
    function decodeSinglePoseGPU(heatmapScores, offsets, outputStride) {
        return __awaiter(this, void 0, void 0, function () {
            var heatmapValues, offsetPoints, keypointConfidence;
            return __generator(this, function (_a) {
                heatmapValues = argmax2d(heatmapScores);
                offsetPoints = getOffsetPointsGPU(heatmapValues, outputStride, offsets);
                keypointConfidence = getPointsConfidenceGPU(heatmapScores, heatmapValues);
                return [2 /*return*/, [offsetPoints, keypointConfidence]];
            });
        });
    }

    /**
     * @license
     * Copyright 2019 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function flipPosesHorizontal(poses, imageSize) {
        for (var _i = 0, poses_1 = poses; _i < poses_1.length; _i++) {
            var pose = poses_1[_i];
            for (var _a = 0, _b = pose.keypoints; _a < _b.length; _a++) {
                var kp = _b[_a];
                kp.x = imageSize.width - 1 - kp.x;
            }
        }
        return poses;
    }

    /**
     * @license
     * Copyright 2019 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function scalePoses(poses, imageSize, inputResolution, padding) {
        var height = imageSize.height, width = imageSize.width;
        var scaleY = height / (inputResolution.height * (1 - padding.top - padding.bottom));
        var scaleX = width / (inputResolution.width * (1 - padding.left - padding.right));
        var offsetY = -padding.top * inputResolution.height;
        var offsetX = -padding.left * inputResolution.width;
        if (scaleX === 1 && scaleY === 1 && offsetY === 0 && offsetX === 0) {
            return poses;
        }
        for (var _i = 0, poses_1 = poses; _i < poses_1.length; _i++) {
            var pose = poses_1[_i];
            for (var _a = 0, _b = pose.keypoints; _a < _b.length; _a++) {
                var kp = _b[_a];
                kp.x = (kp.x + offsetX) * scaleX;
                kp.y = (kp.y + offsetY) * scaleY;
            }
        }
        return poses;
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * https://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    function validateModelConfig$3(modelConfig) {
        var config = modelConfig || MOBILENET_V1_CONFIG;
        if (config.architecture == null) {
            config.architecture = 'MobileNetV1';
        }
        if (VALID_ARCHITECTURE.indexOf(config.architecture) < 0) {
            throw new Error("Invalid architecture ".concat(config.architecture, ". ") +
                "Should be one of ".concat(VALID_ARCHITECTURE));
        }
        if (config.inputResolution == null) {
            config.inputResolution = { height: 257, width: 257 };
        }
        if (config.outputStride == null) {
            config.outputStride = 16;
        }
        if (VALID_STRIDE[config.architecture].indexOf(config.outputStride) < 0) {
            throw new Error("Invalid outputStride ".concat(config.outputStride, ". ") +
                "Should be one of ".concat(VALID_STRIDE[config.architecture], " ") +
                "for architecture ".concat(config.architecture, "."));
        }
        if (config.multiplier == null) {
            config.multiplier = 1.0;
        }
        if (VALID_MULTIPLIER[config.architecture].indexOf(config.multiplier) < 0) {
            throw new Error("Invalid multiplier ".concat(config.multiplier, ". ") +
                "Should be one of ".concat(VALID_MULTIPLIER[config.architecture], " ") +
                "for architecture ".concat(config.architecture, "."));
        }
        if (config.quantBytes == null) {
            config.quantBytes = 4;
        }
        if (VALID_QUANT_BYTES.indexOf(config.quantBytes) < 0) {
            throw new Error("Invalid quantBytes ".concat(config.quantBytes, ". ") +
                "Should be one of ".concat(VALID_QUANT_BYTES, " ") +
                "for architecture ".concat(config.architecture, "."));
        }
        if (config.architecture === 'MobileNetV1' && config.outputStride === 32 &&
            config.multiplier !== 1) {
            throw new Error("When using an output stride of 32, " +
                "you must select 1 as the multiplier.");
        }
        return config;
    }
    function assertValidOutputStride(outputStride) {
        tf.util.assert(VALID_OUTPUT_STRIDES.indexOf(outputStride) >= 0, function () { return "outputStride of ".concat(outputStride, " is invalid. ") +
            "It must be either 8 or 16."; });
    }
    function isValidInputResolution(resolution, outputStride) {
        return (resolution - 1) % outputStride === 0;
    }
    function assertValidResolution(resolution, outputStride) {
        tf.util.assert(isValidInputResolution(resolution.height, outputStride), function () { return "height of ".concat(resolution.height, " is invalid for output stride ") +
            "".concat(outputStride, "."); });
        tf.util.assert(isValidInputResolution(resolution.width, outputStride), function () { return "width of ".concat(resolution.width, " is invalid for output stride ") +
            "".concat(outputStride, "."); });
    }
    function validateEstimationConfig$2(estimationConfig) {
        var config = estimationConfig;
        if (config.maxPoses == null) {
            config.maxPoses = 1;
        }
        if (config.maxPoses <= 0) {
            throw new Error("Invalid maxPoses ".concat(config.maxPoses, ". Should be > 0."));
        }
        if (config.maxPoses > 1) {
            // Multi-poses estimation, needs additional check for multi-poses
            // parameters.
            config = __assign(__assign({}, MULTI_PERSON_ESTIMATION_CONFIG), config);
            if (config.scoreThreshold < 0.0 || config.scoreThreshold > 1.0) {
                throw new Error("Invalid scoreThreshold ".concat(config.scoreThreshold, ". ") +
                    "Should be in range [0.0, 1.0]");
            }
            if (config.nmsRadius <= 0) {
                throw new Error("Invalid nmsRadius ".concat(config.nmsRadius, "."));
            }
        }
        return config;
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * https://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    var MOBILENET_BASE_URL = 'https://storage.googleapis.com/tfjs-models/savedmodel/posenet/mobilenet/';
    var RESNET50_BASE_URL = 'https://storage.googleapis.com/tfjs-models/savedmodel/posenet/resnet50/';
    // The PoseNet 2.0 ResNet50 models use the latest TensorFlow.js 1.0 model
    // format.
    function resNet50Checkpoint(stride, quantBytes) {
        var graphJson = "model-stride".concat(stride, ".json");
        // quantBytes=4 corresponding to the non-quantized full-precision checkpoints.
        if (quantBytes === 4) {
            return RESNET50_BASE_URL + "float/" + graphJson;
        }
        else {
            return RESNET50_BASE_URL + "quant".concat(quantBytes, "/") + graphJson;
        }
    }
    // The PoseNet 2.0 MobileNetV1 models use the latest TensorFlow.js 1.0 model
    // format.
    function mobileNetCheckpoint(stride, multiplier, quantBytes) {
        var toStr = { 1.0: '100', 0.75: '075', 0.50: '050' };
        var graphJson = "model-stride".concat(stride, ".json");
        // quantBytes=4 corresponding to the non-quantized full-precision checkpoints.
        if (quantBytes === 4) {
            return MOBILENET_BASE_URL + "float/".concat(toStr[multiplier], "/") + graphJson;
        }
        else {
            return MOBILENET_BASE_URL + "quant".concat(quantBytes, "/").concat(toStr[multiplier], "/") +
                graphJson;
        }
    }
    function getValidInputResolutionDimensions(inputResolution, outputStride) {
        return {
            height: toValidInputResolution(inputResolution.height, outputStride),
            width: toValidInputResolution(inputResolution.width, outputStride)
        };
    }
    function toValidInputResolution(inputResolution, outputStride) {
        if (isValidInputResolution$1(inputResolution, outputStride)) {
            return inputResolution;
        }
        return Math.floor(inputResolution / outputStride) * outputStride + 1;
    }
    function isValidInputResolution$1(resolution, outputStride) {
        return (resolution - 1) % outputStride === 0;
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * https://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    /**
     * PoseNet detector class.
     */
    var PosenetDetector = /** @class */ (function () {
        function PosenetDetector(posenetModel, config) {
            this.posenetModel = posenetModel;
            // validate params.
            var inputShape = this.posenetModel.inputs[0].shape;
            tf.util.assert((inputShape[1] === -1) && (inputShape[2] === -1), function () { return "Input shape [".concat(inputShape[1], ", ").concat(inputShape[2], "] ") +
                "must both be equal to or -1"; });
            var validInputResolution = getValidInputResolutionDimensions(config.inputResolution, config.outputStride);
            assertValidOutputStride(config.outputStride);
            assertValidResolution(validInputResolution, config.outputStride);
            this.inputResolution = validInputResolution;
            this.outputStride = config.outputStride;
            this.architecture = config.architecture;
        }
        /**
         * Estimates poses for an image or video frame.
         *
         * This does standard ImageNet pre-processing before inferring through the
         * model. The image should pixels should have values [0-255]. It returns a
         * single pose or multiple poses based on the maxPose parameter from the
         * `config`.
         *
         * @param image
         * ImageData|HTMLImageElement|HTMLCanvasElement|HTMLVideoElement The input
         * image to feed through the network.
         *
         * @param estimationConfig
         *       maxPoses: Optional. Max number of poses to estimate.
         *       When maxPoses = 1, a single pose is detected, it is usually much more
         *       efficient than maxPoses > 1. When maxPoses > 1, multiple poses are
         *       detected.
         *
         *       flipHorizontal: Optional. Default to false. When image data comes
         *       from camera, the result has to flip horizontally.
         *
         * @return An array of `Pose`s.
         */
        PosenetDetector.prototype.estimatePoses = function (image, estimationConfig) {
            if (estimationConfig === void 0) { estimationConfig = SINGLE_PERSON_ESTIMATION_CONFIG; }
            return __awaiter(this, void 0, void 0, function () {
                return __generator(this, function (_a) {
                    return [2 /*return*/, this.estimatePosesGPU(image, estimationConfig, false)];
                });
            });
        };
        /**
         * Estimates poses for an image or video frame, optionally supports gpu
         * rendering.
         *
         * This does standard ImageNet pre-processing before inferring through the
         * model. The image should pixels should have values [0-255]. It returns a
         * single pose or multiple poses based on the maxPose parameter from the
         * `config`.
         *
         * @param image
         * ImageData|HTMLImageElement|HTMLCanvasElement|HTMLVideoElement The input
         * image to feed through the network.
         *
         * @param estimationConfig
         *       maxPoses: Optional. Max number of poses to estimate.
         *       When maxPoses = 1, a single pose is detected, it is usually much more
         *       efficient than maxPoses > 1. When maxPoses > 1, multiple poses are
         *       detected.
         *
         *       flipHorizontal: Optional. Default to false. When image data comes
         *       from camera, the result has to flip horizontally.
         *
         * @param useGpuRenderer
         *        Whether rendering predict results with gpu or not.
         *
         * @return If not rendering with gpu, an array of poses, each pose contains an
         *     array of `Keypoint`s. Otherwise an array of tensor, and canvas info.
         */
        PosenetDetector.prototype.estimatePosesGPU = function (image, estimationConfig, useGpuRenderer) {
            if (estimationConfig === void 0) { estimationConfig = SINGLE_PERSON_ESTIMATION_CONFIG; }
            if (useGpuRenderer === void 0) { useGpuRenderer = false; }
            return __awaiter(this, void 0, void 0, function () {
                var config, _a, imageTensor, padding, imageValueShifted, results, offsets, heatmap, displacementFwd, displacementBwd, heatmapScores, poses, _b, pose, score, pose, canvasInfo, scaledPoses, imageSize;
                return __generator(this, function (_c) {
                    switch (_c.label) {
                        case 0:
                            config = validateEstimationConfig$2(estimationConfig);
                            if (image == null) {
                                return [2 /*return*/, useGpuRenderer ? [[], []] : []];
                            }
                            this.maxPoses = config.maxPoses;
                            _a = convertImageToTensor(image, {
                                outputTensorSize: this.inputResolution,
                                keepAspectRatio: true,
                                borderMode: 'replicate'
                            }), imageTensor = _a.imageTensor, padding = _a.padding;
                            imageValueShifted = this.architecture === 'ResNet50' ?
                                tf.add(imageTensor, RESNET_MEAN) :
                                shiftImageValue(imageTensor, [-1, 1]);
                            results = this.posenetModel.predict(imageValueShifted);
                            if (this.architecture === 'ResNet50') {
                                offsets = tf.squeeze(results[2], [0]);
                                heatmap = tf.squeeze(results[3], [0]);
                                displacementFwd = tf.squeeze(results[0], [0]);
                                displacementBwd = tf.squeeze(results[1], [0]);
                            }
                            else {
                                offsets = tf.squeeze(results[0], [0]);
                                heatmap = tf.squeeze(results[1], [0]);
                                displacementFwd = tf.squeeze(results[2], [0]);
                                displacementBwd = tf.squeeze(results[3], [0]);
                            }
                            heatmapScores = tf.sigmoid(heatmap);
                            if (!(this.maxPoses === 1)) return [3 /*break*/, 5];
                            if (!useGpuRenderer) return [3 /*break*/, 2];
                            return [4 /*yield*/, decodeSinglePoseGPU(heatmapScores, offsets, this.outputStride)];
                        case 1:
                            _b = _c.sent(), pose = _b[0], score = _b[1];
                            poses = [pose, score];
                            return [3 /*break*/, 4];
                        case 2: return [4 /*yield*/, decodeSinglePose(heatmapScores, offsets, this.outputStride)];
                        case 3:
                            pose = _c.sent();
                            poses = [pose];
                            _c.label = 4;
                        case 4: return [3 /*break*/, 7];
                        case 5:
                            if (useGpuRenderer) {
                                throw new Error('GPU renderer only supports single pose!');
                            }
                            return [4 /*yield*/, decodeMultiplePoses(heatmapScores, offsets, displacementFwd, displacementBwd, this.outputStride, this.maxPoses, config.scoreThreshold, config.nmsRadius)];
                        case 6:
                            poses = _c.sent();
                            _c.label = 7;
                        case 7:
                            if (useGpuRenderer) {
                                // TODO: handle flipPosesHorizontal in GPU.
                                if (config.flipHorizontal === true) {
                                    throw new Error('flipHorizontal is not supported!');
                                }
                                canvasInfo = this.getCanvasInfo(getImageSize(image), this.inputResolution, padding);
                            }
                            else {
                                imageSize = getImageSize(image);
                                scaledPoses =
                                    scalePoses(poses, imageSize, this.inputResolution, padding);
                                if (config.flipHorizontal) {
                                    scaledPoses = flipPosesHorizontal(scaledPoses, imageSize);
                                }
                            }
                            imageTensor.dispose();
                            imageValueShifted.dispose();
                            tf.dispose(results);
                            offsets.dispose();
                            heatmap.dispose();
                            displacementFwd.dispose();
                            displacementBwd.dispose();
                            heatmapScores.dispose();
                            return [2 /*return*/, useGpuRenderer ? [poses, canvasInfo] : scaledPoses];
                    }
                });
            });
        };
        PosenetDetector.prototype.getCanvasInfo = function (imageSize, inputResolution, padding) {
            var height = imageSize.height, width = imageSize.width;
            var scaleY = height / (inputResolution.height * (1 - padding.top - padding.bottom));
            var scaleX = width / (inputResolution.width * (1 - padding.left - padding.right));
            var offsetY = -padding.top * inputResolution.height;
            var offsetX = -padding.left * inputResolution.width;
            return [
                offsetX, offsetY, scaleX, scaleY, imageSize.width, imageSize.height
            ];
        };
        PosenetDetector.prototype.dispose = function () {
            this.posenetModel.dispose();
        };
        PosenetDetector.prototype.reset = function () {
            // No-op. There's no global state.
        };
        return PosenetDetector;
    }());
    /**
     * Loads the PoseNet model instance from a checkpoint, with the ResNet
     * or MobileNet architecture. The model to be loaded is configurable using the
     * config dictionary ModelConfig. Please find more details in the
     * documentation of the ModelConfig.
     *
     * @param config ModelConfig dictionary that contains parameters for
     * the PoseNet loading process. Please find more details of each parameters
     * in the documentation of the ModelConfig interface. The predefined
     * `MOBILENET_V1_CONFIG` and `RESNET_CONFIG` can also be used as references
     * for defining your customized config.
     */
    function load$3(modelConfig) {
        if (modelConfig === void 0) { modelConfig = MOBILENET_V1_CONFIG; }
        return __awaiter(this, void 0, void 0, function () {
            var config, defaultUrl_1, model_1, defaultUrl, model;
            return __generator(this, function (_a) {
                switch (_a.label) {
                    case 0:
                        config = validateModelConfig$3(modelConfig);
                        if (!(config.architecture === 'ResNet50')) return [3 /*break*/, 2];
                        defaultUrl_1 = resNet50Checkpoint(config.outputStride, config.quantBytes);
                        return [4 /*yield*/, tfconv.loadGraphModel(config.modelUrl || defaultUrl_1)];
                    case 1:
                        model_1 = _a.sent();
                        return [2 /*return*/, new PosenetDetector(model_1, config)];
                    case 2:
                        defaultUrl = mobileNetCheckpoint(config.outputStride, config.multiplier, config.quantBytes);
                        return [4 /*yield*/, tfconv.loadGraphModel(config.modelUrl || defaultUrl)];
                    case 3:
                        model = _a.sent();
                        return [2 /*return*/, new PosenetDetector(model, config)];
                }
            });
        });
    }

    /**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * https://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     */
    /**
     * Create a pose detector instance.
     *
     * @param model The name of the pipeline to load.
     */
    function createDetector(model, modelConfig) {
        return __awaiter(this, void 0, void 0, function () {
            var config, runtime;
            return __generator(this, function (_a) {
                switch (model) {
                    case exports.SupportedModels.PoseNet:
                        return [2 /*return*/, load$3(modelConfig)];
                    case exports.SupportedModels.BlazePose:
                        config = modelConfig;
                        runtime = void 0;
                        if (config != null) {
                            if (config.runtime === 'tfjs') {
                                return [2 /*return*/, load$1(modelConfig)];
                            }
                            if (config.runtime === 'mediapipe') {
                                return [2 /*return*/, load(modelConfig)];
                            }
                            runtime = config.runtime;
                        }
                        throw new Error("Expect modelConfig.runtime to be either 'tfjs' " +
                            "or 'mediapipe', but got ".concat(runtime));
                    case exports.SupportedModels.MoveNet:
                        return [2 /*return*/, load$2(modelConfig)];
                    default:
                        throw new Error("".concat(model, " is not a supported model name."));
                }
            });
        });
    }

    var calculators = { keypointsToNormalizedKeypoints: keypointsToNormalizedKeypoints };
    var movenet = {
        modelType: {
            'SINGLEPOSE_LIGHTNING': SINGLEPOSE_LIGHTNING,
            'SINGLEPOSE_THUNDER': SINGLEPOSE_THUNDER,
            'MULTIPOSE_LIGHTNING': MULTIPOSE_LIGHTNING
        }
    };

    exports.calculators = calculators;
    exports.createDetector = createDetector;
    exports.movenet = movenet;
    exports.util = util;

    Object.defineProperty(exports, '__esModule', { value: true });

})));
